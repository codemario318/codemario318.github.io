[{"content":"JVM 이란? JVM이란 Java Virtual Machine, 자바 가상 머신의 약자를 따서 줄여 부르는 용어이다. JVM의 역할은 자바 애플리케이션을 클래스 로더를 통해 읽어 들여 자바 API와 함께 실행하는 것이다.\nJVM은 Java와 OS 사이에서 중개자 역할을 수행하여 JAVA가 OS에 구애받지 않고 재사용을 가능하게 해준다. 메모리 관리, Garbage collction을 수행한다. 스택기반의 가상머신이다. ARM 아키텍쳐 같은 하드웨어는 레지스터 기반으로 동작하는데 비해 JVM은 스택 기반으로 동작한다.\n자바프로그램 실행과정 프로그램이 실행되면 JVM은 OS로 부터 프로그램이 필요로 하는 메모리를 할당받는다. JVM은 이 메모리를 용도에 따라 여러 영역으로 나누어 관리한다. 자바 컴파일러(javac)가 자바 소스코드(.java)를 읽어들여 자바 바이트 코드(.class)로 변환시킨다. Class Loader를 통해 class 파일들을 JVM으로 로딩한다. 로딩된 class 파일들은 Execution engine을 통해 해석된다. 해석된 바이트 코드는 Runtime Data Areas에 배치되어 실질적인 수행이 이루어지게 된다. 이러한 실행 과정속에서 JVM은 필요에 따라 Thread Synchronizeation과 GC같은 관리작업을 수행한다.\nJVM 구성 클래스 로더 Class Loader JVM 내로 클래스 파일을 로드하고, 링크를 통해 배치하는 작업을 수행하는 모듈이다. Runtime시에 동적으로 클래스를 로드한다. jar파일 내 저장된 크래스들을 JVM위에 탑재하고 사용하지 않는 클래스들은 메모리에서 삭제한다. (컴파일러 역할)\n자바는 동적코드, 컴파일 타임이 아니라 런타임에 참조한다. 즉, 클래스를 처음으로 참조할 때, 해당 클래스를 로드하고 링크한다. 그 역할을 클래스 로더가 수행한다.\n실행 엔진 Execution Engine 클래스를 실행시킨다. 클래스 로더가 JVM내의 런타임 데이터 영역에 바이트 코드를 배치하면 실행엔진에 의해 실행된다. 자바 바이트코드는 기계가 바로 수행할 수 있는 언어보다는 비교적 인간이 보기 편한 형태로 기술된 것이다.\n그래서 실행엔진은 이와 같은 바이트코드를 실제로 JVM내부에서 기계가 실행할 수 있는 형태로 변경한다. 이 때 두가지 방식을 사용하게 된다.\n인터프리터 Interpreter\n실행 엔진은 자바 바이트 코드를 명령어 단위로 읽어서 실행한다.\n인터프리터 언어의 단점을 그대로 갖고 있다. 한 줄 씩 수행하기 때문에 느리다. JIT Just-In-Time\n인터프리터 방식의 단점을 보완하기 위해 도입된 JIT 컴파일러이다. 인터프리터 방식으로 실행하다가 적절한 시점에 바이트 코드 전체를 컴파일하여 네이트브 코드로 변경하고, 이후에는 해당 코드를 더이상 인터프리팅 하지 않고 네이티브 코드로 직접 실행한다.\n네이티브 코드는 캐시에 보관하기 때문에 한 번 컴파일 된 코드는 빠르게 수행하게 된다. JIT 컴파일러가 컴파일 하는 과정은 바이트코드를 인터프리팅하는 것보다 훨씬 오래걸리므로 한 번만 실행되는 코드라면 컴파일하지 않고 인터프리팅 하는 것이 유리하다. JIT 컴파일러를 사용하는 JVM들은 내부적으로 해당 메서드가 얼마나 자주 수행되는지 체크하고, 일정 정도를 넘을 때에만 컴파일을 수행한다. Garbage Collector GC를 수행하는 모듈 (쓰레드)를 가진다.\nRuntime Data Area 프로그램을 수행하기 위해 OS에서 할당받은 메모리 공간\nPC Register Thread가 시작될 때 생성되며 생성될 때마다 생성되는 공간으로 스레드마다 하나씩 존재한다.\n쓰레드가 어떤 부분을 어떤 명령으로 실행해야할 지에 대한 기록을 하는 부분으로 현재 수행중인 JVM 명령의 주소를 갖는다.\nJVM 스택 영역 프로그램 실행과정에서 임시로 할당되었다가 메소드를 빠져나가면 바로 소멸되는 특성의 데이터를 저장하기 위한 영역이다.\n각종 형태의 변수나 임시 데이터, 스레드나 메소드의 정보를 저장한다. 메소드 호출 시마다 각각의 스택 프레임(그 메서드 만을 위한 공간)이 생성된다. 메서드 수행이 끝나면 프레임 별로 삭제를 한다. 메소드 안에서 사용되는 값들(local variable)을 저장한다. 호출된 메소드의 매개변수, 지역변수, 리턴 값 및 연산 시 일어나는 값들을 임시로 저장한다. Native method stack 자바 프로그램이 컴파일 되어 생성되는 바이트 코드가 아닌 실제 실행할 수 있는 기계어로 작성된 프로그램을 실행시키는 영역이다.\n자바가 아닌 다른 언어로 작성된 코드를 위한 공간이다. Java Native Interface를 통해 바이트 코드로 전환하여 저장하게 된다. 일반 프로그램처럼 커널이 스택을 잡아 독자적으로 프로그램을 실행시키는 영역이다. 이 부분을 통해 C code를 실행시켜 Kernel에 접근할 수 있다. Method Area (= Class area = Static area) 클래스 정보를 처음 메모리 공간에 올릴 때 초기화되는 대상을 저장하기 위한 메모리 공간.\n올라가게 되는 메소드의 바이트코드는 프로그램의 흐름을 구성하는 바이트 코드이다. 자바 프로그램은 메인 메소드의 호출에서 부터 계속된 메소드의 호출로 흐름을 이어가기 때문이다. 대부분 인스턴스의 생성도 메소드 내에서 명령하고 호출한다. 사실상 컴파일 된 파이트코드의 대부분이 메소드 바이트코드이기 때무넹 거의 모든 바이트코드가 올라간다고 봐도 상관없다. Runtime Constat Pool이라는 별도의 관리 영역도 함께 존재하여, 상수 자료형을 저장하여 참조하고 중복을 막는 역할을 수행한다. 올라가는 정보의 종류 Feild Information 멤버 변수의 이름 데이터 타입 접근 제어자에 대한 정보 Method Information 메소드의 이름, 리턴타입, 매개변수, 접근 제어자에 대한 정보 Type Information Class인지 interface인지의 여부 저장 Type의 속성 전체 이름 Super class의 전체 이름 (interface이거나 object인 경우 제외) Heap 객체를 저장하는 가상 메모리 공간\n생성된 객체와 배열을 저장한다. class area영역에 올라온 클래스들만 객체로 생성할 수 있다. Permanent Generation 생성된 객체들의 정보 주소값이 저장된 공간이다. class loader에 의해 load되는 class, method 등에 대한 meta 정보가 저장되는 영역이고, JVM에 의해 사용된다.\nReflection을 사용하여 동적으로 클래스가 로딩되는 경우에 사용된다. 내부적으로 Reflection 기능을 자주 사용하는 Spring Framework를 이용할 경우 이 영역에 대한 고려가 필요하다.\nNew/Young 영역 Eden 객체들이 최초로 생성되는 공간 Survivor 0 / 1 Eden에서 참조되는 객체들이 저장되는 공간 Old 영역 New area에서 일정 시간 참조되고 있는, 살아남은 객체들이 저장되는 공간\nEden 영역에 객체가 가득차게 되면 첫번째 GC(minor GC)가 발생한다. Eden 영역에 있는 값들을 Survivor 1 영역에 복사하고 이 영역을 제외한 나머지 영역의 객체를 삭제한다.\n인스턴스는 소멸 방법과 소멸 시점이 지역 변수와는 다리기에 힙이라는 별도의 영역에 할당된다. 자바 가상머신은 매우 합리적으로 인스턴스를 소멸시킨다. 더이상 인스턴스의 존재 이유가 없을 때 소멸시킨다.\n","date":"2023-04-18T16:07:19+09:00","image":"https://codemario318.github.io/post/jvm/jvm_cover_hu0ae05cc4d1c0ca93a8c2f5fc57548620_55838_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/jvm/","title":"JVM"},{"content":"제너레이터는 제너레이터 함수가 호출될 때 반환되는 이터러블 객체이다. 제네레이터 함수는 일반적인 함수와 비슷하게 생겼지만 yield 구문을 사용해 데이터를 원하는 시점에 반환하고 처리를 다시 시작할 수 있다. 일반적인 함수는 진입점이 하나라면 제네레이터는 진입점이 여러개라고 생각할 수 있다. 이러한 특성때문에 제네레이터를 사용하면 원하는 시점에 원하는 데이터를 받을 수 있게된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def generator(): yield 1 yield \u0026#39;string\u0026#39; yield True gen = generator() print(gen) # \u0026lt;generator object generator at 0x10a47c678\u0026gt; next(gen) #1 next(gen) # \u0026#39;string\u0026#39; next(gen) # True next(gen) \u0026#39;\u0026#39;\u0026#39; Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; StopIteration \u0026#39;\u0026#39;\u0026#39; 동작 yield 문이 포함된 함수를 실행하면 제너레이터 객체가 반환되는데 이 때는 함수의 내용이 실행되지 않는다. next() 라는 빌트인 메서드를 통해 제네레이터를 실행시킬 수 있으며 next() 메서드 내부적으로 iterator 를 인자로 받아 이터레이터의 __next__() 메서드를 실행시킨다. 처음 __next__() 를 호출하면 함수의 내용을 실행하다 yield 문을 만났을 때 처리를 중단한다. 이 때 모든 local state는 유지되는데 변수의 상태, 명령어 포인터, 내부 스택, 예외 처리 상태를 포함한다. 그 후 제어권을 상위 컨텍스트로 양보(yield)하고 또 __next__() 가 호출되면 제네레이터는 중단된 시점부터 다시 시작한다. yield 문의 값은 어떤 메서드를 통해 제네레이터가 다시 동작했는지에 따라 다른데, __next__() 를 사용하면 None이고 send() 를 사용하면 메서드로 전달 된 값을 갖게되어 외부에서 데이터를 입력받을 수 있게 된다.\n장점 List, Set, Dict 표현식은 iterable 하기에 for 표현식 등에서 유용하게 쓰일 수 있다. 하지만 해당 객체들은 Collection 특성상 가진 데이터를 메모리에 담고 있어야 하기 때문에 큰 값을 다룰 때는 성능상 불리하다. 제너레이터는 yield 를 통해 필요한 값만 받아 쓰기 때문에 모든 값을 메모리에 들고 있을 필요가 없게 된다.\n1 2 3 4 5 6 7 import sys a = [i for i in range(100000)] sys.getsizeof(a) #824464 b = (i for i in range(100000)) sys.getsizeof(b) #88 리스트가 여러번 사용될 수 있는 반면 b 제네레이터는 한번 사용된 후 소진된다. 이는 모든 이터레이터가 마찬가지인데 List, Set 등은 이터러블하지만 이터레이터는 아니기에 소진되지 않는다.\n1 2 len(list(b)) # 100000 len(list(b)) # 0 while True 구분으로 제공받을 데이터가 무한하거나, 모든 값을 한번에 계산하기엔 시간이 많이 소요되어 그때 그때 필요한 만큼만 받아 계산하고 싶을 때 제네레이터를 활용할 수 있다.\n","date":"2023-04-18T14:31:00+09:00","image":"https://codemario318.github.io/post/python_cover/python_cover_hu071c6006b6148c050030e26fb108bd62_83564_120x120_fill_box_smart1_3.png","permalink":"https://codemario318.github.io/post/python_cover/","title":"Python - Generator"},{"content":"\n엘라스틱서치는 검색 엔진인 아파치 루씬 (Apache Lucene)으로 구현한 RESTful API 기반의 검색 엔진이다. 엘라스틱서치 아키텍쳐는 클러스터 기반으로 구성되어 있다.\n클러스터 기본 특징 수평 확장\n클러스터를 사실상 무한으로 확장할 수 있다.\n인덱스 샤딩\n엘라스틱서치는 인덱스를 조각내서 \u0026ldquo;샤드 (shard)\u0026ldquo;라는 조각난 데이터로 만든다. 때문에 나누어진 데이터를 편하게 각 호스트에 분리해서 보관할 수 있다.\n엘라스틱서치 특징 Schemaless와 문서지향 엘라스틱 서치는 JSON 구조를 사용하여 기존 RDBMS와 같은 엄격한 구조를 적용하지 않는다.\n스키마가 다이나믹하게 변할 수 있다\n전통적인 관계형 구조로 구성할 경우 프로젝트 막바지에 모든 스키마르 ㄹ변경하고, 데이터를 다시 구성하는 문제에 봉착할 수 있는데 JSON 구조는 이런 문제들을 사전에 막을 수 있다. 데이터 공간을 절약할 수 있다.\n컬럼을 동적으로 정의하여, 필요한 데이터만 넣게 되어 데이터 공간 및 CPU 사용량, 네트워크 트래픽도 줄일 수 이쓴 효과를 볼 수 있다. 검색능력(Searching) 기본적인 검색 기능 뿐만 아니라 특히 Full-text 검색 능력이라는 강력한 기능을 탑재하고 있다.\n관계형 데이터베이스의 문자열 컬럼에 대해 실행되는 단순한 SQL 질의와는 다르다.\n기본적으로 엘라스틱은 검색을 할 수 있는 Term(의미의 최소한위)로 단어의 형태소 분석을 수행하고, 이 단어들과 연관된 문서를 매핑하여 검색을 시켜주는 개념으로 문서를 통쨰로 like 검색하는 DB와는 구조적으로 다르다.\n분석(Analytics) 엘라스틱 서치를 탑재하여 만든 사이트에 접속하는 사람들의 OS가 무엇인지, 어느나라에서 접속했는지 등을 알고 싶을 때 분석 기능을 사용하면 편리하게 알 수 있다.\n풍부한 API와 REST 지원 기본적으로 20개의 프로그래밍 언어를 지원하며, 기본적으로 REST API를 제공하여 REST API를 사용하는 모든 언어에서 HTTP 형식으로 사용할 수 있다.\n쉬운 작동, 쉬운 확장 Single Node Instance로 작동하며, 수백개의 스케일 아웃을 쉽게 할 수 있다. 대부분의 빅데이터 플랫폼들이 그러하듯 Horizontal Scaling을 사용한다.\nNear real-time(근접 실시간) 검색엔진은 기본적으로 형태소를 분석하고 색인을 해야 하는 시간이 다른 DBMS보다 오래 걸린다. 엘라스틱 역시 데이터를 삽입한 순간 약 몇 초 정도는 이 단계를 거친 후 검색을 할 수 있다.\nLightning-fast (빠른 속도) 엘라스틱 서치의 DNA는 루씬이기 떄문에 단어 입력후 문서를 찾는 속도가 다른 NoSQL들에 비해 매우 빠르다.\nFault-tolerant(내고장성) 노드 실패시 replicate된 다른 노드에서 데이터를 가져오며, 네트워크 실패 시 다른 마스터 복제본으로 선택한다.\n엘라스틱서치 데이터 구조 엘라스틱서치는 위와 같이 문서를 엘라스틱 인덱스로 만든 뒤, 샤드로 분리하여 보관한다.\n샤드는 논리적/물리적으로 분할 된 인덱스인데, 각각의 엘라스틱서치 샤드는 루씬 인덱스이기도 하다.\n루씬은 새로운 문서를 엘라스틱서치 인덱스에 저장할 때 \u0026ldquo;세그먼트\u0026quot;를 생성하는데, 루씬의 인덱스 조각인 이 세그먼트를 조합해 저장한 데이터의 검색을 할 수 있다.\n색인 처리량이 매우 중요할 때는 세그먼트를 더 생성하기도 한다. 루씬은 순차적으로 세그먼트를 검색하므로 세그먼트 수가 많아지면 검색속도도 따라서 느려지게 된다.\n엘라스틱서치 데이터 설명 인덱스(색인) 데이터를 저장 및 색인 하는 곳으로, 관계형 DB의 데이터베이스 개념과 유사하다.\n실제로는 각 샤드를 가리키고 있는 논리적인 네임스페이스 Shard 샤드는 엘라스틱서치에서 사용하는 검색 엔진인 루씬의 인스턴스.\n인덱스를 한 개의 샤드로 구성할 수도 있지만, 인덱스 사이즈가 증가할 경우 여러개의 물리서버에 나누어 보관하기 위해 보통은 여러개의 샤드로 구성함. Segment 각 샤드는 다수의 세그먼트를 가지고 있고, 샤드에서 검색 시, 먼저 각 세그먼트를 검색하여 결과를 조합한 최종 결과를 해당 샤드의 결과로 리턴하게 된다.\nsearchable\n엘라스틱서치에 데이터(문서)를 저장하면, 엘라스틱서치는 이것을 메모리에 모아두고 새로운 세그먼트를 디스크에 기록하여 검색을 리프레시함. 이로 인해 새로운 검색 가능한 세그먼트가 만들어지게 된다.\ncommited\n그러나 세그먼트가 fsync되지 않았으므로 여전히 데이터 손실의 위험이 남아있다. 그래서 엘라스틱서치는 세그먼트를 fsync하는 \u0026ldquo;flush\u0026quot;를 주기적으로 진행하고, 불필요한 트랜젝션 로그를 비운다.\nmerge process\n세그먼트는 불변임, 데이터(document)가 업데이트되면 실제로는 그저 삭제되었다고 마크하고 새로운 데이터(document)를 가리킬 뿐이다. 이러한 오래된 삭제된 데이터를 지우는 것\n엘라스틱서치 클러스터 구조 위 다이어그램은 3개의 엘라스틱서치 인스턴스 환경에서, 4개의 샤드를 2개의 복제본으로 구성했을 때의 구조이다.\n엘라스틱서치는 클러스터 구조로 구성되어 있으며 샤드와 복제본의 수를 설정해두면 스스로 각 노드에 샤드를 분배하여 장애발생 시 데이터 손실을 최소화한다.\n프라이머리 샤드가 손실되었을 경우에는 레플리카를 프라이머리로 승격시켜 데이터 손실을 방지한다.\n","date":"2023-04-18T14:13:19+09:00","image":"https://codemario318.github.io/post/elasticsearch/elasticsearch_cover_hu19466caf2459bbcd9b4d95bc6d53e495_16781_120x120_fill_box_smart1_3.png","permalink":"https://codemario318.github.io/post/elasticsearch/","title":"Elasticsearch"},{"content":" 검색 엔진은 컴퓨터 시스템에 저장된 정보를 찾아주는 것을 도와주도록 설계된 정보 검색 시스템이다. 검색 엔진을 사용하여정보를 찾는데 필요한 시간을 최소화할 수 있다.\n웹 검색 엔진 웹 사이트를 검색하기 위한 프로그램이다.\nFTP 서버나 웹 사이트의 파일 검색 결과를 포함하며, 이미지나 토렌트 파일 또는 특정 부류의 웹 사이트에 특화된 웹 검색 엔진도 있다.\n서버에서는 \u0026lsquo;로봇\u0026rsquo;이라 불리는 특별한 프로그램을 이용하 웹 사이트들을 돌아다니며 웹 사이트들에 대한 정보를 미리 자동적으로 수집한다. 이휴 검색 엔진 사이트에서 특정 검색어를 입력하면 검색 엔진이 수집한 정보 중 그에 맞는 결과를 볼 수 있다.\n로봇이 참조와 어휘를 분헉하는 방식에 따라 검색 품질이 결정됨 원리 검색 엔진은 사용자가 검색 엔진을 사용하기 전에 미리 웹 상에서 정보를 수집하여 색인을 만들어 놓는다. 그리고 나서 사용자가 찾고자 하는 정보의 키워드를 입력하면, 미리 만들어 놓은 색인 중에서 입력된 키워드에 해당하는 정보들을 찾아서 보여준다.\n문서 수집 현재 대부분의 검색 엔진에서는 엡상의 방대한 정보들을 검색하고 색인화 하는 과정을 크롤러라고 부르는 정보 수집 프로그램을 사용하여 수행하고 있다.\n크롤러가 주기적으로 웹에 접속된 사이트들을 방문하여 해당 웹 사이트가 가지고 있는 정보에 대해 색인을 작성한 후 그것을 데이터베이스에 저장하여 검색시 활용하게된다.\n크롤러\n웹상의 문서나 이미지, 영상 등을 주기적으로 검색하고 취합하여, 자동으로 데이터베이스화 시키는 프로그램으로 봇(Bot)이라고도 부른다.\n검색 엔진의 종류 수집한 정보를 색인하는 방법에 따라 구분된다.\n로봇 검색 엔진 크롤라라고 불리는 로봇을 이용하여 웹상의 데이터를 효율적으로 수집하고, 이렇게 수집한 데이터 키워드 색인을 통해 사용자에게 제공하는 검색 엔진\nGoogle, Naver등 현재 사용되는 대부분의 검색 엔진이 이 방식을 채택하고 있다. 디렉토리 검색 엔진 주제 분류에 의한 검색을 제공하는 검색 엔진이며, 데이터의 분류를 사람이 직접 슈행해야 한다.\n현재 주류인 방식은 아니며, 1990년대 Yahoo등에서 사용되었음 메타 검색 엔진 자체적으로 정보를 보유하고 있지 않으면서 사용자가 입력한 키워드를 복수의 다른 검색 엔진으로 전송하여 결과를 얻고, 그 결과들을 종합하여 표시만 해주는 검색 엔진\n여러 검색 엔진의 결과를 동시에 보여주기 때문에 결과를 한눈에 살펴보기에는 편하지만, 메타 검색이라는 과정을 한 번 더 거쳐야 하므로 속도가 느를 수 있다.\n검색 엔진 최적화(Search Engine Optimization, SEO) 검색 결과의 상위에 자신의 웹 페이지가 노출되기 위해 검색 엔진이 자료를 수집하고 결과를 산출하는 방식에 맞춰 웹 페이지의 구성을 조정하는 것을 의미한다.\n각각의 검색 엔진에 맞처 웹 페이지 내의 키워드나 링크 등을 최적화 하는 작업을 SEO라고 한다.\n","date":"2023-04-18T14:04:15+09:00","image":"https://codemario318.github.io/post/search_engine/search_engine_cover_hu920de5c22e59a77d3210239e6515a52e_9451_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/search_engine/","title":"검색 엔진"},{"content":"용어정리 MOM (Message Oriented Middleware, 메시지 지향 미들웨어) 독립된 어플리케이션 간에 데이터를 주고받을 수 있도록 하는 시스템 디자인 함수 호출, 공유메모리 등이 방식이 아닌, 메시지 교환을 이용하는 중간 계층에 대한 인프라 아키텍쳐 개념 분산 컴퓨팅이 가능해지며, 서비스간의 결합성이 낮아짐 지동기로 메시지를 전달하는 것이 특징 Queue, Broadcast, Multicast 등의 방식으로 메시지 전달 Pub/Sub 구조 메시지를 발행하는 Publisher(Producer), 메시지를 소비하는 Subscribe(Consumer)로 구성 Message Broker 메시지처리 또는 메시지 수신자에게 메시지를 전달하는 시스템이며, 일반적으로 MOM 기반으로 구축됨 MQ (Message Queue, 메시지 큐) Message bBroker와 MOM을 구현한 소프트웨어 (RabbitMQ, ActiveMQ, Kafka 등) MOM은 메시지 전송 보장을 해야하므로 AMQP를 구현함 AMQP (Advanced Message Queueing Protocol) 메시지를 안정적으로 주고박기 위한 인터넷 프로토콜 RabbitMQ, Kafka 등은 AMQP를 구현한 MOM 시스템이다.\n메시징 시스템이란? 로그 데이터, 이벤트 메시지 등 API로 호출할 떄 보내는 데이터들을 처리하는 시스템\n예를 들어, 다음과 같이 자동 메일을 발송 시스템이 있다고 가정하면,\n회원가입을 했을 때, 이메일을 발송하는 MemberService 주문완료가 되었을 때, 이메일을 발송하는 OrderService 메일을 실제 발송하는 MailService 이렇게 서비스가 분리되었을 때 프로세스는 다음과 같이 처리될 수 있다.\nMemberService에서 회원가입, OrderService에서 주문완료 이벤트가 발생 Messaging Client로 메일 전송에 필요한 데이터( 받는/보내는 사람 이메일 주소, 메시지 제목/내용 등.. )를 API 호출 Messaging Client에서 MOM을 구현한 소프트웨어(ex. kafka)로 메시지를 생산 MailService에서 메시지가 존재하는지 구독하고 있다가 메시지가 존재하면 메시지를 소비 MailService에서 API 정보들을 통해 User에게 메일 발송 장점 서비스간의 결합성이 낮아지므로 각자의 비즈니스 로직에만 집중할 수 있다. 메시지 처리 방식은 Message Broker에 위임 각 서비스는 Client를 통해 메시지를 보내고 받기만 하면 됨 각 서비스는 비동기 방식으로 메시지를 보내기만 하면, Message Broker에서 순서 보장, 메시지 전송 보장 등을 처리 메시징 시스템이 잠깐 다운되어도 각 서비스에는 직접적인 영향을 미치지 않음 단점 Message Broker 구축, 예를 들면 kafka 클러스터 구축에 필요한 금전, 인적 자원에 대한 비용 비동기의 양면성 - 정말 메시지가 잘 전달되었는가? 함수호출, 공유 메모리 사용 방식보다 메시징 시스템을 사용했을 때 호출 구간이 늘어나므로 네트워크 비용 발생 MOM, 메세지 지향 미들웨어(Message-Oriented-Middleware) 미들웨어: 어플리케이션들을 연결해 이들이 서로 데이터를 교환할 수 있게 해주는 소프트웨어 메시지 지향(=메시징 시스템): 메시지 API를 통해 각 분산되어 있는 어플리케이션간의 다리 역할을 함으로써 데이터를 교환 할 수 있도록 하는 시스템 메시지 지향 미들웨어란? 메시지를 통해 여러 분산되어 있는 시스템 간의 Connector 역할로 결합성을 낮추고, 이들이 서로 실시간 비동기식 데이터를 교환할 수 있도록 하는 소프트웨어\nMessage Queue 기반 패턴 메시지 대기열 패턴은 일종의 지점 간(peer to peer) 메시징 시스템이다. Queue 대기열의 메시지는 Consumer가 소비하면 지워지는 형태\n소비하면 지워지는 형태라는 의미는 Producer 서버가 메시지를 Queue에 보내고 서버가 다운이 되도 Consumer가 소비하지 않았다면 Queue 대기열에 데이터가 존재한다는 걸 의미한다.\n발행(Publish)-구독(Subscribe) 메시지 패턴 메시지 큐와 마찬가지로 메시지를 생산하는 Producer와 메시지를 소비하는 Consumer로 구성되어 있다.\n차이점은 여러 소비자가 하나의 주제에서 각 메시지를 수신할 수 있다는 점. 또한 모든 Consumer가 메시지를 사용하는 경우에만 메시지가 대기열에서 지워진다.\nkafka와 같은 메시징 시스템에는 메시지가 대기열에 있어야 하는 기간을 지정한 보존 정책이 있다. 따라서 메시지는 모든 Consumer가 소비하더라도 지정된 기간 동안 대기열에 사용할 수 있다.\n언제 쓰이는가? 분산 시스템 여러 컴퓨터를 분산시켜 네트워크를 연결하여 데이터들을 나눠서 처리하면 서버의 과부하를 분산할 수 있으며, 성는개선과 장애요소를 최소화하기 위해 분산 시스템을 사용함 과거 분산 시스템의 단점과 웹 API 통신의 한계 과거 분산시스템의 단점 수많은 데이터를 처리하기 위하여 분산 시스템을 운영하였지만, 시스템이 거대해질수록 분산 시스템의 설계도의 복잡성 문제가 발생한다. 하나의 응용프로그램이 변경되면, 다른 응용프로그램에도 영향을 미쳐 분산 시스템 간의 결합도가 강한 단점을 가지고 있었다.\n웹 API 통신의 특성 MSA를 사용한 분산 시스템은 웹 API 서버로 요청 시 응답을 기다려야 한다. 여러 분산되어있는 서비스 간에는 실시간으로 비동기식으로 데이터를 처리해야 하기 떄문에 웹 API로도 비동기식 구현이 가능하지만 순서가 보장되지 않는다는 특성이 있다. 메시지를 보내는 A어플리케이션은 메시지를 보낼 때 B라는 어플리케이션의 목적지(도착점)을 알아야 통신할 수 있다. 두 어플리케이션간 불필요한 결합도가 발생되고, 응답을 취하는 B어플리케이션이 서버 장애시 요청되었던 데이터 때문에 A어플리케이션에게도 장애가 전파될 수 있다. 메시징 지향 미들웨어의 필요성 메시지 API는 비동기 프로토콜을 지원하며, 메시지 순서를 보장합니다. 메시지가 대기열에 전달되면, 응답을 즉시 할 필요가 없다. 메시지 대기열에 전달 된 상황이라면 메시지는 시스템에 보존되어 있어, 다른 어플리케이션간의 의존성이 낮게 된다. Message Broker 송신자와 수신자 사이에서 메시지의 전달을 중재하는 컴퓨터 프로그램 모듈\n메시지 브로커는 정형화된 메시지의 교환을 통해 어플리케이션간의 소통이 이뤚디는 네트워크 엘리먼드이다.\n목적 메시지의 유효성, 정송, 라우팅을 위한 아키텍처 패턴\n어플리케이션 사이의 커뮤니케이션 중재 어플리케이션간의 메시지 전달을 위한 상호 인식(mutal awareness)를 줄여 어플리케이션간의 결합성을 낮춘다(decoupling) 기능 엔드 포인트 분리 NFR(non-functional requirement) 충조 중재함수 (intermediary function)의 간편한 재사용 하나이상의 목적지로의 메시지 라우팅 메시지의 형태 변형 메시지를 수집하여 여러 메시지로 분해하고 대상으로 보내 응답을 하나의 메시지로 재구성하여 사용자에게 반환 메시지 양 증가 또는 저장을 위한 외부 저장소와 상호작용 데이터 검색을 위한 웹 서비스 호출 이벤트 또는 에러의 응담 발행-구독 패턴을 활용한 컨텐츠와 토픽 기반 메시지 라우팅 제공 설계 허브 앤 스포크(hub and spoke)\n중앙 서버가 통합 서비스를 제공하는 메커니즘으로 작동 메시지 버스(message bus)\n메시지 브로커가 버스에서 작동하는 통신 백본 또는 분산 서비스 ","date":"2023-04-17T19:42:33+09:00","image":"https://codemario318.github.io/post/messaging_system/messaging_cover_huc80ec853f6ab161a17ff43aa6052ff01_60754_120x120_fill_box_smart1_3.png","permalink":"https://codemario318.github.io/post/messaging_system/","title":"메시징 시스템이란?"},{"content":"Not Only SQL: SQL만을 사용하지 않는 데이터베이스 관리 시스템을 지칭하는 단어. \u0026lsquo;데이터를 저장하는 데에는 SQL 외에 다른 방법들도 있다.\u0026rsquo;\n정의 NoSQL에 내려진 구체적인 정의는 없으나 공통적인 성향을 가지고 있다.\n대부분 클러스터에서 실행할 목적으로 만들어졌기 때문에 관계형 모델을 사용하지 않는다. 오픈 소스이다. 스키마 없이 동작하며, 구조에 대한 정의를 변경할 필요 없이 데이터베이스 레코드에 자유롭게 필드를 추가할 수 있다. 21세기 초반에 개발 된 SQL을 사용하지 않는 Schema-less 데이터베이스\n클러스터\n저렴한 상용 제품 여러 대를 조합하여 더 빠르고 안정적인 시스템을 목표로 만들어진 방법\n등장배경 여러 대의 컴퓨터에 데이터를 분산 저장하는 것을 목표로 등장했다.\n기존에는 안정적인 데이터 관리가 가장 중요했기 때문에, 트랙잭션을 통한 관리가 가능한 RDBMS가 많이 이용되었지만 웹 2.0 환경과 빅데이터가 등장하면서 RDBMS는 데이터와 트래픽 양이 기하급수적으로 증가함에 따라 한 대에서 실행되도록 설계된 RDBMS를 사용하는 데 필요한 비용 증가 이슈가 생겨났다.\nNoSQL은 데이터의 일관성을 약간 포기한 대신 여러 대의 컴퓨터에 데이터를 분산하여 저장하는 것을 목표로 등장하였고, NoSQL의 등장으로 작고 값싼 장비 여러 대로 대량의 데이터와 컴퓨팅 부하를 처리하는 것이 가능하게 되었다.\n특징 일관성과 확장성 사이의 Trade-off\n일관성이 데이터베이스의 절대적인 요소가 아님을 주장하는 움직임이 생기기 시작했다. 다수가 동시에 읽고 쓰는 상황에서의 성능 향상을 위해서. 분산 환경에서 노드들이 잘 작동하고 있음에도, 시스템의 일부가 고장나면 데이터베이스를 사용할 수 없게 되는 문제를 해결하기 위해서. 분산 저장\n데이터와 트래픽이 증가함에 따라 기존의 장비로는 원할한 데이터의 처리가 어려워졌다. 이를 해결하기 위한 방법으로 장비의 성능을 키우는 수직적 확장과 처리하는 장비 수를 늘리는 수평적 확장이 있다. 수직적 확장은 큰 비용적인 문제가 발생하므로 수평적 확장을 고려했지만, RDBMS가 클러스터 상에서 효율적으로 동작하도록 설계되지 않았다. 샤딩(Sharding)\n샤드키를 기준으로 하나의 테이블을 수평 분할하여 서로 다른 클러스터에 분산 저장하고 질의할 수 있는 기법. RDBMS에서도 사용 가능하지만 어플리케이션 레벨에서 모든 샤딩을 제어해야 한다.(어떤 데이터를 어느 클러스터에서 처리해야 하는지 등) 또한 여러 샤드에 걸치는 쿼리나 참조 정합성, 트랜잭션, 일관성 문제가 발생할 수 있다. 분산 저장을 지원하는 NoSQL 데이터베이스의 경후, 집합-지향(Aggregtae-oriented) 모델을 사용하여 이러한 문제를 해결한다. 연관된 데이터들이 함께 분산되므로, 관계형 모델에서처럼 복잡한 제어가 필요하지 않게 된다. 데이터 일치\nRDBMS에서 관계형 튜플 안의 값은 단순해야 하며 중첩된 레코드나 리스트 등 다른 구조를 포함할 수 없느 반면, 메모리 내 데이터 구조에서는 이런 제약이 없어 훨씬 복잡한 구조를 사용한다.(리스트, 딕셔너리, 중첩된 객체 구조) 그 결과 복잡한 메모리내 데이터 구조를 데이터베이스에 저장하려면 먼저 관계형 표현으로 변환해야 한다. (ORM 프레임워크등을 이용) NoSQL은 메모리 내의 데이터가 어떤 구조이든지 상관하지 않고 하나의 Aggregation으로 취급하여 저장하기 때문에 자유롭다. Impedance mismatch\n관계형 모델과 메모리 내 데이터 구조 간의 불일치\nSchema-less\nNoSQL 데이터베이스의 공통적인 특징은 스키마 없이 동작한다는 점이다. 장점 데이터 구조를 미리 정의할 필요가 없다. 시간이 지나더라도 언제든지 바꿀 수 있기 때문에 비형식적인 데이터를 저장하는 데 용이하다. 단점 단일 값에 대한 데이터 타입에서 불일치가 발생할 수 있다. 데이터베이스가 스키마를 직접 관리하지 않는 것을 의미할 뿐, 데이터 타입에 따른 암묵적인 스키마는 여전히 존재하기 때문 종류 네 가지 모델로 나눌 수 있다.\nkey-value Document Column-family Graph 이 중 그래프 모델을 제외한 나머지 세 모델은 집합-지향(Aggregate-orented)모델이다.\n집합-지향 (Agregate-orented) 모델 집합 지향 데이터베이스는 집합 자료구조로 이루어져 있다.\n집합\n연산의 한 단위로 취급되는 연관된 객체들의 집합.\n관계형 모델처람 하나의 엔티티에 대한 ACID 트랜잭션을 지원하지는 않지만, 하나의 집합에 대한 연산에서는 트랜잭션을 지원한다.\n장점\n집합 지향 데이터베이스는 여러 대의 클러스터로 이루어진 시스템에서 사용하기 적합하다. 수평적 확장이 용이하다. 이는 관계형 데이터베이스와는 달리 연관된 데이터들이 함께 움직이기 떄문이다. 메모리 내의 자료구조와 집합 간 데이터가 잘 일치하므로, 관계형 데이터베이스처럼 객체-관계 매핑 프레임워크가 필요하지 않다. 데이터의 검색도 아주 쉬운편으로, key나 ID를 사용하면 쉽게 집합 레코드를 찾아낼 수 있다. 단점\n집합 지향 데이터베이스는 조인 연산이 불가능 MongoDB나 Cassandra등의 데이터베이스에서는 맵리듀스(MapReduce) 기능을 제공함으로써 조인과 유사한 연산을 가능하도록 설계했지만 사용법이 어렵고 Hadoop의 맵 리듀스에 비하면 속도도 매우 느리다. Key-Value 키 값 저장소는 가장 단순한 형태의 NoSQL\n장점\n수평적 확장이 용이하다. 아주 간단한 API만을 제공하기 떄문에 배우는 것이 어렵지 않다. 간단한 API를 제공하는 만큼 질의의 속도가 굉장히 빠른편 어떠한 형태의 데이터라도 담을 수 있다. 이미지나 비디오도 가능 단점\n값의 내용을 사용한 쿼리가 불가능하다. 키를 사용해 값을 읽어들인 뒤, 어플리케이션 레벨에서 적절히 처리해야 한다. Document 데이터가 키와 문서 형태로 저장되는 키-값 모델의 개선 형태\n키-값 모델과의 차이점\nValue가 계층적인 형태인 도큐먼트로 저장된다. 객체지향의 객체와 유사하며, 하나의 단위로 취급되어 저장된다.\n장점\n하나의 객체를 여러 테이블에 나눠 저장할 필요가 없다. 도큐먼트 내의 item을 이용한 쿼리가 가능하다. 단, Xquery나 다른 도큐먼트 질의 언어가 필요 객체-관계 매핑이 필요하지 않다. 객체를 도큐먼트의 형태로 바로 저장 가능하기 떄문 검색에 최적화 되어있다. 단점\n사용이 번거롭고 쿼리가 SQL과 다르다. 질의의 결과가 JSON이나 XML 형태로 출력되기 때문에 사용방법이 RDBMS와 다르다. 질의 언어가 SQL과 다르기 떄문에 사용에 익숙해지기까지 다소 어려움이 있을 수 있음. 종류 MongoDB 도큐먼트 지향 데이터 베이스이다.\nbson 데이터 구조로 저장 문서를 기본 저장 단위로 이용하면서 내장 문서와 배열을 이용하여 복잡한 계층구조를 하나의 레코드로 표현한다. 스키마가 없다. 필드 추가 제거는 자유로우며 필요할 때 마다 자유자재로 변경 가능하다. RDBMS 보다 매우 빠르다. 조인과 트랜잭션을 지원하지 않으며 여러 제약조건에 대한 처리도 없다. →버전에 따라 다름 Redis(REmote DIctionary Server) 메모리 기반의 \u0026ldquo;Key-Value\u0026rdquo; 구조 데이터 관리 시스템이며, 모든 데이터를 메모리에 저장하고 조회하기에 빠른 Read, Write 속도를 보장하는 비 관계형 데이터베이스이다.\nString, set, Sorted Set, Hash, List 데이터 형식을 지원한다. Redis는 빠른 오픈 소스인 메모리 키-값 데이터 구조 스토어이며, 다양한 인메모리 데이터 구조 집합을 제공하므로 사용자 정의 어플리케이션을 손쉽게 생성 할 수 있다.\n특징 영속성을 지원하는 인메모리 데이터 저장소\n읽기 성능 증대를 위한 서버측 복제 지원\nRedis가 실행중인 서버가 충돌하는 경우 장애 조치 처리와 함께 더 높은 읽기 성능을 지원하기 위해 슬레이브가 마스터에 연결하고 전체 데이터베이스의 초기 복사본을 받는 마스터/ 슬레이브 복제를 지원. 마스터에서 쓰기가 수행되면 슬레이브 데이터 세트를 실시간으로 업데이트 하기 위해 연결된 모든 슬레이브로 전송됨 쓰기 성능 증대를 위한 클라이언트\n","date":"2023-04-17T19:24:48+09:00","image":"https://codemario318.github.io/post/nosql/nosql_cover_hu705a0f96b7606376fe264778ca77daa9_6424_120x120_fill_box_smart1_3.png","permalink":"https://codemario318.github.io/post/nosql/","title":"NoSQL이란?"},{"content":"Apache 아파치는 클라이언트 요청을 받으면 MPM(Multi Processing Module : 다중처리모듈) 방식으로 처리한다.\n스레드/프로세스 기반 구조 동작 ServerSocket으로 request A가 들어오면 Thread를 할당해준다. Thread는 해당 socket을 가지고 read, write작업 등을 수행한다. 수행 도중 ServerSocket으로 request B가 들어오면, context switching이 일어난다. 새로 들어온 요청에 쓰레드를 배분하고, 또 해당 소켓을 가지고 작업을 수행한다. 아직 마무리되지 않은 A를 처리하기 위해 일정 기간마다 지속적으로 context switching을 반복하고 모든 작업을 마무리 한다. Prefork MPM 실행중인 프로세스를 복제하여 처리하는 방식\n각 프로세스는 한번에 한 연결만 처리하고, 요청량이 많아질수록 프로세스를 복제하여 동작한다.\n프로세스를 복제하는 방식이기 떄문에 메모리가 많이 소비된다\n연결 수 = 프로세스 수\nWorker MPM Prefork 방식은 한개의 프로세스가 한개의 스레드로 처리되지만, Worker 방식은 한개의 프로세스가 여러 쓰레드를 사용하여 처리한다.\n쓰레드를 사용하기 떄문에 Prefork 방식보다 메모리 소모가 적고, 통신량이 많을 때 유리하다.\n문제점 아파치는 접속마다 프로세스 또는 쓰레드를 생성하는 구조이다.\n동시 접속 요청이 많을수록 그만큰 생성 비용이 들고 대용양 요청을 처리할 수 있는 웹 서버로서 한계가 나타난다.\nNginx 한개 또는 고정된 프로세스만 생성하고, 프로세스 내부에서 비동기 방식으로 작업을 처리한다. 따라서 동시 접속 요청이 많아도 프로세스 또는 쓰레드 생성 비용이 존재하지 않는다.\nEvent-Driven 방식 Event-Driven 방식은 Reactor pattern을 사용한다.\nReactor는 이벤트가 들어오면 알맞는 handler로 dispatch 해준다. Handler는 dispatch된 이벤트를 받아서 처리하는 역할을 수행 Reactor pattern\n이벤트 처리(event handling)디자인 패턴으로 하나의 Reactor가 계속 이벤트를 찾고 이벤트가 발생(trigger)하면 해당 이벤트 처리기(event handler)에게 알린다.\nNginx와 Apache의 차이점 컨텐츠의처리 방식 정적 컨텐츠 처리\nApache: 전통적인 파일기반 방식의 정적 컨텐츠 Nginx: 이벤트 처리/비동기식/논블로킹 방식 처리로 인해 정적 컨텐츠 제공시 고속 처리 가능 동적 컨텐츠 처리\nApache: 서버 내에서 처리 기본적으로 유연성과 범용성을 갖추는 방식으로 서버 자체에서 동적 컨텐츠 처리가 가능하다. Nginx: 동적 컨텐츠를 처리하지 않음 동적 웹 페이지 컨텐츠를 가진 모든 요청을 위해 외부 자원과 연계한다. 따라서 최종적으로 동적 컨텐츠가 다시 돌아올 때까지 기다렸다가 클라이언트에게 전달하는 방식을 가지고 있다. OS 지원에 대한 범용성 Apache: 리눅스, BSD, UNIX, WINDOW 역사가 있는 만큼 지원 범위가 다양하기 때문에 일관성 있는 웹 서비스 아키텍쳐를 구현할 수 있다. Nginx: LINUX, BSD, UNIX, WIN(부분 지원) 다양한 운영체제를 지원하지만 아파치 만큼 완벽히 지원하지 않는다. 분산/중앙집중식 구성 방식 Apache: 분산/중앙집중식 구성 채택 .htaccess를 통해 디렉토리별로 추가 구성을 할 수 있다. 단일 기반 뿐만 아니라 분산형 구칙이 가능하므로 대용량 서버 아키텍쳐에서 자원만 충분하다면 여러 웹 서비스를 구현 할 수 있다. Nginx: 중앙집중식 구성 채택 아파치처럼 .htaccess를 지원하지 않는다. 따라서 추가 구성을 할 수 없는 단점이 있다. 하지만 이러한 방식은 가상화, 클라우드, MSA와 같은 아키텍쳐에서는 오히려 경량화와 성능 보장이라는 측면에서 단점이 되지 않을 수도 있다. 모듈 및 확장성/보안 Apache 60개 이상의 다양한 기능과 모듈을 지원하며, 필요에 따라 활성화 또는 비활성 시킬 수 있다. 동적 모듈을 통해 웹 서버의 사용자 지정도 가능하게 할 수 있는 등 다양한 디자인과 확장이 가능하다. 보안을 위해 다양한 Web기반 DDoS 방어 기술을 제공한다. Nginx 다른 코어 모듈을 동적으로 로딩할 수 없도록 되어있다. 옵션을 최소화 해서 태생 부터 성능에 포커싱 했다. 보안에 대한 다양한 기술 문서를 제공하며, 코드 자체가 가볍고 경량화 되어 있어서 보안에 유리한 측면도 있다.https://youngmind.tistory.com/entry/Apache-vs-Nginx ","date":"2023-04-17T19:10:21+09:00","image":"https://codemario318.github.io/post/nginx_vs_apache/web_cover_hu71ff0ea2f7ce80fa0f2ad0c2fcb44a04_52909_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/nginx_vs_apache/","title":"Nginx VS Apache"},{"content":"웹 동작 방식 클라이언트(브라우저)가 HTTP(URL)을 통해 요청을 보내면 HTML, CSS, 이미지와 같은 정적 콘텐츠를 응답으로 보내게 되고 그것을 받은 클라이언트가 해석하여 페이지로 보여준다.\nStatic pages와 Dynamic Pages Static Pages Web Server는 파일 경로의 이름을 받아 경로와 일치하는 file contents를 반환 항상 동일한 페이지를 반환 Ex) image, html, css, javascript 파일과 같이 컴퓨터에 저장되어 있는 파일들 Dynamic Pages 인자의 내용에 맞게 동적인 Contents를 반환 웹 서버에 의해서 실행되는 프로그램을 통해서 만들어진 결과물(WAS)위에서 돌아가는 프로그램 Web Server와 WAS의 차이 Web Server 소프트웨어와 하드웨어로 구분된다.\n하드웨어 Web 서버가 설치되어 있는 컴퓨터 소프트웨어 웹 브라우저 클라이언트로 부터 HTTP 요청을 받아 정적인 컨텐츠(.html, .jpeg, .css 등)을 제공하는 컴퓨터 프로그램 Web Server의 역할 HTTP 프로토콜을 기반으로 하여 클라이언트의 요청을 서비스 하는 기능 담당\n요청에 따라 두 가지 기능 중 적절하게 선택하여 수행\n정적인 컨텐츠 제공 WAS를 거치지 않고 바로 자원을 제공한다 동적인 컨텐츠 제공을 위한 요청 전달 클라이언트의 요청을 WAS에 보내고, WAS가 처리한 결과를 클라이언트에게 전달한다. Web Server의 예 Apache Server Nginx IIS 등 WAS(Web Application Server) DB 조회나 다양한 로직 처리를 요구하는 동적인 컨텐츠를 제공하기위해 만들어진 Application Server\nHTTP를 통해 컴퓨터나 장치에 어플리케이션을 수행해주는 미들웨어이다.\n웹 컨테이너(Web Container), 서블릿 컨테이너(Servlet Container)라고도 불림\nWAS의 역할 WAS = Web Server + Web Container\n웹서버 기능들을 구조적으로 분리하여 처리하고자하는 목적으로 제시됨\n분산 트랜잭션 보안 메시징 쓰레드 처리 등 DB와 서버와 같이 수행됨\nWAS의 주요 기능 프로그램 실행 환경과 DB 접속 기능 제공 여러 개의 트랜잭션 관리 기능 업무를 처리하는 비지니스 로직 수행 WAS가 필요한 이유 웹 페이지는 정적 컨텐츠와 동적 컨텐츠가 모두 존재한다.\n사용자의 요청에 맞게 적절한 동적 컨텐츠를 만들어서 제공해야 한다. 웹 서버만을 이용하게 되면 그에 맞는 결과가 정적 파일로 존재해야 한다. 따라서 WAS를 통해 요청에 맞는 데이터를 DB에서 가져와 비즈니스 로직에 맞게 결과를 만들어 제공함으로 자원을 효율적으로 사용할 수 있다.\nWAS와 Web Server를 분리하는 이유 기능 분리를 통한 서버 부하 방지\nWAS만으로도 웹서비스를 제공 가능하지만 WAS는 DB조회 등 동적인 웹 페이지를 위한 다양한 동작을 하기 때문에 바쁘다. 따라서 웹 서버를 통해 정적인 컨텐츠를 제공하여 부하를 방지한다.\n물리적으로 분리하여 보안 강화\nSSL에 대한 암복호화 처리에 웹서버를 사용한다.\n여러대의 WAS를 연결 가능\nLoad Balancing을 위해 Web Server를 사용 가능하다\nfail over(장애 극복), fail back 처리에 유리 여러대의 서버를 사용하는 대용량 웹 어플리케이션의 경우 웹 서버와 WAS를 분리하여 무중단 운영을 위한 장애 극복에 쉽게 대응할 수 있다. 여러 웹 어플리케이션 서비스 가능\n하나의 웹 서버로 다양한 WAS를 이용하게 만들 수 있다. ","date":"2023-04-17T18:28:10+09:00","image":"https://codemario318.github.io/post/web/web_cover_hu71ff0ea2f7ce80fa0f2ad0c2fcb44a04_52909_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/web/","title":"Web"},{"content":"클로저는 두개의 함수로 만들어진 환경으로 이루어진 특별한 객체의 한 종류이다. 여기서 환경이라 함은 클로저가 생성될 때 그 범위에 있던 여러 지역 변수들이 포함 된 context를 말한다. 이러한 범위는 자바스크립트 코드를 실행하기 위해 발생하는 컴파일 단계에서 결정된다.\n클로저를 통해서 자바스크립트에는 없는 비공개 속성/메소드, 공개 속성/메소드 처럼 구현 할 수 있다.\nLexical Scope 자바스크립트 코드를 실행할 때 컴파일 단계에서 몇가지 일이 일어난다. 그중 하나인 토크나이징과 렉싱이 있다.\n토크나이징 문자열을 나누어 토큰으로 만드는 과정\n1 var num = 5; 위와 같은 구문을 만나게 되면, 아래와 같은 토큰으로 나눈다.\n1 2 3 4 5 var num = 5 ; 렉스타임 토크나이징의 결과물인 토큰을 분석하여 생성된 토큰에 의미를 부여하는 것을 렉싱이라고 하며, 이 과정을 렉스타임이라고 한다.\n렉시컬 스코프 개발자가 코드를 작성할때 변수를 어디에 작성하는가를 바탕으로 렉스타임에 토큰이 분석되며 스코프가 결정된다. 이때 구성된 유효 범위를 렉스컬 스코프라고 한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 var a = 10; function foo() { var b = 20; function bar() { var c = 30; colsole.log(a + b + c); // 60 } bar(); } foo(); 위의 코드가 실행될때 스코프 버블은 bar 안쪽에서 부터 시작되어 올라간다.\n코드를 해석하는 과정에서 상위에서 하위로 쌓이는 구조로 해석되기 때문에, scope에 대한 검색은 기본적으로 하위에서 상위는 되지만 상위에서 하위로의 검색은 불가능하다.\n1 2 3 4 5 6 7 8 9 var a = 10; function foo () { var b = 20; console.log(a); // 10 console.log(b); // 20 } console.log(b); // error 정리 컴파일레이션의 렉싱 단계에서 모든 변수들이 어디서 어떻게 선언되었는지 바탕으로 실행 단계에서 스코프를 구성하고, 이렇게 구성되는 스코프가 렉시컬스코프이다.\n클로저 생성하기 내부 함수가 익명 함수로 되어 외부 함수의 반환값으로 사용된다. 내부 함수는 외부 함수의 실행 환경에서 실행된다. 내부 함수에서 사용되는 변수는 외부 함수의 변수 스코프에 있다. 1 2 3 4 5 6 7 8 9 10 11 12 function outer() { var name = `closure`; function inner() { console.log(name); } inner(); } outer(); // console\u0026gt; closure outer함수를 실행시키는 context에는 name이라는 변수가 존재하지 않지만, inner함수가 outer 함수 내부에 선언된 name을 참조하기 때문에, name 변수에 대한 정보를 알 수 없는 outer 변수 외부환경에서도 정상 출력된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 var name = `Warning`; function outer() { var name = `closure`; return function inner() { console.log(name); }; } var callFunc = outer(); callFunc(); // console\u0026gt; closure 위 코드에서 callFunc 를 클로저라고 한다. callFunc 호출에 의해 name 이라는 값이 console에 출력되는데, \u0026ldquo;Warning\u0026ldquo;이 아니라 \u0026ldquo;closure\u0026ldquo;이다. 즉, outer 함수의 context 에 속해있는 변수를 참조하는 것이다. 여기서 outer 함수의 지역변수로 존재하는 name 변수를 free variable(자유변수) 라고 한다.\n이처럼 외부 함수 호출이 종료 되더라도 외부 함수의 지역 변수 및 변수 스코프 객체의 체인 관계를 유지할 수 있는 구조를 클로저라고 한다.\n","date":"2023-04-17T18:11:36+09:00","image":"https://codemario318.github.io/post/js_closure/js_cover_huc1c9a52f33db3f5dad8bb16243cf7e4e_11875_120x120_fill_box_smart1_3.png","permalink":"https://codemario318.github.io/post/js_closure/","title":"Javascript - Closure"},{"content":"Javascript에서 함수의 this 키워드는 다른 언어와 조금 다르게 동작한다. 또한 엄격 모드와 비엄격 모드에서도 일부 차이가 있다.\n대부분의 경우 this의 값은 함수를 호출한 방법에 의해 결정되는데, 실행중에는 할당으로 설정할 수 없고 함수를 호출할 때 마다 다를 수 있다.\nES5는 함수를 어떻게 호출했는지 상관하지 않고 this 값을 설정할 수 있는 bind 메서드를 도입했고, ES2015는 스스로의 this 바인딩을 제공하지 않는 화살표 함수를 추가했다.(렉시컬 컨텍스트안의 this값을 유지함)\n전역 문맥 전역 실행 문맥(global execution context)에서 this는 엄격 모드 여부에 관계 없이 전역 객체를 참조한다.\n1 2 3 4 5 6 7 8 9 // 웹 브라우저에서는 window 객체가 전역 객체 console.log(this === window); // true a = 37; console.log(window.a); // 37 this.b = \u0026#34;MDN\u0026#34;; console.log(window.b) // \u0026#34;MDN\u0026#34; console.log(b) // \u0026#34;MDN\u0026#34; 함수 문맥 함수 내부에서 this의 값은 함수를 호출한 방법에 의해 결정된다.\n단순 호출 엄격 모드가 아닐경우 this의 값이 호출에 의해 설정되지 않으므로, 기본값으로 브라우저에서는 window인 전역 객체를 참조하게 된다.\n1 2 3 4 5 6 7 8 9 function f1() { return this; } // 브라우저 f1() === window; // true // Node.js f1() === global; // true 반면에 엄격 모드에서 this 값은 실행 문맥에 진입하며 설정되는 값을 유지하므로 다음 예시에서 보여지는 것 처럼 this는 undefined로 남아있게 된다.\n1 2 3 4 5 6 function f2(){ \u0026#34;use strict\u0026#34;; // 엄격 모드 참고 return this; } f2() === undefined; // true f2를 객체의 메서드나 속성(예: window.f2())이 아닌 직접 호출했기 때문에 this는 undefined여야 하지만 브라우저에서 엄격 모드를 지원하지 않는다면 window 객체를 반환한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 var prop = 1; var test = { prop: 42, func: function() { var func2 = function() { console.log(this); } console.log(this); func2(); }, }; test.func(); /* \u0026gt; Object { prop: 42, func: function() { var func2 = function() { console.log(this); } console.log(this); func2(); } } \u0026gt; [object Window] // browser \u0026gt; [object global] // node.js */ function 키워드로 선언된 함수가 전역 실행 문맥(global execution context)에서 호출되었기 때문에 this는 엄격 모드 여부에 관계 없이 전역 객체를 참조한다.\nbind 메서드 ECMAScript5는 Function.prototype.bind를 도입했다. f.bind(someObject)를 호출하면 f와 같은 본문(코드)과 범위를 가졌지만 this는 원본 함수를 가진 새로운 함수를 생성한다. 새 함수의 this는 호출 방식과 상관없이 영구적으로bind()의 첫 번째 매개변수로 고정된다.\n1 2 3 4 5 6 7 8 9 10 11 12 function f() { return this.a; } var g = f.bind({a: \u0026#39;azerty\u0026#39;}); console.log(g()); // azerty var h = g.bind({a: \u0026#39;yoo\u0026#39;}); // bind는 한 번만 동작함! console.log(h()); // azerty var o = {a: 37, f: f, g: g, h: h}; console.log(o.a, o.f(), o.g(), o.h()); // 37, 37, azerty, azerty 화살표 함수 화살표 함수에서 this는 자신을 감싼 정적 범위(lexical context)이다. 전역 코드에서는 전역 객체를 가르킨다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 var globalObject = this; var foo = (() =\u0026gt; this); console.log(foo() === globalObject); // true // 객체로서 메서드 호출 var obj = {func: foo}; console.log(obj.func() === globalObject); // true // call을 사용한 this 설정 시도 console.log(foo.call(obj) === globalObject); // true // bind를 사용한 this 설정 시도 foo = foo.bind(obj); console.log(foo() === globalObject); // true 화살표 함수를 call(), bind(), apply()를 사용해 호출할 때 this의 값을 정해주더라도 무시한다. 사용할 매개변수를 정해주는 건 문제 없지만, 첫 번째 매개변수(thisArg)는 null을 지정해야 한다.\n어떤 방법을 사용하든 foo의 this는 생성 시점의 것으로 설정된다.(위 예시에서는 global 객체). 다른 함수 내에서 생성된 화살표 함수에도 동일하게 적용된다. this는 싸여진 렉시컬 컨텍스트로 유지된다.\n1 2 3 4 5 6 7 8 9 10 11 12 var obj = { bar: function() { var x = (() =\u0026gt; this); return x; } }; var fn = obj.bar(); console.log(fn() === obj); // true var fn2 = obj.bar; console.log(fn2()() === window); // true 화살표 함수의 범위는 선언될때 결정되는데, fn은 obj.bar()로 호출된 x를 활용하게 되어 this가 obj 를 의미하게 되고, fn2는 전역 실행 문맥에서 obj.bar 자체를 fn2에 할당 하였기 때문에 window로 설정되었다.\n객체의 메서드를 호출할 때 함수를 어떤 객체의 메서드로 호출하면 this의 값은 그 객체를 사용한다.\n다음 예제에서 o.f()를 실행할 때 o 객체가 함수 내부의 this와 연결된다.\n1 2 3 4 5 6 7 8 9 10 11 12 var o = {prop: 37}; function independent() { return this.prop; } o.f = independent; console.log(o.f()); // logs 37 o.b = {g: independent, prop: 42}; console.log(o.b.g()); // logs 42 this 바인딩은 멤버 대상에 영향을 받는다. 함수를 실행할 때, 객체 o.b의 메소드 g 로서 호출하면 함수 내부의 this는 o.b를 나타낸다.\n객체의 프로토타입 체인에서의 this 메서드가 어떤 객체의 프로토타입 체인 위에 존재한다면, this의 값은 그 객체가 메서드를 가진 것 처럼 설정된다.\n1 2 3 4 5 6 7 8 var o = { f:function() { return this.a + this.b; } }; var p = Object.create(o); p.a = 1; p.b = 4; console.log(p.f()); // 5 이 예제에서, f 속성을 가지고 있지 않은 변수 p가 할당된 객체는, 프로토타입으로 부터 상속받는다. 그러나 그것은 결국 o에서 f 이름을 가진 멤버를 찾는 되는 문제가 되지 않는다 ; p.f를 찾아 참조하기 시작하므로, 함수 내부의 this는 p 처럼 나타나는 객체 값을 취한다. 즉, f는 p의 메소드로서 호출된 이후로, this는 p를 나타낸다. 이것은 JavaScript의 프로토타입 상속의 흥미로운 기능이다.\n접근자와 설정자의 this 함수를 접근자와 설정자에서 호출하더라도 동일하다. 접근자나 설정자로 사용하는 함수의 this는 접근하거나 설정하는 속겅을 가진 객체로 묶인다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 function sum() { return this.a + this.b + this.c; } var o = { a: 1, b: 2, c: 3, get average() { return (this.a + this.b + this.c) / 3; } }; Object.defineProperty(o, \u0026#39;sum\u0026#39;, { get: sum, enumerable: true, configurable: true}); console.log(o.average, o.sum); // 2, 6 생성자로서 함수를 new 키워드와 함께 생성자로 사용하면 this는 새로 생긱 객체에 묶인다.\n","date":"2023-04-17T18:11:36+09:00","image":"https://codemario318.github.io/post/js_this/js_cover_huc1c9a52f33db3f5dad8bb16243cf7e4e_11875_120x120_fill_box_smart1_3.png","permalink":"https://codemario318.github.io/post/js_this/","title":"Javascript - this"},{"content":"hoist라는 단어의 사전적 정의는 \u0026ldquo;끌어올리기\u0026rdquo; 라는 뜻이다. 자바스크립트가 실행될때 선언된 모든 변수 선언부가 코드의 가장 위로 끌어올려진 것 처럼 처리된다.\n호이스트를 통해 변수의 정의가 그 범위에 따라 선언과 할당으로 분리된다. 즉, 변수가 함수 내에서 정의되었을 경우, 선언이 함수 최상위로, 함수 바깥에서 정의되었을 경우, 전역 컨텍스트의 최상위로 변경이 된다.\n1 2 3 4 5 6 7 8 9 function getX() { console.log(x); // undefined var x = 100; console.log(x); // 100 } getX(); 위와 같이 정의 되었을때, 아래와 같이 해석된다.\n1 2 3 4 5 6 7 8 9 10 11 function getX() { var x; console.log(x); x = 100; console.log(x); } getX(); 선언문은 항상 자바스크립트 엔진 구동시 가장 최우선으로 해석하므로 호이스팅 되고, 할당 구문은 런타임 과정에서 이루어지기 때문에 호이스팅 되지 않는다.\n함수의 호이스팅 함수가 자신이 위치한 코드에 상관없이 함수 선언문 형태로 정의한 함수의 유효범위는 전체 코드의 맨 처음부터 시작한다. 함수 선언이 함수 실행 부분보다 뒤에 있더라도 자바스크립트 엔진이 함수 선언을 끌어올리는 것을 의미한다.\n1 2 3 4 5 6 7 foo(); function foo(){ console.log(‘hello’); }; // console\u0026gt; hello foo 함수에 대한 선언을 호이스팅하여 global 객체에 등록시키기 때문에 hello가 제대로 출력된다.\n오류 사례 1 2 3 4 5 6 7 foo(); var foo = function() { console.log(‘hello’); }; // console\u0026gt; Uncaught TypeError: foo is not a function 예제의 함수 표현은 함수 리터럴을 할당하는 구조이기 때문에 호이스팅 되지 않으며 그렇기 때문에 아래와 같이 해석되어 런타임 환경에서 Type Error를 발생시킨다.\n1 2 3 4 5 6 7 8 var foo; foo(); // foo = undefined // console\u0026gt; Uncaught TypeError: foo is not a function foo = function( ) { console.log(‘hello’); }; ","date":"2023-04-17T18:04:35+09:00","image":"https://codemario318.github.io/post/js_hoisting/js_cover_huc1c9a52f33db3f5dad8bb16243cf7e4e_11875_120x120_fill_box_smart1_3.png","permalink":"https://codemario318.github.io/post/js_hoisting/","title":"Javascript - Hoisting"},{"content":"MySQL 서버는 서버의 상태를 진단할 수 있는 많은 도구들을 지원하지만 이러한 기능은 많은 지식을 필요로 하는 경우가 많다. 로그 파일을 활용하면 MySQL 서버에 대해 깊은 지식이 없어도 서버의 상태나 부하를 일으키는 원인을 쉽게 찾아 해결할 수 있다.\n에러 로그 파일 MySQL이 실행되는 도중 발생하는 에러나 경고 메시지가 출력되는 로그 파일이다. MySQL 설정 파일(my.cnf)에서 log_error라는 이름의 파라미터로 정의된 경로에 생성되는데 설정 파일에 별도로 정의도지 않은 경우 데이터 디렉터리(datadir 파라미터에 설정된 디렉터리)에 .err라는 확장자가 붙은 파일로 생성된다.\nMySQL이 시작하는 과정과 곤련된 정보성 및 에러 메시지 MySQL 설정 파일을 변경하거나 데이터베이스가 비정상적으로 종료된 후 다시 시작하는 경우에는 반드시 MySQL 에러 로그 파일을 통해 설정된 변수의 이름이나 값이 명확하게 설정되고 의도한 대로 적용됐는지 확인해야 한다.\nMySQL 서버가 정상적으로 기동했고(mysqld: ready for commections 메시지 확인), 새로 변경하거나 추가된 파라미터에 대한 에러나 경고성 메시지가 없다면 정상적으로 적용된 것으로 판단하면 된다.\n무시 ignore: 서버는 정상적으로 기동하지만 해당 파라미터가 적용안됨. 실패: 에러 메시지를 출력하고 시작하지 못했다는 메시지가 노출됨 마지막으로 종료할 때 비정상적으로 종료된 경우 나타나는 트랜잭션 복구 메시지 InnoDB의 경우 MySQL 서버가 비정상적으로 종료됐다면 다시 시작되면서 완료하지 못한 트랜잭션을 정리하고 디스크에 기록되지 못한 데이터가 있다면 다시 기록하는데, 이 과정에서 간단한 메시지가 출력된다.\n복구가 불가능한 경우 해당 에러메시지를 출력하고 MySQL은 다시 종료되며, 이 단계에서 발생하는 문제는 해결하기 어려운 문제점 일 때가 많고, innodb_force_recovery 파라미터를 설정하여 재시작 해야 할 수 있다.\n쿼리 처리 도중에 발생하는 문제에 대한 에러 메시지 쿼리 도중 발생하는 문제점은 사전 예방이 어려우며, 에러 로그 파일을 검토하는 과정에서 알게 된다.\n쿼리 실행 도중 발생한 에러나 복제에서 문제가 될 만한 쿼리에 대한 경고 메시지가 에러 로그에 기록되므로 자주 검토하는 것이 숨겨진 문제점을 해결하는데 많은 도움이 될 수 있다.\n비정상적으로 종료된 커넥션 메시지(Aborted connection) 클라이언트 애플리케이션에서 정상적으로 접속 종료를 하지 못하고 프로그램이 종료된 경우 MySQL 서버의 에러 로그 파일에 이런 내용이 기록된다. (네트워크 문제로 인한 겨우 포함)\n이런 메시지가 아주 많이 기록된다면 애플리케이션의 커넥션 종료 로직을 한번 검토해볼 필요가 있다.\nmax_connect_errors 시스템 변숫값이 너무 낮게 설정된 경우 클라이언트 프로그램이 MySQL 서버에 접속하지 못하고 Host 'host_name' is blocked라는 에러가 발생 가능하며, 이러한 경우는 에러가 어떻게 발생하게 됐는지 원인을 확인하고, 문제가 없다면 해당 시스템 변수의 값을 증가시키면 해결된다.\nInnoDB의 모니터링 또는 상태 조회 명령의 결과 메시지 InnoDB 테이블 모니터링이나 락 모니터링, 또는 엔진 상태를 조회하는 명령은 상대적으로 큰 메시지를 로그 파일에 기록한다.\nInnoDB의 모니터링을 활성화 상태로 유지하는 경우에는 에러 로그 파일이 매우 커져서 파일 시스템의 공간을 많이 사용할 수 있으므로, 다시 비활성화하여 에러 로그 파일이 커지지 않게 만들어야 한다.\nMySQL의 종료 메시지 가끔 MySQL이 아무도 모르게 종료돼 있거나 재시작 되는 경우가 있는데, 이러한 경우 에러 로그 파일에서 MySQL이 마지막으로 종료되면서 출력한 메시지를 확는 것이 서버가 종료된 이유를 확인하는 유일한 방법이다.\nReceived SHOUTDOWN from user ... 메시지: 특정 유저가 종료한 경우 없거나 스택 트레이스(16진수 주소값이 잔뜩 출력되는) 메시지: 세그멘테이션 폴트로 비정상 종료된 경우 세그멘테이션 폴트로 종료된 경우 스택 트레이스 내용을 최대한 참조하여 MySQL의 버그와 연관이 있는지 조사 후 버전을 업그레이드 하거나 회피책(WorkAround)를 찾는다. MySQL \u0026ldquo;The Error Log\u0026quot;절을 확인한다. 제너럴 쿼리 로그 파일 MySQL 서버에서 실행되는 쿼리 목륵을 검토하고 싶다면, 쿼리 로그를 활성화하여 실행 쿼리를 쿼리 로그 파일로 기록하게 한 다음, 해당 파일을 검토한다.\n슬로우 쿼리 로그와는 다르게 제너럴 로그는 실행되기 전에 MySQL이 요청을 받으면 바로 기록하기 때문에 쿼리 실행 중에 에러가 발생해도 일단 로그 파일에 기록된다.\n쿼리 로그 파일의 경로는 general_log_file 파라미터에 설정되있으며, 쿼리 로그를 파일이 아닌 테이블에 저장하도록 설정할 수 있으므로 이 경우에는 테이블을 SQL로 조회해 검토해야 한다.\n1 SHOW GLOBAL VARIABLES LIKE \u0026#39;general_log_file\u0026#39;; 슬로우 쿼리 로그 서비스 운영 중에 MySQL 서버의 전체적인 성능 저하를 검사하거나 정기적인 점검을 위한 튜닝이 필요할 때 어떤 쿼리가 문제인지를 판단하는데 많은 도움을 준다.\nlong_query_time: 해당 시스템 변수에 설정한 시간 이상의 시간이 소요된 쿼리가 모두 기록된다. log_output: 슬로우 커리 로그를 파일 또는 테이블에 기록할지 설정할 수 있다. TABLE: mysql DB의 테이블에 제너럴로그나 슬로우 쿼리 로그를 테이블(slow_log, general_log)에 저장한다. FILE: 로그 내용을 디스크의 파일로 저장한다. 로그 파일의 분석이 완료되면 그 결과는 3개의 그룹으로 나뉘어 저장된다.\n슬로우 쿼리 통계 분석 결과의 최상단에 표시되며, 모든 쿼리를 대상으로 슬로우 쿼리 로그의 실행 시간(Exec time), 잠금 대기 시간(Lock time) 등에 대해 평균 및 최소/최대 값을 표시한다.\n실행 빈도 및 누적 실행 시간순 랭킹 각 쿼리별로 응답 시간과 실행 횟수를 보여주는데, pt-query-digest 명령 실행 시 --oorder-by옵션으로 정렬 순서를 변경할 수 있다.\nQuery ID는 실행된 쿼리 문장을 정규화(쿼리에 사용된 리터럴을 제거)해서 만들어진 해시 값을 의미하는데, 같은 모양의 쿼리라면 동일한 Query ID를 가지게 된다.\n쿼리별 실행 횟수 및 누적 실행 시간 상세 정보 Query ID별 쿼리를 쿼리 랭킹에 표시된 순서대로 자세한 내용을 보여준다. 랭킹별 쿼리에서는 대상 테이블에 대해 어떤 쿼리인지만을 표시하는데, 실제 상세한 쿼리 내용은 개별 쿼리의 정보를 확인해보면 된다.\n","date":"2023-04-14T16:31:23+09:00","image":"https://codemario318.github.io/post/real_mysql_4_4/real_mysql_hu03b8ff0acb6f52b3ec9ae95e616f82c2_25714_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/real_mysql_4_4/","title":"4.4 MySQL 로그 파일"},{"content":"\n키 캐시 키 버퍼라고도 불리는 MyISAM의 키 캐시는 InnoDB의 버퍼풀과 비슷한 역할을 수행한다. 키 캐시는 인덱스만을 대상으로 작동하며, 인덱스의 디스크 쓰기 작업에 대해서만 부분적으로 버퍼링 역할을 한다.\n키 캐시 효율성 수식\n키 캐시 히트율 = 100 - (Key_reads / Key_read_requests * 100)\nKey_reads: 인덱스를 디스크에서 읽어들인 횟수를 저장하는 상태 변수 Key_read_requests: 키 캐시로부터 인덱스를 읽은 횟수를 저장하는 상태변수 1 SHOW GLOBAL STATUS LIKE \u0026#39;Key%\u0026#39;; 메뉴얼에서는 키 캐시를 이용한 쿼리의 비율(Hit rate)을 99% 로 유지할 것을 권장하며, 99% 미만이라면 키 캐시를 조금 더 크게 설정하는 것이 좋다.\n32비트 운영체제에서는 하나의 키 캐시에 4GB 이상 메모리 공간을 설정할 수 없고, 64비트 운영체제에서는 OS_PER_PROCESS_LIMIT 값에 설정된 크기만큼의 메모리를 할당할 수 있다.\n제한 값 이상의 키 캐시를 할당하고 싶다면 기본 키 캐시 이외에 별도 명명된 키 캐시 공간을 설정해야 하며, 기본 키 캐시 공간을 설정하는 파라미터는 key_buffer_size다.\n1 2 3 key_buffer_size = 4GB kbuf_board.key_buffer_size = 2GB kbuf_comment.key_buffer_size = 2GB 위 같이 설정하면 기본 키 캐시 4GB와 kbuf_board, kbuf_comment라는 이름의 키 캐시가 각각 2GB씩 생성된다.\n기본 키 캐시 영역외 키 캐시 영역은 아무런 설정이 없다면 할당만 해두고 사용하지 않아 추가된 키 캐시는 어떤 인덱스를 캐시할지 MySQL에 알려야 한다.\n1 2 CACHE INDEX db1.board, db2.board IN kbuf_board; CACHE INDEX db1.comment, db2.comment IN kbuf_comment; 운영체제의 캐시 및 버퍼 MyISAM 테이블의 인덱스는 키 캐시를 이용해 디스크를 검색하지 않고도 빠르게 검색될 수 있으나, 디스크 데이터 I/O를 성능을 위한 캐시나 버퍼링 기능은 없다. 따라서 MyISAM 테이블의 데이터 읽기나 쓰기 작업은 항상 운영체제의 디스크 읽기 또는 쓰기 작업으로 요청된다.\n운영체제의 캐시 공간은 남는 메모리를 사용하는 것이 기본 원칙이어서 남는 공간이 없다면 MyISAM 스토리지 엔진 데이터 I/O에 사용될 메모리를 확보할 수 없어 느려진다.\nMyISAM이 주로 사용되는 MySQL에서 일반적으로 키 캐시는 최대 물리 메모리의 40% 이상을 넘지 않게 설정하고, 나머지 메모리 공간은 운영체제가 자체적은 파일 시스템을 위한 캐시 공간을 마련할 수 있게 해주는 것이 좋다.\n데이터 파일과 프라이머리 키(인덱스) 구조 InnoDB 스토리지 엔진을 사용하는 테이블은 프라이머리 키에 의해서 클러스터링되어 저장되지만, MyISAM 테이블은 프라이머리 키에 의한 클러스터링 없이 데이터 파일이 Heap 공간처럼 활용된다. (프라이머리 키 값과 무관하게 INSERT되는 순서대로 데이터 파일에 저장된다.)\nMyISAM 테이블에 저장되는 레크드는 모두 ROWID라는 물리적인 주소값을 가지는데, 프라이머리 키와 세컨더리 인덱스는 모두 데이터 파일에 저장된 레코드의 ROWID 값을 포인터로 가진다.\nROWID는 두가지 방법으로 저장된다.\n고정 길이 ROWID\n자주 사용되지는 않지만 MyISAM 테이블을 생성할 때 MAX_ROWS 옵션을 사용해 명시하면 MySQL 서버는 쵀대로 가질 수 있는 레코드가 한정된 테이블을 생성한다. 레코드 개수가 한정되면 MyISAM 테이블은 ROWID값으로 4바이트 정수를 사용하여 INSERT된 순번으로 ROWID를 사용한다.\n가변 길이 ROWID\nMAX_ROWS 옵션을 사용하지 않으면 MyISAM 테이블의 ROWID는 최대 myisam_data_pointer_size 시스템 변수에 설정된 바이트 수 만큼에 공간을 사용할 수 있다. 기본값은 7이며 최소 2byte 부터 7byte 까지 가변적인 ROWID를 갖게 된다. 첫 바이트는 ROWID의 길이를 저장하는 용도로 사용되고 나머지 공간은 실제 ROWID를 저장하는데 사용한다. 가변적인 ROWID를 가지면 데이터 파일에서 레코드의 위치가 ROWID로 사용되어, 가변 길이 ROWID인 테이블일때 최대 크기 256TB(2**(8(7-1)))가질 수 있다.\n","date":"2023-04-14T15:52:19+09:00","image":"https://codemario318.github.io/post/real_mysql_4_3/real_mysql_hu03b8ff0acb6f52b3ec9ae95e616f82c2_25714_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/real_mysql_4_3/","title":"4.3 MyISAM 스토리지 엔진 아키텍처"},{"content":"Double Write Buffer InnoDB 스토리지 엔진의 리두 로그는 공간 낭비를 막기 위해 페이지의 변경된 내용만 기록한다. 이로인해 더티 페이지를 디스크 파일로 플러시할 때 일부만 기록되는 문제가 발생하면 그 페이지의 내용은 복구할 수 없을 가능성이 있다.\n이런 현상을 파셜 페이지 또는 톤 페이지라고 하는데, 하드웨어의 오작동이나 시스템의 비정상 종료 등으로 발생할 수 있다.\n파셜 페이지(Partial-Page)\n데이터 베이스 페이지 중에서 데이터가 일부만 채워진 페이지. 레코드가 페이지의 크기보다 작을 때 발생하며, 레코드가 페이지를 벗어나지 않은 상태에서 페이지의 일부만 사용하게 된다. 톤 페이지(Tone-Page)\n디스크에 기록 중인 페이지의 기록 작업이 중간에 중단되어 발생하는 문제. 페이지 일부가 디스크에 기록되지 않아 데이터 무결성이 손상되는 문제를 일으킬 수 있다. InnoDB 스토리지 엔진은 이러한 문제를 막기 위해 Double-Write 기법을 활용한다.\nInnoDB 스토리지 엔진은 실제 데이터 파일에 변경 내용을 기록하기 전에 기록될 더티 페이지들을 묶어 시스템 테이블 스페이스의 DoubleWrite 버퍼에 기록한다.\n더티 페이지 플러싱 중 오류등으로 서버가 종료되었다면 InnoDB 스토리지 엔진은 재시작 될 때 항상 Double Write 버퍼의 내용을 데이터 파일의 페이지로 복사하게 된다.\nDoubleWrite 기능을 사용할지 여부는 Innodb_doublewrite 시스템 변수로 제어할 수 있다.\n이처럼 DoubleWrite 버퍼는 데이터의 안정성을 위해 사용되는데, HDD처럼 자기 원판이 회전하는 저장 시스템에서는 한 번의 순차 디스크 쓰기를 하는 것으로 부담스럽지 않지만 SSD처럼 랜덤 IO와 순차 IO의 비용이 비슷한 저장 시스템에서는 부담스럽다.\nSSD는 HDD와 다르게 내부적으로 물리적인 섹터 단위로 데이터를 읽고 쓰지 않는다. 따라서 메모리에 복사된 내용이 SSD의 섹터 크기보다 작은 경우에도(순차 디스크 쓰기) 여러번 기록되어야 한다.\n하지만 데이터의 무결성이 매우 중요한 서비스에서는 DoubleWrite의 활성화를 고려하는 것도 좋다. 만약 데이터베이스 서버의 성능을 위해 InnoDB 리두 로그 동기화 설정(innodb_flush_log_at_trx_commit 시스템 변수)을 1이 아닌 값으로 설정했다면, DoubleWrite도 비활성화 하는 것이 좋다.\ninnodb_flush_log_at_trx_commit\n0: 커밋 후 로그 버퍼를 디스크에 즉시 플러시 하지 않고, 로그 버퍼가 일정 수준 채워지거나 데이터베이스 서버가 종료될 때 플러시한다. 데이터 일관성이 보장되지 않을 수 있다. 1(default): 컷밋 후 로그 버퍼를 디스크에 즉시 플러시한다. 데이터 일관성은 보장하지만 디스크 IO가 부하를 발생시킬 수 있다. 2: 커밋 후 로그 버퍼를 디스크에 즉시 플러시 하지 않고, 로그를 별도 파일에 쓴 후 파일을 주기적으로 플러시 한다. 0과 1의 중간 정도로 데이터 일관성과 디스크 IO 부하 감소를 균형있게 유지할 수 있다. 언두 로그 InnoDB 스토리지 엔진은 트랜잭션과 격리 수준을 보장하기 위해 DML로 변경되기 이전 버전의 데이터를 별도로 백업한다. 이렇게 백업된 데이터를 언두 로그(Undo Log)라고 한다.\n트랜잭션 보장\n트랜잭션이 롤백되면 트랜잭션 도중 변경된 데이터를 변경 전 데이터로 복구해야 하는데, 이때 언두 로그에 백업해둔 이전 버전의 데이터를 이용해 복구한다. 격리 수준 보장\n특정 커넥션에서 데이터를 변경하는 도중 다른 커넥션에서 데이터를 조회하면 트랜잭션 격리 수준에 맞게 변경중인 레코드를 읽지 않고 언두 로그에 백업해둔 데이터를 읽어서 반환하기도 한다. 언두 로그 모니터링 언두 로그로 인해 여러가지 성능 이슈가 발생할 수 있어 모니터링이 필요하다.\n대용량 처리 트랜잭션\n1억 건의 레코드가 저장된 100GB 크기의 테이블을 DELETE로 삭제한다고 가정했을때, 언두 로그에 삭제전 값을 저장해야 하므로 언두 로그 공간은 100GB가 된다.\n장시간 활성화된 트랜잭션\n트랜잭션이 완료됐다고 해서 해당 트랜잭션이 생성한 언두 로그를 즉시 삭제할수 없을 수 있다. 먼저 시작된 트랜잭션보다 이후 발생한 트랜잭션이 완료된 경우, 먼저 시작된 완료된 트랜적션이 완료되기 전 까지 언두 로그는 삭제되지 않는다. 이러한 경우 언두 로그의 이력을 필요한 만큼 스캔해야만 필요한 레코드를 찾을 수 있기 때문에 쿼리의 성능이 전반적으로 떨어질 수 있다.\n1 2 3 4 5 6 7 8 9 /* MySQL 모든 버전 */ SHOW ENGING INNODB STATUS \\G /* MySQL 8.0 */ SELECT count FROM information_schema.innodb_metrics WHERE SUBSYSTEM=\u0026#39;transaction\u0026#39; AND NAME=\u0026#39;trx_rseg_history_len\u0026#39; ; MySQL 서버에서 실행되는 INSERT, UPDATE, DELETE 문장이 얼마나 많은 데이터를 변경하느냐에 따라 평상시 언두 로그 건수는 상이할 수 있어, 안정적인 시점의 언두 로그 건수를 확인하고 이를 기중으로 언두 로그의 급증 여부를 모니터링하는 것이 좋다.\nMySQL 서버에서 INSERT 문장으로 인한 언두 로그와 UPDATE, DELETE 문장으로 인한 언두 로그는 별도로 관리된다. UPDATE, DELETE 문장으로 인한 언두 로그는 MVCC와 데이터 복구(롤백 등)에 모두 사용되지만, INSERT 문장으로 인한 언두 로그는 롤백, 데이터 복구만을 위해 사용된다.\n언두 테이블스페이스 관리 언두 로그가 저장되는 공간을 언두 테이블스페이스(Undo Tablespace)라고 한다.\nMySQL 5.6 이전 버전에서는 언두 로그가 모두 시스템 테이블스페이스(ibdata.idb)에 저장되었었지만, 시스템 테이블스페이스의 언두 로그는 MySQL서버가 초기화될 때 생성되기 때문에 확장의 한계가 있었다. 이에 따라 5.6 버전에서는 innodb_undo_tablespaces 시스템 변수가 도입되어 별도 로그 파일을 사용할 수 있게 되었고, 8.0으로 업그레이드되면서 언두 로그는 항상 시스템 테이블스페이스 외부의 별도 로그 파일에만 기록되도록 개선되었다.\n하나의 언두 테이블스페이스는 1~128개의 롤백 세그먼트를 가지며, 롤백 세크먼트는 1개 이상의 언두 슬롯(Undo Slot)을 가진다.\n최대 동시 처리 가능한 트랜잭션의 개수는 다음 수식으로 예측할 수 있다.\n(InnDB 페이지 크기) / 16 * (롤백 세그먼트 개수) * (언두 테이블 스페이스 수)\nInnoDB 기본 설정(innodb_undo_tablespace=2, innodb_rollback_segments=128)을 사용한다면 131,072개 정도의 트랜잭션이 동시에 처리 가능해진다. 일반적인 서비스에서 이 정도까지 동시 트랜잭션이 필요하진 않겠지만 기본값으로 해서 크게 문제될 건 없다.\n언두 로그 슬롯이 부족한 경우에는 트래잭션을 시작할 수 없는 심각한 문제가 발생하기 때문에 적절히 정해야 한다.\nMySQL 8.0 부터 CREATE UNDO TABLESPACE나 DROP TABLESPACE같은 명령으로 새로운 언두 테이블 스페이스를 동적으로 추가하고 삭제할 수 있게 개선되었다.\n언두 테이블스페이스 공간을 필요한 만큼만 남기고 불필요하거나 과도하게 할당된 공간을 운영체제로 반납하는 것을 \u0026lsquo;Undo tablespace truncate\u0026rsquo;라고 하며 자동, 수동 두가지 방법이 있다.\n체인지 버퍼 RDBMS에서 레코드가 추가, 변경될 때 데이터 파일을 변경하는 작업뿐 아니라 해당 테이블에 포함된 인덱스를 업데이트하는 작업도 필요하다. 인덱스를 업데이트하는 작업은 랜덤하게 디스크를 읽는 작업이 필요하므로 테이블에 인덱스가 많다면 상당히 많은 자원을 소모하게 된다. 따라서 InnoDB는 변경해야 할 인덱스 페이지가 버퍼풀에 있으면 바로 업데이트를 수행하지만, 그렇지 않고 디스크로부터 읽어와서 업데이트해야 한다면 이를 즉시 실행하지 않고 임시 공간에 저장해 두고 바로 사용자에게 결과를 반환하는 형태로 성능을 향상시키게 되는데, 이때 사용하는 임시 메모리 공간을 체인지 버퍼(Change Buffer)라고 한다.\n사용자에게 결과를 반환하기 전에 반드시 중복 여부를 체크해야 하는 유니크 인덱스는 체인지 버퍼를 사용할 수 없다.\n체인지 버퍼에 임시로 저장된 인덱스 레코드 조각은 이후 백그라운드 스레드에 의해 병합되는데, 이 스레드를 체인지 버퍼 머지 스레드라고 한다.\nMySQL 5.5 이전 버전까지는 INSERT 작업에 대해서만 이러한 버퍼링이 가능했는데, 이후 조금씩 개선되며 INSERT, UPDATE, DELETE로 인해 키를 추가하거나 삭제하는 작업에 대해서도 버퍼링이 될 수 있게 개선되었다.\n또한 innodb_change_buffering이라는 시스템 변수가 새로 도입되어 작업의 종류별로 체인지 버퍼를 활성화할 수 있으며, 체인지 버퍼가 비효일적일 때는 체인지 버퍼를 사용하지 않게 설정할 수 있게 개선되었다.\nall: 모든 인덱스 관련 작업을 버퍼링(inserts + deletes + purges) none: 버퍼링 안함 inserts: 인덱스에 새로운 아이템을 추가하는 작업만 버퍼링 deletes: 인덱스에서 기존 아이템을 삭제하는 작업(삭제됐다는 마킹 작업)만 버퍼링 changes: 인덱스에 추가하고 삭제하는 작업만(inserts + deletes) 버퍼링 purges: 인덱스 아이템을 영구적으로 삭제하는 작업만 버퍼링(백그라운드 작업) 체인지 버퍼는 기본적으로 InnoDB 버퍼풀로 설정된 메모리 공간의 25%까지 활용할 수 있게 설정돼있으며, 필요하다면 50%까지 설정할 수 있다. innodb_change_buffer_max_size 시스템 변수에 비율을 조정하여 바꿀 수 있다.\n리두 로그 및 로그 버퍼 리두 로그는 트랜잭션의 4가지 요소인 ACID 중에서 D(Durable)에 해당하는 영속성과 가장 밀점하게 연관돼 있다. 리두 로그는 하드웨어나 소프트웨어 등 문제로 인해 MySQL 서버가 비정상적으로 종료됐을 때 데이터 파일에 기록되지 못한 데이터를 잃지 않게 해주는 안전장치이다.\n대부분 데이터베이스 서버는 데이터 변경 내용을 로그로 먼저 기록한다. 대부분 DBMS에서 데이터 파일은 쓰기보다 읽기 성능을 고려한 자료 구조를 가지고 있기 때문에 데이터 파일 쓰기는 디스크의 랜덤 액세스가 필요하여 상대적으로 큰 비용이 필요하다.\n이로 인한 성능 저하를 막기 위해 쓰기 비용이 낮은 자료구조인 리두 로그를 가지고 있으며, 비정상 종료가 발생하면 리두 로그의 내용을 이용해 데이터 파일을 다시 서버가 종료되기 직전 상태로 복구한다.\n또한 성능을 위해 리두 로그를 버퍼링 할 수 있는 InnoDB 버퍼풀이나, 리두 로그를 버퍼링할 수 있는 로그 버퍼와 같은 자료 구조도 가지고 있다.\nMySQL 서버가 비정상으로 종료되는 경우 InnoDB 스토리지 엔진의 데이터 파일은 두 가지 일관되지 않은 데이터를 가질 수 있다.\n커밋됐지만 데이터 파일에 기록되지 않은 데이터 롤백됐지만 데이터 파일에 이미 기록된 데이터 리두로그를 활용하여 변경이 커밋, 롤백, 트랜잭션의 실행 중간 상태였는지 확인하고, 적절히 처리한다.\n데이터베이스 서버에서 리두 로그는 트랜잭션이 커밋되면 즉시 디스크로 기록되도록 시스템 변수를 설정하는 것을 권장한다. 그래야만 서버가 비정상적으로 종료되었을때 직전까지의 트랜잭션 커밋 내용이 리두 로그에 기록될 수 있고, 그 리두 로그를 이용해 장애 직전 시점까지 복구가 가능해진다.\n하지만 트랜잭션이 커밋될 때마다 리두 로그를 디스크에 기록하면 부하가 생길 수 있어, InnoDB 스토리지 엔진에서 리두 로그를 어느 주기로 디스크에 동기화할지를 결정하는 innodb_flush_log_trx_commit 시스템 변수를 제공한다.\n0: 1초에 한 번씩 리두 로그를 디스크로 기록하고 동기화를 실행한다. 서버가 비정상 종료되면 최대 1초 동안의 트랜잭션은 커밋됐더라도 데이터는 사라질 수 있다. 1: 매번 트랜잭션이 커밋될 때마다 디스크로 기록되고 동기화까지 수행한다. 2: 트랜잭션이 커밋될 때마다 디스크로 기록은 되지만 실질적인 동기화는 1초에 한번씩 실행된다. 커밋이 되면 변경 내용이 운영체제의 메모리 버퍼로 기롤되는 것이 보장되기 때문에 MySQL 서버가 비정상 종료되더라도 트랜잭션 데이터는 사라지지 않는다. 리두 로그 파일들의 전체 크기는 버버풀의 효율성을 결정하기 때문에 신중히 결정해야한다. 리두 로그 파일의 크기는 innodb_log_file_size 시스템 변수로 결정하며, innodb_log_files_in_group 시스템 뼌수는 리두 로그 파일 개수를 결정한다.\n리두 로그 파일의 전체 크기를 버퍼풀의 크기에 맞게 설정해야 적절히 변경된 내용을 버퍼풀에 모아 한번에 디스크에 기록할 수 있다.\nACID는 데이터베이스에서 트랜잭션의 무결성을 보장하기 위해 꼭 필요한 4가지 요소(기능)을 의미한다.\nA(Atomic): 트랜잭션은 원자성 작업이어야 함. C(Consistent): 일관성 I(Isolated): 격리성 D(Durable): 영속성. 한 번 저장된 데이터는 지속적으로 유지되어야 함. 리두 로그 아카이빙 MySQL 8.0부터 InnoDB 스토리지 엔진의 리두 로그를 아카이빙 할 수 있는 기능이 추가됐다.\n백업 툴이 리두 로그 아카이빙을 사용하려면 먼저 MySQL 서버에서 아카이빙된 리두 로그가 저장될 디렉터리를 innodb_redo_log_archive_dirs 시스템 변수에 설정해야 하며, 디렉터리는 운영체제의 MySQL 서버를 실행하는 유저만 접근이 가능해야 한다.\n1 2 3 4 mkdir /var/log/mysql_redo_archive cd /var/log/mysql_redo_archive mkdir 20230413 chmod 700 20230413 1 SET GLOBAL innodb_redo_log_archive_dirs=\u0026#39;backup:/var/log/mysql_redo_archive\u0026#39;; 디렉터리가 준비되면 리두 로그 아카이빙을 시작하도록 innodb_redo_log_archive_start UDF(사용자 정의 함수)를 실행한다. 해당 UDF는 리두 로그를 아카이빙할 디렉터리에 대한 레이블과 선택적으로 서브 디렉터리 이름 총 두가지의 매개 변수를 받는다.\n1 DO innodb_redo_log_archive_start(\u0026#39;backup\u0026#39;, \u0026#39;20230413\u0026#39;); 리두 아카이빙을 종료할 때는 innodb_redo_log_archive_stop UDF를 실행한다.\n1 DO innodb_redo_log_archive_stop(); innodb_redo_log_archive_start UDF를 실행한 세션의 연결이 끊어지면 InnoDB 스토리지 엔진은 리두 로그 아카이빙을 멈추고 아카이빙 파일도 자동으로 삭제하므로 커넥션을 유지해야 하고, innodb_redo_log_archive_stop UDF를 호출하여 정상적으로 종료돼야 한다.\n리두 로그 활성화 및 비활성화 InnoDB 스토리지 엔진의 리두 로그는 MySQL 서버가 비정상 종료됐을때 데이터 파일에 기록되지 못한 트랜잭션을 복구하기 위해 항상 활성화되어있다. MySQL 서버에서 트랜잭션이 커밋돼도 데이터 파일은 즉시 디스크로 동기화되지 않는 반면, 리두 로그는 항상 디스크로 기록된다.\nMySQL 8.0 버전부터 수동으로 리두 로그를 비활성화 할 수 있어, 대용량 데이터를 한번에 적재하는 경우 사용하여 적재 시간을 단축할 수 있다.\n어댑티브 해시 인덱스 어댑티브 해시 인덱스는 InnoDB 스토리지 엔진에서 사용자가 자주 요청하는 데이터에 대해 자동으로 생성하는 인덱스로, innodb_adaptive_hash_index 시스템 변수를 이용하여 활성화, 비활성화 할 수 있다.\nInnoDB 스토리지 엔진의 대표적인 인덱스는 B-Tree로 데이터는 PK 순으로 정렬되어 관리되고, Secondary Key는 인덱스키 + PK 조합으로 정렬되어 있다. 특정 데이터를 찾기 위해 Secondary Key에서 PK를 찾고, 찾은 PK를 통해 원하는 데이터를 찾는 형태로 처리된다.\nPK 사용시 데이터에 접근되는 비용은 O(logN)이고, Secondary Key를 사용해 데이터에 접근은 PK에 대한 접근도 필요하므로 2 * O(logN)이다.\n따라서 B-Tree 자료구조 특성으로 데이터가 많아진다 하더라도 탐색 비용이 크게 증가하지 않지만, 동시에 많은 스레드에서 탐색 작업이 발생할 경우 Lock 등으로 인해 성능 저하가 발생할 수 있다.\n어댑티브 해시 인덱스는 B-Tree의 검색 시간을 줄여주기 위해 도입된 기능으로, 자주 읽히는 데이터 페이지의 키 값을 이용해 해시 인덱스를 만들고, 필요할 때마다 어댑티브 해시 인덱스를 검색해서 레코드가 저장된 데이터 페이지를 즉시 찾아갈 수 있다.\n구조 해시 인덱스는 인덱스 키 값과 해당 인덱스 키 값이 저장된 데이터 페이지 주소의 쌍으로 관리된다.\n인덱스 키 값:\nB-Tree 인덱스의 고유번호 + B-Tree 인덱스의 실제 키 값 인덱스의 고유번호가 포함되는 이유는 InnoDB 스토리지 엔진에서 어댑티브 해시 인덱스는 하나만 존재하기 때문이다. 데이터 페이지 주소:\n실제 키 값이 저장된 데이터 페이지의 메모리 주소, 버퍼풀에 로딩된 페이지의 주소를 의미 어댑티브 해시 인덱스는 버퍼풀에 올려진 데이터 페이지에 대해서만 괸리되고, 버퍼풀에서 해당 데이터 페이지가 없어지면 어댑티브 해시 인덱스에서도 해당 페이지의 정보는 사라진다.\n성능 어댑티브 해시 인덱스를 활성화 후 처리량은 2배 가까이 늘었음에도 불구하고 CPU 사용량은 오히려 떨어진다.\nInnoDB 내부잠금(세마포어)의 횟수도 획기적으로 줄어든다.\n추가로 MySQL 8.0 부터는 내부 잠금을 줄이기 위해 어댑티브 해시 인덱스의 파티션 기능을 제공하며 innodb_adaptive_hash_index_parts 시스템 변수를 통해 파티션 개수를 변경할 수 있다(기본값 8개).\n어댑티브 해시 인덱스가 성능에 많은 도음이 된다면 파티션 개수를 더 많이 설정하는 것도 도움이 될 수 있다.\n한계 상황에 따라 어댑티브 해시 인덱스가 성능 향상에 크게 도움이 되지 않는 경우도 있다.\n성능 향상에 도움이 되는 경우 디스크의 데이터가 InnoDB 버퍼풀 크기와 비슷한 경우(디스크 읽기가 많지 않은 경우) 동등 조건 검색(동등 비교 및 IN 연산)이 많은 경우 쿼리가 일부 데이터에만 집중 되는 경우 성능 향상에 크게 도움이 되지 않는 경우 디스크 읽기가 많은 경우 특정 패턴의 쿼리가 많은 경우(JOIN, LIKE 패턴 검색) 매우 큰 데이터를 가진 테이블의 레코드를 폭넓게 읽는 경우 어댑티브 해시 인덱스는 데이터 페이지를 메모리(버퍼풀) 내에서 접근하는 것을 더 빠르게 만드는 기능으로 데이터 페이지를 디스크에서 읽어오는 경우가 많은 경우 데이터베이스 서버에서는 큰 도움이 되지 않는다.\n어댑티브 해시 인덱스 또한 메모리를 사용하며, 때로는 상당히 큰 메모리 공간을 사용할 수 있다. 데이터 페이지의 인덱스 키가 해시 인덱스로 만들어져야 하기 때문에 불필요한 경우 제거되어야 한다. 활성화되면 InnoDB 스토리지 엔진이 필수적으로 검색에 활용해야 하기 때문에 불필요한 접근이 발생할 수 있다. 주의할 점 테이블 삭제(DROP), 변경(ALTER)시 해당 테이블이 가진 모든 데이터 페이지의 내용을 어댑티브 해시 인덱스에서 제거해야한다. 이로 인해 테이블이 삭제되거나 스키마가 변경되는 동안 상당히 많은 CPU 자원을 사용하게되어 데이터베이스 서버의 처리 성능이 떨어진다.\n모니터링 MySQL 서버의 상태 값들을 통해 어댑티브 해시 인덱스가 불필요한 오버헤드만 만들고 있는지 확인할 수 있다.\n1 2 3 4 5 6 7 8 SHOW ENGINE INNODB STATUS\\G /* Hash table size 8747, node heap has 1 buffers(s) Hash table size 8747, node heap has 0 buffers(s) ... 1.03 hash searches/s, 2.64 non-hash searches/s /* searches: 쿼리가 처리되기 위해 내부적으로 키 값의 검색이 몇 번 실행되었는지를 의미함\n어댑티브 해시 인덱스의 효율은 검색 횟수가 아니라 해시 인덱스 히트율과 인덱스가 사용 중인 메모리 공간, 서버의 CPU 사용량을 종합해서 판단해야 한다.\n위 실행 쿼리 결과에서는 28% 정도가 어댑티브 해시 인덱스를 이용했다는 것을 알 수 있는데, 서버의 CPU 사용량이 100%에 근접한다면 효율적이라고 볼 수 있다. 하지만 CPU 사용량이 낮고 어댑티브 해시 인덱스의 메모리 사용량이 높다면 비활성화하여 버퍼풀이 더 많은 메모리를 사용할 수 있게 유도하는 것도 좋은 방법이다.\n어댑티브 해시 인덱스의 메모리 사용량은 performance_schema를 이용해서 확인 가능하다.\n1 2 3 4 5 SELECT EVENT_NAME ,CURRENT_NUMBER_OF_BYTES_USED FROM performance_schema.memory_summary_global_by_event_name WHERE EVENT_NAME=\u0026#39;memory/innodb/adaptive hash index\u0026#39; ; MyISAM, MEMORY 스토리지 엔진 비교 MyISAM MySQL 5.5부터는 InnoDB 스토리지 엔진이 기본 스토리지 엔진으로 채택 되었지만, 이전까지는 MyISAM이 기본 스토리지 엔진으로 사용되는 경우가 많았다.\nMySQL 서버의 시스템 테이블의 기본 스토리지 엔진 MySQL 8.0 부터는 MyISAM이 기본 설정되었던 서버의 시스템 테이블(사용자 인증 관련 정보, 복제 관련 정보가 저장된 mysql DB의 테이블) 등 서버의 모든 기능을 InnoDB 스토리지 엔진으로 교체되었다. 전문 검색 및 공간 좌표 검색 기능 제공. InnoDB 스토리지 엔진에서도 전문 검색과 공간 좌표 검색 기능을 모두 지원하도록 개선되었다. 이러한 이유로 MyISAM 스토리지 엔진은 InnoDB 스토리지 엔진으로 대체될 것으로 예상된다.\nMEMORY MEMORY 스토리지 엔진이 메모리라는 이름 때문에 과대 평가를 받는 경우가 있다.\n단일 스레드 처리 성능 단일 스레드 처리 성능은 MEMORY 스토리지 엔진이 빠를 수 있으나, MySQL 서버는 일반적으로 온라인 트랜잭션 처리를 위한 목적으로 사용되어 동시 처리 성능이 매우 중요하다. MEMORY 스토리지 엔진에서 동시에 많은 클라이언트 쿼리 요청이 실행되는 상황이라면 테이블 수준의 잠금으로 인해 InnoDB 스토리지 엔진을 따라갈 수 없다.\n임시 테이블 용도로 활용 MySQL 5.7 버전까지 내부 임시 테이블 용도로 활용되었으나, 가변 길이 타입의 컬럼을 지원하지 않는다는 문제점으로 MySQL 8.0 부터는 TempTable 스토리지 엔진이 대체되어 사용된다.\n이러한 이유로 MEMORY 스토리지 엔진을 선택해서 얻을 수 있는 장점이 없어져, 향후 버전에서는 제거될 것으로 예상된다.\n","date":"2023-04-13T12:39:01+09:00","image":"https://codemario318.github.io/post/real_mysql_4_2_3/real_mysql_hu03b8ff0acb6f52b3ec9ae95e616f82c2_25714_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/real_mysql_4_2_3/","title":"4.2 InnoDB 스토리지 엔진 아키텍처(3)"},{"content":"버퍼풀은 InnoDB 스토리지 엔진의 핵심으로 디스크에서 데이터를 읽어 메모리에 보관하고, 필요할 때 메모리에서 데이터를 읽어와 처리하는 역할을 수행한다. 또한 디스크와 메모리 사이에서 데이터 읽기 및 쓰기를 관리하여 데이터 베이스의 성능을 향상시킨다.\n디스크의 데이터 파일이나 인덱스 정보를 메모리에 캐시해 두는 공간이다. 쓰기 작업을 지연시켜 일괄 작업으로 처리할 수 있게 해주는 버퍼 역할도 수행한다. 일반적인 애플리케이션에서는 INSERT, UPDATE, DELETE처럼 데이터를 변경하는 쿼리는 데이터 파일의 흩어져있는 레코드를 변경하기 때문에 랜덤한 디스크 작업을 발생시킨다. 변경을 모아 처리하여 랜덤 디스크 접근 작업 수를 줄일 수 있다.\n버퍼풀의 크기 설정 운영체제와 각 클라이언트 스레드가 사용할 메모리도 충분히 고려하여 설정한다. MySQL 서버 내에서 메모리를 필요로 하는 부분은 크게 없지만 아주 독특한 경우 레코드 버퍼가 상당한 메모리를 사용하기도 한다.\n레코드버퍼\n각 클라이언트 세션에서 테이블의 레코드를 읽고 쓸 때 버퍼로 사용하는 공간으로 커넥션이 많고 사용하는 테이블도 많다면 레코드 버퍼 용도로 사용되는 메모리 공간이 많이 필요할 수 있다.\nMySQL 서버가 사용하는 레코드 버퍼 공간은 별도로 설정할 수 없어, 전체 커넥션 개수와 각 커넥션에서 읽고 쓰는 테이블의 개수에 따라 결정되고, 동적으로 해제되기도 하므로 정확히 필요한 메모리의 크기를 계산할 수 없다.\n버퍼풀 동적 크기 조절 MySQL 5.7 버전부터 InnoDB 버퍼풀의 크기를 동적으로 조절할 수 있게 개선되어 가능하면 InnoDB 버퍼풀의 크기를 적절히 작은 값으로 설정하고 상황을 봐가며 증가시키는 방법이 최적이다.\ninnodb_buffer_pool_size 시스템 변수로 크기를 설정할 수 있으며, 동적으로 버퍼풀의 크기를 확장할 수 있다.\n크리티컬한 변경이므로 가능하며 MySQL 서버가 한가한 시점을 골라 실행한다. 버퍼풀의 크기를 줄이는 작업은 서비스 영향도가 매우 크므로 주의해야한다. 버퍼풀은 내부적으로 128MB 청크 단위로 쪼개어 관리되어 조절된다. 버퍼풀 나누기 InnoDB 버퍼풀은 정통적으로 버퍼풀 전체를 관리하는 잠금(세마포어)으로 인해 내부 잠금 경합을 많이 유발해왔는데, 이런 경함을 줄이기 위해 버퍼풀을 여러개로 쪼개어 관리할 수 있게 개선되었다.\n버퍼풀이 여러 개의 작은 버퍼풀로 쪼개지면서 개별 버퍼풀을 관리하는 잠금 자체도 경합이 분산되는 효과를 얻을 수 있게 된다.\ninnodb_buffer_pool_instances 시스템 변수를 이용해 버퍼풀을 여러개로 분리하여 관리할 수 있다.\n버퍼풀 구조 InnoDB 스토리지 엔진은 버퍼풀이라는 거대한 메모리 공간을 페이지 크기(innodb_page_size 시스템 변수에 설정된)의 조각으로 쪼개어 InnoDB 스토리지 엔진이 데이터를 필요로 할 때 해당 데이터 페이지를 읽어서 각 조각에 저장한다.\n버퍼풀의 페이지 조각을 관리하기 위해 LRU(least Recently Used) 리스트와, 플러시(Flush) 리스트, 프리(Free) 리스트라는 3개의 자료 구조를 관리한다.\nLRU 리스트: 디스크로부터 읽어온 페이지 저장하는 자료구조. 읽어온 페이지를 최대한 오랫동안 버퍼풀의 메모리에 유지하여 디스크 읽기를 최소화 한다.\n플러시 리스트: 디스크로 동기화되지 않은 데이터를 가진 데이터 페이지(더티 페이지)의 변경 시점 기준의 페이지 목록을 관리한다.\n프리리스트: 버퍼풀에서 실제 사용자 데이터로 채워지지 않은 비어있는 페이지들의 목록. 사용자의 쿼리가 새로벡 디스크의 데이터 페이지를 읽어와야 하는 경우 사용된다.\nLRU 리스트 구조 LRU 리스트는, Old 서브리스트 영역은 LRU, New 서브리스트 영역은 MRU(Most Recently Used)가 합쳐진 방식으로 동작한다.\nNew 서브리스트의 Tail과 Old 서브리스트의 Head가 만나는 지점을 MidPoint라 하며 버퍼풀에 새로운 페이지가 들어올 경우 Old 서브리스트의 Head 부분에 저장한다.\nNew 서브리스트와 Old 서브리스트로 나눈 이유는?\n하나의 큐를 사용하여 페이지를 관리할 경우에 Head 또는 Tail에 페이지를 저장하는 방식을 생각해 볼 수 있다. Head에 저장될 경우 새로 관리되는 페이지가 사용되지 않더라도 오랜 시간동안 리스트에 남아 있게되고, Tail에 저장될경우 해당 페이지를 즉시 읽지 않는다면 리스트에 남아있지 않게 되어 의미가 없어질 수 있다.\n이를 위해 두개의 서브리스트로 나누고, 경험적으로 얻은 5/8 지점을 활용한 중간점 삽입 전략을 사용하는 것 같다.\n데이터를 찾는 과정 필요한 레코드가 저장된 데이터 페이지가 버퍼풀에 있는지 검사\nInnoDB 어댑티브 해시 인덱스를 이용해 페이지를 검색 해당 테이블의 인덱스(B-Tree)를 이용해 버퍼풀에서 페이지를 검색 버퍼풀에 이미 데이터 페이지가 있다면 해당 페이지의 포인터를 MRU 방향으로 승급 디스크에서 필요한 데이터 페이지를 버퍼풀에 적재하고, 적재된 페이지에 대한 포인터를 LRU 헤더 부분에 추가\n버퍼풀의 LRU 헤더에 적재된 데이터 페이지가 실제로 읽히면 MRU 헤더 부분으로 이동(Read Ahead와 같이 대량 읽기의 경우 디스크 페이지가 버퍼풀로 적재는 되지만 실제 쿼리에서 사용되지는 않을수도 있으며, 이련 경우는 MRU로 이동되지 않음)\n버퍼풀에 상주하는 데이터 페이지는 사용자 쿼리가 얼마나 최근에 접근했었는지에 따라 나이가 부여되며, 버퍼풀에 상주하는 동안 쿼리에서 오랫동안 사용되지 않으면 오래된 페이지는 버퍼풀에서 제거됨. 버퍼풀의 페이지가 쿼리에 의해 사용되면 나이가 초기회되고 MRU헤더 부분으로 옮겨진다.\n필요한 데이터가 자주 접근됐다면 해당 페이지의 인덱스 키를 어댑티브 해시 인덱스에 추가\n처음 한번 읽힌 데이터 페이지가 이후 자주 사용된다면 버퍼풀의 MRU 영역에서 살아남게 되고, 그렇지 않은 경우 새롭게 읽히는 데이터 페이지에 밀려 결과적으로 버퍼풀에서 제거된다.\n버퍼풀과 리두 로그 버퍼풀은 데이터 베이스 서버의 성능 향상을 위해 데이터 캐시와 쓰기 버퍼링이라는 두가지 용도가 있다. 따라서 메모리가 허용하는 만큼 크게 설정하면 데이터 캐시 공간을 키워 쿼리의 성능 높힐 수 있지만, 쓰기 버퍼링 성능 향상을 위해서는 버퍼풀과 리두 로그의 관계에 대해 이해하는 것이 중요하다.\n리두 로그(Redo Log)란? 리두 로그는 데이터베이스에 대한 모든 변경 내용을 기록하는 파일셋이다. 시스템 장애나 충돌이 발생했을 때 데이터의 내구성과 일관성을 보장하기 위해 사용된다.\n데이터베이스에 변경 사항이 발생하면, 먼저 선로깅(write-ahead logging)프로세스로 리두 로그에 쓰여지고 변경 내용이 리두 로그에 기록되면 데이터베이스에 적용된다.\n리두 로그 파일은 일반적으로 디스크에 저장되며, MySQL은 변경 사항을 순차적으로 기록한다. 리두 로그 파일이 가득 차면 MySQL은 \u0026ldquo;체크포인트(checkpoint)\u0026ldquo;를 수행하여 데이터베이스의 모든 더티 페이지(버퍼풀에서 수정된 페이지)를 디스크에 기록한 후, 로그 파일을 잘라내어 공간을 확보하게 된다.\nMySQL에서 리두 로그는 원형 버퍼 형식으로 저장되며, 채워지면 다음 변경 사항은 순환 방식으로 다음 사용 가능한 리두 로그 파일에 기록된다. 이를 통해 리두 로그에 변경 사항이 지속적으로 기록되어 시스템 충돌이나 장애가 발생하더라도 변경 사항을 손실하지 않도록 보장한다.\n버퍼풀과 리두 로그의 관계 버퍼풀은 디스크에서 읽은 상태로 전혀 변경되지 않은 클린 페이지(Clean Page)와 함께 INSERT, UPDATE, DELETE를 통해 변경된 데이터를 가진 더티 페이지(Duty Page)를 가지고 있다.\n데이터 변경이 발생하면 먼저 리두 로그에 기록되고 리두 로그는 더티 페이지와 대응하게 된다.\n데이터 변경이 반복되면 결국 리두 로그 파일을 기록할 수 없거나 버퍼풀 용량이 부족해지는데, 이를 대응하기 위해 체크포인트를 수행하여 모든 더티페이지를 디스크에 기록한 후, 리두 로그 파일을 잘라내어 공간을 확보한다.\n이러한 방식이 버퍼풀이 쓰기 버퍼의 역할을 수행하게 만들게 되는데, 이에 따라서 리두 로그 파일의 크기가 작을수록 버퍼풀의 크기가 크더라도 대응되는 더티 페이지가 적으므로 버퍼링으로 얻을 수 있는 효과가 적어지고, 리두 로그 파일이 클수록 체크포인트를 통해 디스크에 기록되는 데이터가 많아져 갑자기 많은 디스크 I/O를 발생 시킬 수 있다.\n따라서, 리두 로그 파일의 크기를 적절히 선택해야하며, 어렵다면 버퍼풀의 크기가 100GB 이하의 MySQL 서버에서는 리두 로그 파일의 전체 크기를 대략 5~10GB 수준으로 선택하고 필요할 때마다 조금씩 늘려가며 최적값을 찾는 것이 좋다.\n버퍼풀 플러시(Buffer Pool Flush) 버퍼풀에서 수정된 데이터 페이지를 디스크로 쓰는 과정으로 MySQL 5.6 버전까지는 InnoDB 스토리지 더티 페이지 플러시 기능이 급작스럽게 디스크 기록이 폭증해서 MySQL 서버의 사용자 쿼리 처리 성능에 영향을 받는 등 그다지 부드럽게 처리되지 않았다.\nMySQL 5.7 버전을 거쳐 8.0 버전으로 업그레이드되면서 대부분의 서비스에서는 더티 페이지 프러시에서 예전과 같이 폭증 현상은 발생하지 않았다. 따라서 InnoDB 스토리지 엔진의 더티 페이지 플러시 성능 문제가 발생하지 않는다면 관련 시스템 변수는 조절하지 않아도 괜찮다.\nInnoDB 스토리지 엔진은 버퍼풀에서 아직 디스크로 기록되지 않은 더티 페이지들을 성능상 악영향 없이 디스크에 동기화하기 위해 다음과 같이 2개의 플러시 기능을 백그라운드로 실행한다.\n플러시 리스트(Flush_list) 플러시 LRU 리스트(LRU_list) 플러시 플러시 리스트 플러시 InnoDB 스토리지 엔진은 리두 로그 공간의 재활용을 위해 주기적으로 오래된 리두 로그 엔트리가 사용하는 공간을 비운다. 이때 오래된 리두 로그 공간이 지워지려면 반드시 InnoDB 버퍼풀의 더티 페이지가 먼저 디스크로 동기화 돼야 한다.\n이를 위해 InnoDB 스토리지 엔진은 주기적으로 플러시 리스트(Flush_list) 플러시 함수를 호출하여 플러시 리스트에서 오래전에 변경된 데이터 페이지 순서대로 디스크에 동기화 하는 작업을 수행한다.\n이때 언제부터 얼마나 많은 더티 페이지를 한번에 디스크로 기록하느냐에 따라 사용자의 쿼리 처리가 악영향을 받지 않으면서 부드럽게 처리된다. 리를 위해 InnoDB 스토리지 엔진은 여러 시스템 변수를 제공한다.\ninnodb_page_cleaners InnoDB 스토리지 엔진에서 더티 페이지를 디스크로 동기화하는 스레드를 클리너 스레드(Cleaner Thread)라고 하고, 클리너 스레드의 개수를 조정할 수 있게 해준다.\n설정값이 버퍼풀 인스턴스 개수보다 많은 경우 innodb_buffer_pool_instances 설정값으로 자동으로 변경하여, 하나의 클리너 스레드가 하나의 버퍼풀 인스턴스를 처리하도록 한다.\n시스템 변수의 설정값이 버퍼풀 인스턴스 개수보다 적은 경우 하나의 클리너 스레드가 여러 개의 버퍼풀 인스턴스를 처리하므로, innodb_page_cleaners 설정값은 innodb_buffer_pool_instances 설정 값과 동일하게 설정하는 것이 좋다.\ninnodb_max_dirty_pages_pct InnoDB 버퍼풀은 클린 페이지와 더티 페이지를 함께 가지고 있어 뭏란정 더티 페이지를 그대로 유지할 수 없다. 기본적으로 InnoDB 스토리지 엔진은 전체 버퍼풀이 가진 페이지의 90%까지 더티페이지를 가질 수 있는데, innodb_max_dirty_pct 시스템 변수를 이용해 더티페이지의 비율을 조절할 수 있다.\n일반적으로 버퍼풀이 더티페이지를 많이 가지고 있을수록 디스크 쓰기 작업을 버퍼링함으로써 I/O 작업을 줄일 수 있으므로 기본값으로 유지하는 것이 좋다.\ninnodb_max_dirty_pages_pct_lwm InnoDB 스토리지 엔진은 innodb_io_capacity 시스템 변수에 설정된 값을 기준으로 더티 페이지 쓰기를 실행하는데, 디스크로 기록되는 더티페이지 개수보다 더 많은 더티페이지가 발생하면 버퍼풀에 더티페이지가 계속 증가하게 되고, 지정한 비율이 넘어가면 더티페이지를 디스크로 기록하여 디스크 쓰기 폭발(Dist IO Bust) 현상이 발생할 가능성이 있다.\n이런 문제를 완화하기 위해 innodb_max_dirty_pages_pct_lwm 시스템 설정 변수를 이용해 일정 수준 이상의 더티페이지가 발생하면 조금씩 더티 페이지를 디스크로 기록한다.\n기본값은 10% 정도로, 디스크 쓰기가 많이 발생하고 더티 페이지 비율이 낮은 상태를 유지한다면 높은 값으로 조정할 수 있다.\ninnodb_io_capacity, innodb_io_capacity_max 데이터베이스 서버에서 어느정도의 디스크 IO가 가능한지 설정하는 값이다. innodb_io_capacity는 일반적인 상황에서 디스크가 적절히 처리할 수 있는 수준의 값을 설정하며, innodb_io_capacity_max는 디스크가 최대 성능을 발휘할 때 어느 정도 IO가 가능한지를 설정한다.\n여기서 언급되는 IO는 InnoDB 스토리지 엔진의 백그라운드 스레드가 수행하는 디스크 작업을 의미하며, 대부분 더티페이지 쓰기이다.\n스토리지 엔진은 사용자의 쿼리를 처리하기 위해 디스크를 읽기도 해야하므로 하드웨어 성능에 무조건 맞추는 것은 좋지 않다.\ninnodb_adaptive_flushing, innodb_adaptive_flushing_lwm 어댑티브 플러시를 활성화 하면 InnoDB 스토리지 엔진은 버퍼불의 더티 페이지 비율이나 innodb_io_capacity, innodb_io_capacity_max 설정 값에 의존하지 않고 알고리즘을 사용한다.\n더티 페이지는 리두 로그와 대응하므로, 리두 로그가 어느정도 증가하는지 분석하여 확인할 수 있다. 어댑티브 플러시 알고리즘은 리두 로그의 증가 속도를 분석하여 적절한 수준의 더티 페이지가 버퍼풀에 유지될 수 있도록 디스크 쓰기를 실행한다.\ninnodb_adaptive_flushing는 기본값이 활성이며, innodb_adaptive_flushing_lwm는 어댑티브 플러시 알고리즘 활성을 위한 활성 리두 공간의 하한 비율을 의미한다.\ninnodb_flush_neighbors 더티페이지를 디스크에 기록할 때 디스크에서 근접한 페이지 중 더티페이지가 있다면 InnoDB 스토리지 엔진이 함께 묶어 디스크로 기록하게 해주는 기능을 활성화 할지 결정한다.\n과거에는 HDD의 경우 IO 비용이 높아 최대한 줄이기 위해 만들어졌다.\n데이터 저장을 하드디스크로 하고있다면 1, 2 정도로 활성화 하고, SSD를 사용한다면 기본값인 비활성으로 유지하는 것이 좋다.\nLRU 리스트 플러시 InnoDB 스토리지 엔진은 LRU 리스트에서 사용 빈도가 낮은 데이터 페이지들을 제거하여 새로운 페이지들을 읽어올 공간을 만들어야 하는데, 이를 위해 LRU 리스트 플러시 함수가 사용된다.\n리스트 끝부분 부터 시작하여 최대 innodb_lru_scan_depth 시스템 변수에 설정된 수만큼의 페이지들을 스캔하는데, 이때 더티체이지는 디스크에 동기화하고, 클린 페이지는 즉시 프리 리스트로 페이지를 옮긴다.\nInnoDB 스토리지 엔진은 버퍼풀 인스턴스 별로 최대 innodb_lru_scan_depth 개수만큼 스캔하기 때문에 실질적으로 LRU 리스트의 스캔은 (innodb_buffer_pool_instances * innodb_lru_scan_depth) 수만큼 수행하게 된다.\n버퍼풀 상태 백업 및 복구 InnoDB 서버의 버퍼풀은 쿼리의 성능에 매우 밀접하게 연결돼 있다. 서버 재실행시 버퍼풀에 쿼리들이 사용할 데이터가 없어 성능이 매우 떨어지게 된다.\n디스크의 데이터가 버퍼풀에 적재돼 있는 상태를 위밍업(Warming Up)이라고 표현하는데, 워밍업 상태에 따라 몇십 배 쿼리 처리속도 차이가 발생하게 된다.\nMySQL 5.5 버전은 재실행시 강제 워밍업을 위해 주요 테이블과 인덱스에 대해 풀스캔을 실행하고 서비스를 오픈했었다. 하지만 5.6 버전부터는 버퍼풀 덤프 및 적재 기능이 도입되어 MySQL 서버 셧다운 전 innodb_buffer_pool_dump_now 시스템 변수를 이용해 현재 InnoDB 버퍼풀 상태를 백업할 수 있다.\n1 2 3 4 5 /* 버퍼풀 상태 백업 */ SET GLOBAL innodb_buffer_pool_dump_now=ON; /* 백업된 버퍼풀 상태 복구 */ SET GLOBAL innodb_buffer_pool_load_now=ON; 버퍼풀 백업을 수행하면 데이터 디렉터리에 ib_buffer_pool이라는 파일로 생성되는데, InnoDB 스토리지 엔진이 버퍼풀의 LRU 리스트에서 적재된 데이터 페이지의 메타 정보만 가져와 저장하여, 버퍼풀이 크다고 하더라도 몇십 MB 이하로 작다.\n하지만 버퍼풀로 복구하는 과정에서 각 테이블의 데이터 페이지를 디스크에서 다시 읽어와야 하기 때문에 버퍼풀의 크기에 따라 매우 오래 걸릴 수 있다.\n1 SHOW STATUS LIKE \u0026#39;Innodb_buffer_pool_dump_status\u0026#39;\\G InnoDB의 버퍼풀을 복구하는 작업은 상당히 많은 디스크 읽기를 필요로 하기 때문에, 복구중 서비스 재개하는 것은 좋지 않을 수 있다. 버퍼풀 적재 작업을 중지하려면 innodb_buffer_pool_load_abort 시스템 변수를 통해 중지하여 재개하는 것을 권장한다.\n1 SET GLOBAL innodb_buffer_pool_load_abort=ON; 백업 및 복구 자동화 InnoDB 스토리지 엔진은 innodb_buffer_pool_dump_at_shutdown, innodb_buffer_pool_load_at_shutdown 설정을 MySQL 설정 파일에 넣으면 서버가 셧다운 되기 직전에 버퍼풀의 백업을 실행하고, MySQL 서버가 시작되면 자동으로 백업된 버퍼풀의 상태를 복구할 수 있는 기능을 제공한다.\n버퍼풀의 적재 내용 확인 MySQL 5.6 버전부터 MySQL 서버의 information_schema 데이터베이스의 innodb_buffer_page 테이블을 이용해 InnoDB 버퍼풀의 메모리에 어떤 테이블의 페이지들이 적재돼 있는지 확인할 수 있었다. 하지만 버퍼풀이 큰 경우에는 테이블 조회가 상당히 큰 부하를 일으키면서 서비스 쿼리가 많이 느려지는 문제가 있어, 실제 서비스용으로 사용되는 MySQL 서버에서는 버퍼풀의 상태를 확인하는 것이 거의 불가능했다.\nMySQL 8.0 버전에서는 information_schema 데이터베이스에 innodb_cached_indexes 테이블이 새로 추가되어, 테이블의 인덱스별로 데이터 페이지가 얼마나 InnoDB 버퍼풀에 적재돼 있는지 확인할 수 있다.\n1 2 3 4 5 6 7 8 9 SELECT it.name table_name ,ii.name index_name ,ici.n_cached_pages n_cached_pages FROM information_schema.innodb_tables it JOIN information_schema.innodb_indexes ii ON ii.table_id = it.table_id JOIN information_schema.innodb_cached_indexes ici ON ici.index_id = ii.index_id WHERE it.name=CONCAT(\u0026#39;employees\u0026#39;, \u0026#39;/\u0026#39;, \u0026#39;employees\u0026#39;) ; 아직 MySQL 서버는 개별 인덱스별로 전체 페이지 개수가 몇 개인지는 사용자에게 알려주지 않기 때문에 information_schema의 테이블을 이용해도 테이블의 인덱스별로 페이지가 InnoDB 버퍼풀에 적재된 비율은 확인할 수가 없다.\n","date":"2023-04-12T14:27:41+09:00","image":"https://codemario318.github.io/post/real_mysql_4_2_2/real_mysql_hu03b8ff0acb6f52b3ec9ae95e616f82c2_25714_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/real_mysql_4_2_2/","title":"4.2 InnoDB 스토리지 엔진 아키텍처(2) - InnoDB 버퍼풀"},{"content":"\nInnoDB는 MySQL에서 사용할 수 있는 스토리지 엔진 중 거의 유일하게 레코드 기반 잠금을 제공하며, 그 때문에 높은 동시성 처리가 가능하고 안정적이며 성능이 뛰어나다.\n프라이머리 키에 의한 클러스터링 InnoDB의 모든 테이블은 기본적으로 프라이머리 키를 기준으로 클러스터링되어 자장된다.\n프라이머리 키 값의 순서대로 디스크에 저장되며, 모든 세컨더리 인덱스는 레코드의 주소 대신 프라이머리 키의 값을 논리적인 주소로 사용한다. 프라이머리 키가 클러스터링 인덱스이기 때문에 프라이머리 키를 이용한 레인지 스캔은 상당히 빨리 처리될 수 있다. 쿼리의 실행계획에서 프라이머리 키는 기본적으로 다른 보조 인덱스에 비해 비중이 높게 설정된다. 외래 키 지원 외래 키에 대한 지원은 InnoDB 스토리지 엔진 레벨에서 지원하는 기능으로 MyISAM이나 MEMORY 테이블에서는 사용할 수 없다.\n외래 키는 데이터베이스 서버 운영의 불편함 때문에 서비스용 데이터베이스에서는 생성하지 않는 경우도 자주 있다. 그렇다 하더라도 개발 환경의 데이터베이스에서는 좋은 가이드 역할을 할 수 있다.\nInnoDB에서 외래 키는 부모 테이블과 자식 테이블 모두 해당 칼럼에 인덱스 생성이 필요함 변경 시에는 반드시 부모 테이블이나 자식 테이블에 데이터가 있는지 체크하는 작업이 필요하므로, 잠금이 여러 테이블로 전파됨 그로인한 데드락이 발생할 때가 많으므로 개발할때도 외래 키의 존재에 주의하는 것이 좋음 수동으로 데이터를 적재하거나 스키마 변경 등의 관리 작업이 실패할 수 있다. 부모 테이블과 자식 테이블의 관계를 명확히 파악해서 순서대로 작업한다면 문제없이 실행될 수 있지만 외래키가 복잡하게 얽힌 경우에는 간단하지 않다.\nforeign_key_checks 시스템 변수를 OFF로 설정하면 외래키 관계에 대한 체크 작업을 일시적으로 멈출 수 있다. 외래키 체크 작업을 일시적으로 멈추면 대략 레코드 적재나 삭제 등의 작업도 부가적인 체크가 필요 없기 때문에 훨씬 빠르게 처리할 수 있다.\n1 2 3 4 5 SET foreign_key_checks=OFF; /* 작업 수행 ... */ SET foreign_key_checks=ON; 외래키 체크를 일시적으로 중지한 상태에서 외래키 관계를 가진 부모 테이블의 레코드를 삭제했다면 반드시 자식 테이블의 레코드도 살제하여 일관성을 맞춰준 후 다시 외래키 체크 기능을 활성화 해야 한다.\nforeign_key_checks가 비활성화되면 외래키 관계의 부모 테이블에 대한 작업도 무시한다.(ON DELETE CASCADE, ON UPDATE CASCADE)\nMVCC - Multi Version Concurrency Control 일반적으로 레코드 레벨의 트랜잭션을 지원하는 DBMS가 제공하는 기능이며, MVCC의 가장 큰 목적은 잠금을 사용하지 않는 일관된 읽기를 제공하는 데 있다.\nInnoDB는 언두 로그(Undo log)를 이용해 이 기능을 구현한다.\n멀티 버전: 하나의 레코드에 대해 여러 개의 버전이 동시에 관리 1 2 3 4 5 6 7 CREATE TABLE member ( m_id INT NOT NULL, m_name VARCHAR(20) NOT NULL, m_area VARCHAR(100) NOT NULL, PRIMARY KEY (m_id), INDEX ix_area (m_area) ); 1 2 INSERT INTO member (m_id, m_name, m_area) VALUES (12, \u0026#39;홍길동\u0026#39;, \u0026#39;서울\u0026#39;); COMMIT; 1 UPDATE member SET m_area=\u0026#39;경기\u0026#39; WHERE m_id=12; UPDATE 문장이 실행되면 커밋 실행 여부와 관계 없이 InnoDB의 버퍼풀은 새로운 값인 ‘경기’로 업데이트 된다. 그리고 디스크의 데이터 파일에는 체크포인트나 InnoDB의 Write 스레드에 의해 새로운 값으로 업데이트돼 있을 수도 있고 아닐 수도 있다.(InnoDB가 ACID를 보장하기 때문에 일반적으로는 InnoDB의 버퍼풀과 데이터 파일은 동일한 상태라고 가정해도 무방함)\n아직 COMMIT이나 ROLLBACK이 되지 않은 상태에서 다른 사용자가 다음 같은 쿼리로 작업 중인 레코드를 조회한다면, MySQL 서버의 시스템 변수(transaction_isolation)에 설정된 격리 수준(Isolation level)에 따라 다르다.\nREAD_UNCOMMITED: InnoDB 버퍼풀이 현재 가지고 있는 변경된 데이터를 읽어서 반환한다. READ_COMMITTED, REPEATABLE_READ, SERIALIZABLE: 아직 커밋되지 않았기 때문에 InnoDB 버퍼풀이나 데이터 파일에 있는 내용 대신 변경되기 이전의 내용을 보관하고 있는 언두 영역의 데이터를 반환한다. 이러한 과정을 DBMS에서는 MVCC라고 표현한다. 즉 하나의 레코드(회원번호가 12인 레코드)에 대해 2개의 버전이 유지되고, 필요에 따라 어느 데이터가 보여지는지 여러 가지 상황에 따라 다르다.\n트랜잭션이 길어지면 언두에서 관리하는 예전 데이터가 삭제되지 못하고 오랫동안 관리되어야 하며, 자연히 언두 영역이 저장되는 시스템 테이블 스페이스의 공간이 많이 늘어나는 상황이 발생할 수 있다.\nUPDATE 쿼리가 실행되면 InnoDB 버퍼 풀은 즉시 새로운 데이터로 변경되고 기존 데이터는 언두영역으로 복사된다.\nCOMMIT: InnoDB는 더 이상의 변경 작업 없이 지금의 상태를 영구적인 데이터로 만들어 버린다. ROLLBACK: 언두 영역에 있는 백업된 데이터를 InnoDB 버퍼 풀로 다시 복구하고, 언두 영역의 내용을 삭제한다. 커밋이 된다고 언두 영역의 백업 데이터가 항상 바로 삭제되지는 않고, 언두 영역을 필요로 하는 트랜잭션이 없을때 삭제된다.\n잠금 없는 일관된 읽기 - Non-Locking Consistent Read InnoDB 스토리지 엔진은 MVCC 기술을 이용해 감금을 걸지 않고 읽기 작업을 수행한다. 잠금을 걸지 않기 때문에 InnoDB에서 읽기 작업은 다른 트랜잭션이 가지고 있는 잠금을 기다리지 않고, 읽기 작업이 가능하다.\n격리수준이 SERIALIZABLE이 아닌 READ_UNCOMMITED나 READ_COMMITED, REPEATEABLE_READ 수준인 경우 INSERT와 연결되지 않은 순수한 읽기(SELECT) 작업은 다른 트랜잭션의 변경 작업과 관계 없이 항상 잠금을 대기하지 않고 바로 실행된다.\n특정 사용자가 레코드를 변경하고 아직 커밋을 수행하지 않았다 하더라도 변경 트랜잭션이 다른 사용자의 SELECT 작업을 방해하지 않는다. 이를 ‘잠금 없는 일관된 읽기’ 라고 표현하며, InnoDB에서는 변경되기 전의 데이터를 읽기 위해 언두 로그를 사용한다.\n오랜 시간 동안 활성 상태인 트랜잭션으로 인해 MySQL 서버가 느려지거나 문제가 발생할 때가 가끔 있는데, 일관된 읽기를 위해 언두 로그를 삭제하지 못하고 계속 유지해야 하기 때문에 발생하는 문제이다.\n따라서 트랜잭션이 시작됐다면 가능한 빨리 롤백이나 커밋을 통해 트랜잭션을 완료하는 것이 좋다.\n자동 데드락 감지 InnoDB 스토리지 엔진은 내부적으로 잠금이 교착 상태에 빠지지 않았는지 체크하기 위해 잠금 대기 목록(Wait-for List)을 그래프 형태로 관리한다. InnoDB 스토리지 엔진은 데드락 감지 스레드를 통해 주기적으로 잠금 대기를 그래프를 검사해 교착 상태에 빠진 트랜잭션들을 찾아서 그중 하나를 강제 종료한다.\n트랜잭션의 언두 로그양이 적은 트랜잭션이 롤백 해도 처리한 내용이 적기 때문에 선택된다.\nInnoDB 스토리지 엔진은 상위 레이어인 MySQL 엔진에서 관리되는 테이블 잠금(LOCK TABLES 명령으로 잠긴 테이블)은 볼 수가 없어 데드락 감지가 불확실 할 수 있는데, innodb_table_locks 시스템 변수를 활성화 하면 InnoDB 스토리지 엔진 내부의 레코드 잠금뿐만 아니라 테이블 레벨의 잠금 까지 감지할 수 있게 된다.\n일반적인 서비스에서는 데드락 감지 스레드가 데드락을 찾아내는 작업은 부담되지 않지만, 동시 처리 스레드가 매우 많아지거나 트랜잭션이 가진 잠금 개수가 많아지면 데드락 감지 스레드가 느려진다.\n데드락 감지 스레드는 잠금 목록을 검사해야 하기 때문에 잠금 상태가 변경되지 않도록 잠금 목록이 저장된 리스트(잠금 테이블)에 새로운 잠금을 걸고 데드락 스레드를 찾게 되는데, 데드락 감시 스레드가 느려지면 서비스 쿼리를 처리중인 스레드는 더는 작업을 진행하지 못하고 대기하며 서비스에 악영항을 미치게 된다. 이렇게 동시 처리 스레드가 매우 많은 경우 데드락 감지 스레드는 더 많은 CPU 자원을 소모할 수도 있다.\ninnodb_deadlock_detect 시스템 변수를 활용하여 데드락 감지 스레드를 비활성화 할 수 있다. 이럴 경우 데드락 상황 발생시 무한정 대기할 수도 있지만, innodb_lock_wait_timeout 시스템 변수를 활성화하면 일정 시간이 지났을 경우 요청 실패하고 에러 메시지를 반환하게 만들 수 있다.\n데드락 감시 스레드가 부담되어 innodb_deadlock_detect를 OFF로 설장해서 비활성화 하는 경우에는 innodb_lock_time_wait_timeout을 기본값인 50초보다 훨씬 낮은 시간으로 변경하여 사용할 것을 권장한다.\n자동화된 장애 복구 InnoDB에는 손실이나 장애로 부터 데이터를 보호하기 위한 여러가지 메커니즘이 탑재돼있다. 그러한 메커니즘을 이용해 MySQL 서버가 시작될 때 완료되지 못한 트랜잭션이나 디스크에 일부만 기록된(Partial write)데이터 페이지 등에 대한 인련의 복구 작업이 자동으로 진행된다.\nInnoDB 스토리지 엔진은 매우 견고해서 데이터 파일이 손상되거나 MySQL 서버가 시작되지 못하는 경우는 거의 발생하지 않지만, 디스크나 하드웨어 이슈로 InnoDB 스토리지 엔진이 자동으로 복구를 못 하는 경우도 발생할 수 있는데, 한번 문제가 생기면 복구하기 쉽지 않다.\nInnoDB 데이터 파일은 기본적으로 서버가 시작될 때 자동 복구를 수행하며, 자동으로 복구될 수 없는 손상이 있다면 서버가 종료된다.\n장애 복구 대응 MySQL 서버의 설정 파일에 innodb_force_recovery 시스템 변수를 설정하여 시작해야 한다.\n6: 로그 파일 손상 1: 테이블의 데이터 파일이 손상 어떤 부분이 문제인지 알 수 없다면 1~6까지 변경하며 재실행 이후 서버가 가동되고 InnoDB 테이블이 인식된다면 mysqldump를 이용해 데이터를 가능한 만큼 백업하고 그 데이터로 MySQL 서버의 DB와 테이블을 다시 생성하는 것이 좋다.\nInnoDB_force_recovery 옵션 1(SRV_FORCE_IGNORE_CORRUPT):\n테이블스페이스의 데이터나 인덱스 페이지에서 손상된 부분이 발견되도 무시하고 서버를 시작한다. \u0026lsquo;Database page corruption on disk or a failed\u0026rsquo; 출력되는 경우가 많다. mysqldump나 SELECT INTO OUTFILE ...를 이용해 덤프하여 데이터베이스를 다시 구축하는 것이 좋다. 2(SRV_FORCE_NO_BACKGROUND):\n백그라운드 스레드 가운데 메인 스레드를 시작하지 않고 MySQL 서버를 시작한다. 메인 스레드가 언두 데이터를 삭제하는 과정에서 장애가 발생했을때 사용 3(SRV_FORCE_NO_TRX_UNDO):\n일반적으로 MySQL 서버는 재실행시 언두 영역의 데이터를 먼저 파일에 적용하고 리두 로그의 내용을 다시 덮어써서 장애 시점의 데이터 상태를 만들어 낸 후, 최종적으로 커밋되지 않은 트랜잭션의 작업을 롤백하지만 3으로 설정시 롤백하지 않고 그대로 나둔다. 커밋되지 않고 종료된 트랜잭션은 계속 그 상태로 남아있게 된다. 백업 후 데이터베이스를 다시 구축하는 것이 좋다. 4(SRV_FORCE_NO_IBUF_MERGE):\nInnoDB는 INSERT, UPDATE, DELETE 등의 데이터 변경으로 인한 인덱스 변경 작업을 상황에 따라 즉시처리 혹은 버퍼에 두고 나중에 처리할 수 있다. 인서트 버퍼를 통해 처리가 될 경우, 비정상 종료시 병합 될지 알 수 없기 때문에, 인서트 버퍼의 손상을 감지하면 에러를 발생시켜 MySQL 서버의 실행을 막는다. 인서트 버퍼의 내용을 무시하고 강제로 MySQL을 실행시킨다. 인서트 버퍼는 실제 데이터와 관련된 부분이 아니라, 인덱스에 관련된 부분이므로 테이블을 텀프한 후 다시 데이터베이스를 구축하면 데이터의 손실 없이 복구할 수 있다. 5(SRV_FORCE_NO_UNDO_LOG_SCAN):\nMySQL 서버가 종료되는 시점에 처리중인 트랜잭션이 있을 경우 별도의 처리 없이 커넥션을 강제로 끊어버리고 종료된다. MySQL 서버가 재실행되면 InnoDB 엔진은 언두 레코드를 이용해 데이터 페이지를 복구하고 리두 로그를 적용해 종료 시점의 상태로 만들고, 커밋되지 않은 트랜잭션에서 변경한 작업은 모두 롤백 처리한다. 이때 InnoDB 스토리지 엔진이 언두 로그를 사용할 수 없다면 에러가 발생하여 MySQL 서버가 실행될 수 없다. 언두 로그를 모두 무시하고 실행한다. MySQL 서버가 종료되던 시점에 커밋되지 않았던 작업도 모두 커밋된 것처럼 처리되어 잘못된 데이터가 남을 수 있다. 데이터를 백업하고, 데이터베이스를 새로 구축해야한다. 6(SRV_FORCE_NO_LOG_REDO):\nInnoDB 스토리지 엔진의 리두 로그가 손상되면 MySQL 서버가 실행되지 못한다. 해당 복구 모드로 실행하면 리두 로그를 무시하고 서버가 실행된다.\n트랜잭션이 커밋됐다 하더라도 리두 로그에만 기록되고 데이터 파일에 기록되지 않은 데이터는 모두 무시되므로 마지막 체크 포인트시점의 데이터만 남게 된다. 기존 InnoDB의 리두 로그는 모두 삭제 또는 백업하고 MySQL 서버를 시작하는 것이 좋다. 데이터를 백업하고 MySQL 서버를 새로 구축하는 것이 좋다. 위 방법을 수행해도 MySQL서버가 시작되지 않으면 백업을 이용해 다시 구축하는 방법밖에 없다. 백업이 있다면 마지막 백업으로 데이터베이스를 다시 구축하고, 바이너리 로그를 사용해 최대한 장애 시점까지의 데이터를 복구할 수도 있다.\n마지막 풀 백업 시점부터 장애 시점까지의 바이너리 로그가 있다면 이용하는 것이 데이터 손실이 더 적을 수 있다.\n백업은 있지만 복제의 바이너리 로그가 없거나 손실되었다면, 마지막 백업 시점가지만 복구할 수 있다.\n","date":"2023-04-11T19:15:11+09:00","image":"https://codemario318.github.io/post/real_mysql_4_2_1/real_mysql_hu03b8ff0acb6f52b3ec9ae95e616f82c2_25714_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/real_mysql_4_2_1/","title":"4.2 InnoDB 스토리지 엔진 아키텍처(1)"},{"content":"MySQL의 전체 구조 MySQL 서버는 크게 MySQL 엔진과 스토리지 엔진으로 구분할 수 있다.\n사람으로 비유하면 MySQL 엔진은 머리 역할을 담담하고, 스토리지 엔진은 손과 발의 역할을 담당한다.\nMySQL 엔진 MySQL 엔진은 요청된 SQL 문장을 분석하거나 최적화하는 등 DBMS의 두뇌에 해당하는 처리를 수행한다.\n커넥션 핸들러: 클라이언트 요청에 따라 새로운 연결을 생성하고 관리 SQL 파서 및 전처리기: SQL 쿼리를 최적화 및 실행하기 전에 구문 분석 및 전처리를 담당 옵티마이저: 쿼리의 최적화 MySQL은 표준 SQL(ANSI SQL) 문법을 지원하기 때문에 표준 문법에 따라 작성된 쿼리는 타 DBMS와 호환되어 실행될 수 있다.\n스토리지 엔진 스토리지 엔진은 실제 데이터를 디스크 스토리지에 저장하거나 디스크 스토리지로부터 데이터를 읽어오는 역할 수행한다.\nMySQL 서버에서 MySQL엔진은 하나지만 스토리지 엔진은 여러 개를 동시에 사용할 수 있다.\n1 CREATE TABLE test_table (fd1 INT, fd2 INT) ENGINE=INNODB; 위처럼 테이블이 사용할 스토리지 엔진을 지정하면 해당 테이블의 모든 읽기 작업과 변경 작업은 정의된 스토리지 엔진이 처리한다.\n각 스토리지 엔진은 성능 향상을 위해 키 캐시(MyISAM), 버퍼풀(InnoDB) 같은 기능을 내장하고 있다.\n핸들러 API MySQL 엔진의 쿼리 실행기에서 데이터를 쓰거나 읽어야 할 때는 스토리지 엔진에 쓰기 또는 읽기를 요청하는데, 이러한 요청을 핸들러 요청이라고 하며, 사용되는 API를 핸들러 API라고 한다.\nInnoDB 스토리지 엔진 또한 이 핸들러 API를 이용해 MySQL 엔진과 데이터를 주고 받는다.\n핸들러 API를 통해 발생한 작업은 아래 쿼리로 확인 가능하다.\n1 SHOW GLOBAL STATUS LIKE \u0026#39;Handler%\u0026#39;; MySQL 스레딩 구조 MySQL 서버는 프로세스 기반이 아니라 스레드 기반으로 동작한다.\nMySQL 서버에서 실행 중인 스레드 목록은 performance_schema 데이터베이스에 threads 테이블을 통해 확인할 수 있다.\n1 2 3 4 5 6 7 8 9 SELECT thread_id ,name ,type ,processlist_user ,processlist_host FROM performance_schema.threads ORDER BY type,thread_id ; 백그라운드 스레드의 개수는 MySQL 서버의 설정 내용에 따라 가변적일 수 있다. 동일한 스레드가 2개 이상씩 보이는 것은 MySQL 서버의 설정 내용에 의해 여러 스레드가 동일 작업을 병렬로 처리하는 경우이다.\n포그라운드 스레드(클라이언트 스레드) 포그라운드 스레드는 클라이언트 연결 요청을 처리하고 데이터베이스 작업을 수행한다. 이러한 스레드는 쿼리 실행 중에 CPU 및 I/O 리소스를 사용하므로, 성능에 중요한 역할을 한다.\n포그라운드 스레드는 최소한 MySQL 서버에 접속된 클라이언트의 수만큼 존재하며, 주로 각 클라이언트 사용자가 요청하는 쿼리 문장을 처리한다.\n클라이언트 사용자가 작업을 마치고 커넥션을 종료하면, 해당 커넥션을 담당하던 스레드는 다시 스레드 캐시로 돌아간다.\n이때 이미 스레드 캐시에 일정 개수 이상의 대기중인 스레드가 있으면 스레드 캐시에 넣지 않고 스레드를 종료시켜 일정 개수의 스레드만 스레드 캐시에 존재하게 한다.\n스레드 캐시에 유지할 수 있는 최대 스레드 개수는 thread_cache_size 시스템 변수로 설정한다.\n포그라운드 스레드는 데이터를 MySQL 데이터 버퍼나 캐시로 부터 가져오며, 버퍼나 캐시에 없는 경우 직접 디스크의 데이터나 인덱스 파일로부터 데이터를 읽어와서 작업을 처리한다.\nMyISAM: 디스크 쓰기 작업까지 포그라운드 스레드가 처리 InnoDB: 데이터 버퍼나 캐시까지만 포그라운드 스레드가 처리 백그라운드 스레드 MyISAM의 경우 해당 사항이 별로 없지만, InnoDB는 다음과 같이 여러가지 작업이 백그라운드로 처리된다.\n인서트 버퍼(Insert Buffer)를 병합하는 스레드 로그를 디스크로 기록하는 스레드 InnoDB 버퍼풀의 데이터를 디스크에 기록하는 스레드 데이터 버퍼로 읽어 오는 스레드 잠금이나 데드락을 모니터링 하는 스레드 모두 중요한 역할을 수행하지만 로그 스레드와 버퍼의 데이터를 디스크로 내려쓰는 작업을 처리하는 쓰기 스레드(Write thread)가 특히 중요하다.\nMySQL 5.5 버전부터 데이터 쓰기 스레드와 데이터 읽기 스레드의 개수를 2개 이상 지정할 수 있게 됐으며, innodb_write_io_thread, innodb_read_io_threads 시스템 변수로 스레드의 개수를 설정한다.\nInnoDB에서도 데이터를 읽는 작업은 주로 클라이언트 스레드에서 처리되기 때문에 읽기 스레드는 많이 설정할 필요는 없지만, 쓰기 스레드는 아주 많은 작업을 백그라운드로 처리하기 때문에 일반적인 내장 디스크를 사용할때는 2~4 정도, DAS, SAN과 같은 스토리지를 사용할 때는 디스크를 최적으로 사용할 수 있을 만큼 충분히 설정하는 것이 좋다.\n사용자의 요청을 처리하는 도중 데이터의 쓰기 작업은 지연(버퍼링)되어 처리될 수 있지만 데이터의 읽기 작업은 절대 지연될 수 없다. 일반적인 상용 DBMS에는 대부분 쓰기 작업을 버퍼링해서 일괄 처리하는 기능이 있다.\nInnoDB: INSERT, UPDATE, DELETE 쿼리로 데이터가 변경되는 경우 데이터가 디스크의 데이터 파일로 완전히 저장될 때까지 기다리지 않아도 된다. MyISAM: 사용자 스레드가 쓰기 작업까지 함께 처리하도록 설계되어, 일반적인 쿼리는 쓰기 버퍼링 기능을 사용할 수 없다. 메모리 할당 및 사용 구조 글로벌 메모리 영역과 로컬 메모리 영역으로 구분되며, 서버 내에 존재하는 많은 스레드가 공유해서 사용하는 공간인지 여부에 따라 구분된다.\n글로벌 메모리 영역 일반적으로 클라이언트 스레드의 수와 무관하게 하나의 메모리 공간만 할당된다. 필요에 따라 2개 이상의 메모리 공간을 할당받을 수도 있지만 클라이언트의 스레드 수와 무관하며, 생성된 글로벌 영역이 N개라 하더라도 모든 스레드에 의해 공유된다.\n테이블 캐시 InnoDB 버퍼풀 InnoDB 어댑티드 해시 인덱스 InnoDB 리두 로그 버퍼 등이 대표적인 글로벌 메모리 영역이다.\n로컬 메모리 영역 세션 메모리 영역이라고도 표현하며, MySQL 서버상에 존재하는 클라이언트 스레드가 쿼리를 처리하는 데 사용하는 메모리 영역이다.\n정렬 버퍼 조인 버퍼 바이너리 로그 캐시 네트워크 버퍼 MySQL 서버에 클라이언트가 접속하면, 클라이언트 커넥션(세션)으로부터의 요청을 처리하기 위해 스레드를 하나씩 할당하게 되는데, 클라이언트 스레드가 사용하는 메모리 공간이라고 해서 클라이언트 메모리 영역이라고도 한다.\n로컬 메모리는 각 클라이언트 스레드별로 독립적으로 할당되며 절대 공유되어 사용되지 않는다.\n일반적으로 글로벌 메모리 영역의 크기는 주의해서 설정하지만 소트 버퍼와 같은 오컬 메모리 영역은 크게 신경 쓰지 않고 설정하는데, 최악의 경우 MySQL 서버가 메모리 부족으로 멈춰 버릴수도 있으므로 적절한 메모리 공간을 설정하는 것이 중요하다.\n커넥션이 열러있는 동안 계속 할당된 상태로 남아있는 경우: 커넥션 버퍼, 결과 버퍼 쿼리를 실행하는 순간에만 할당: 소트 버퍼, 조인 버퍼 플러그인 스토리지 엔진 모델 MySQL의 독특한 구조 중 대표적인 중 하나가 플러그인 모델이다.\n스토리지 엔진 검색 엔진을 위한 검색어 파서 사용자의 인증을 위한 Native Authentication, Caching SHA-2 Authentication 등 MySQL은 이미 기본적으로 많은 스토리지 엔진을 가지고 있지만, 필요에 의해 직접 스토리지 엔진을 만드는 것도 가능하다.\nMySQL에서 쿼리가 실행되는 과정을 보면 대부분 작업이 MySQL엔진에서 처리되고, 마지막 데이터 읽기, 쓰기 작업만 스토리지 엔진에 의해 처리한다.\nGROUP BY, ORDER BY 등 복잡한 처리는 스토리지 엔진 영역이 아니라 MySQL 엔진의 처리 영역인 쿼리 실행기에서 처리된다.\n스토리지 엔진에 따라 데이터 읽기/쓰기 작업 처리 방식이 크게 달라질 수 있다.\n하나의 쿼리 작업은 여러 하위 작업으로 나뉘는데, 각 하위 작업이 MySQL 엔진 영역에서 처리되는지 스토리지 엔진 영역에서 처리되는지 구분할 줄 알아야 한다.\n1 2 /* 스토리지 엔진 조회 */ SHOW ENGINES; 서버에 포함되지 않은 스토리지 엔진을 사용하려면 MySQL 서버를 다시 빌드해야 한다. 준비만 되어있다면 플러그인 형태로 빌드된 스토리지 엔진 라이브러리를 다운로드해서 끼워넣기만 하면 사용할 수 있다.\n1 2 /* 플러그인 조회 */ SHOW PLUGINS; 컴포넌트 플러그인 아키텍처는 다음과 같은 단점이 있다.\n오직 MySQL 서버와 인테페이스할 수 있고, 플러그인끼리는 통신할 수 없음 MySQL 서버의 변수나 함수를 직접 호출하기 때문에 안전하지 않음(캡슐화 안됨) 플러그인은 상호 의존 관계를 설정할 수 없어 초기화가 어려움 이러한 문제를 개선하기 위해 MySQL 8.0 부터는 기존의 플러그인 아키텍처를 대체하기 위해 컴포넌트 아키텍처가 지원된다.\n예를 들면, MySQL 5.7 버전까지는 비밀번호 검증 기능이 플러그인 형태로 제공됐지만 MySQL8.0의 비밀번호 검증 기능은 컴포넌트로 개선됐다.\n1 2 3 4 5 /* validate_password 설치 */ INSTALL COMPONENT \u0026#39;file://component_validate_password\u0026#39;; /* 설치된 컴포넌트 확인 */ SELECT * FROM mysql.component; 쿼리 실행 구조 쿼리 파서 쿼리 파서는 사용자 요청으로 들어온 쿼리 문장을 토큰(MySQL이 인식할 수 있는 최소 단위의 어휘나 기호)으로 분리해 트리 형태의 구조로 만들어 내는 작업을 의미한다.\n쿼리 문장의 기본 문법 오류는 이 과정에서 발견되고 사용자에게 오류 메시지를 전달하게 된다. 전처리기 파서 과정에서 만들어진 파서 트리를 기반으로 쿼리 문장에 구조적인 문제점이 있는지 확인한다.\n각 토큰을 테이블 이름이나 컬럼 이름, 또는 내장 함수와 같은 개체를 매핑해 해당 객체의 존재 여부와 객체의 접근 권한 등을 확인하는 과정을 수행한다.\n실제 존재하지 않거나 권한상 사용할 수 없는 개체의 토큰(컬럼, 내장 함수)은 이 단계에서 걸러진다. 옵티마이저 사용자의 요청으로 들어온 쿼리 문장을 저렴한 비용으로 가장 빠르게 처리할지를 결정하는 역할을 담당한다.\nDBMS의 두뇌에 비유되며, 옵티마이저가 더 나은 선택을 하도록 유도하는 것이 매우 중요하다.\n실행 엔진 옵티마이저가 두뇌라면 실행 엔진과 핸들러는 손과 발에 비유할 수 있다.\n옵티마이저가 GROUP BY를 처리하기 위해 임시 테이블을 사용하기로 결정했다면 아래 과정을 거칠 수 있다.\n실행 엔진이 핸들러에게 임시 테이블을 만들라고 요청 실행 엔진은 WHERE 절에 일치하는 레코드를 읽어오라고 핸들러에게 요청 읽어온 레코드들을 1번에서 준비한 임시 테이블로 저장하라고 핸들러에게 요청 데이터가 준비된 임시 테이블에서 필요한 방식으로 데이터를 읽어 오라고 핸들러에게 요청 결과를 사용자나 다른 모듈로 넘김 즉, 만들어진 계획대로 각 핸들러에게 요청해서 받은 결과를 또 다른 핸들러 요청의 입력으로 연결하는 역할을 수행한다.\n핸들러(스토리지 엔진) MySQL 서버의 가장 밑단에서 실행 엔진의 요청에 따라 데이터를 디스크로 저장하고 디스크로부터 읽어 오는 역할을 담당한다.\n핸들러는 결국 스토리지 엔진을 의미하며, MyISAM 테이블을 조작하는 경우 핸들러가 MyISAM 스토리지 엔진이 되고, InnoDB 테이블을 조작하는 경우 InnoDB 스토리지 엔진이 된다.\n복제 MySQL 서버에서 복제(Replication)는 매우 중요한 역할을 담당하며, 지금까지 MySQL 서버에서 복제는 많은 발전을 거듭해왔다.(16장)\n쿼리 캐시 쿼리 캐시는 빠른 응답을 필요로 하는 웹 기반의 응용 프로그램에서 매우 중요한 역할을 담당했다. 쿼리 캐시는 SQL의 실행 결과를 메모리에 캐시하고, 동일 SQL 쿼리가 실행되면 테이블을 읽지 않고 즉시 결과를 반환하기 때문에 매우 빠른 성능을 보였다.\n하지만 쿼리 캐시는 테이블의 데이터가 변경되면 캐시에 저장된 결과 중에서 변경된 테이블과 관련된 테이블과 관련된 것들은 모두 삭제(Invalidate)해야 하므로, 심각한 동시 처리 성능 저하를 유발한다. 또한 MySQL 서버가 발전하면서 성능이 개선되는 과정에서 쿼리 캐시는 계속된 동시 처리 성능 저하와 많은 버그의 원인이 되기도 했다.\n다수의 클라이언트가 동시에 같은 쿼리를 실행하는 경우 쿼리 캐시 락(query cache lock)이 발생 가능하다. 이는 쿼리 캐시에 새로운 결과를 저장하거나 기존 결과를 반환하기 위해 필요한 락(lock)으로, 동시 처리가 많은 시스템에서는 쿼리 캐시를 사용하지 않는 것이 더 나은 성능을 보일 수 있다.\nMySQL 5.6 이하 버전에서는 쿼리 캐시가 InnoDB 또는 NDB Cluster 스토리지 엔진을 사용하는 경우에만 동작하는데 MyISAM 스토리지 엔진을 사용하는 경우에도 쿼리 캐시를 켜면 쿼리 결과가 무한정 캐시될 수 있는 버그가 있었다. 이러한 버그는 시스템의 부하를 높일 뿐만 아니라, 캐시 메모리의 공간을 차지해 다른 쿼리의 실행에 영향을 미칠 수 있다.\n이러한 이유로 MySQL 8.0으로 올라오면서 완전히 제거되고, 관련 시스템 변수도 모두 제거되었다.\n스레드 풀 MySQL 서버 엔터프라이즈 에디션은 스레드풀 기능을 제공하지만 커뮤니티 에디션은 지원하지 않는다. 따라서 Percona Server 플러그인에서 제공하는 스레드풀 기능을 살펴본다.\n스레드풀은 내부적으로 사용자의 요청을 처리하는 스레드 개수를 줄여서 동시 처리되는 요청이 많다 하더라도 MySQL 서버의 CPU가 제한된 개수의 스레드 처리에만 집중할 수 있게 하여 서버의 자원 소모를 줄이는것이 목적이다.\n하지만 스레드풀이 실제 서비스에서 눈에띄는 성능 향상을 보여준 경우는 드물다.\n실행 중인 스레드들을 CPU가 최대한 잘 처리해낼 수 있는 수준으로 줄여서 빨리 처리하게 하는 기능으므로 스케줄링 과정에서 CPU 시간을 제대로 확보하지 못하는 경우 쿼리 처리가 더 느려지는 사례도 발생할 수 있다.\n제한된 수의 스레드만으로 CPU가 처리하도록 적절히 유도하면 CPU의 프로세서 친화도(Processor affinity)도 높히고 불필요한 컨텍스트 스위치를 줄여 오버헤드를 낮출 수 있다.\n스레드 그룹 개수 Percona Server의 스레드 풀은 기본적으로 CPU 코어의 개수만큼 스레드 그룹을 생성하며 일반적으로 CPU 코어의 개수와 맞추는것이 CPU 프로세서 친화도를 높이는 데 좋다.\nMySQL 서버가 처리해야할 요청이 생기면 스레드풀로 처리를 이관하는데, 이미 스레드풀이 처리중인 작업이 있는 경우 시스템 변수에 설정된 개수만큼 추가로 더 받아들여서 처리한다. 너무 많으면 스케줄링해야 할 수레드가 많아져 비효율적으로 작동할 수 있다.\n타이머 스레드 스레드 그룹의 모든 스레드가 일을 처리하고 있다면 스레드 풀은 해당 스레드 그룹에 새로운 작업 스레드를 추가할지, 기존 작업 스레드가 처리를 완료할 때가지 기다릴지 여부를 판단해야 한다.\n주기적으로 스레드 그룹의 상태를 체크해서 thread_pool_stall_limit 시스템 변수에 정의된 시간에 작업을 끝내지 못했다면 새로운 스레드를 생성해 스레드 그룹에 추가한다.\n모든 스레드 그룹의 스레드가 작업을 수행중이라면 시스템 변수에 설정된 개수를 넘어설 수 없어 대기해야 한다.\n응답 시간이 아주 민감한 서비스라면 시스템 변수를 적절히 낮춰 설정해야하며, 0에 가까운 값으로 설정하는 것은 좋지 않고 이런 경우는 스레드풀을 사용하지 않는 것이 좋을 수 있다.\n우선순위 큐 선순위 큐와 후순위 큐를 이용해 특정 트랜잭션이나 쿼리를 우선적으로 처리할 수 있는 기능도 제공한다. 먼저 시작된 트랜잭션 내에 속한 SQL을 빨리 처리해주면 해당 트랜잭션이 가지고 있던 잠금이 빨리 해제되고 잠금 경합을 낮춰 전체적인 처리 성능을 향상시킬 수 있다.\n트랜잭션 지원 메타데이터 데이터베이스 서버에서 테이블의 구조 정보와 스토어드 프로그램 등의 정보를 데이터 딕셔너리 또는 메타데이터라고 하는데, MySQL 서버는 5.7 버전까지 테이블의 구조를 FRM 파일에 저장하고 일부 스토어드 프로그램 또한 파일 기반으로 관리 되었다.\n이러한 파일 기반의 메타데이터는 생성 및 변경 작업이 트랜잭션을 지원하지 않기 때문에 테이블의 생성 또는 변경 도중에 MySQL 서버가 비정상적으로 종료되면 일관되지 않은 상태로 남게되는 문제가 있었다.\n이에따라 8버전 부터는 테이블의 구조 정보나 스토어드 프로그램의 코드 관련 정보를 모두 InnoDB의 테이블에 저장하도록 개선되었다.\n","date":"2023-04-10T00:00:00Z","image":"https://codemario318.github.io/post/real_mysql_4_1/real_mysql_hu03b8ff0acb6f52b3ec9ae95e616f82c2_25714_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/real_mysql_4_1/","title":"4.1 MySQL 엔진 아키텍처"}]