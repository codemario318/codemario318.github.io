[{"content":" 뭔가 잘못되면 바로잡을 책임은 바로 우리 프로그래머에게 있다.\n깨끗한 코드와 오류처리는 연관이 있다. 상당수 코드들은 전적으로 오류 처리 코드에 좌우된다. 여기저기 흩어진 오류 처리 코드 때문에 실제 코드가 하는 일을 파악하기가 거의 불가능하다는 의미다.\n💡 오류 처리는 중요하지만 이로 인해 프로그램 논리를 이해하기 어려워진다면 깨끗한 코드라 부르기 어렵다.\n오류 코드보다 예외를 사용하라 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class DeviceController { ... piblic void sendShutDown() { DeviceHandle handle = getHandle(DEV1); if (handle != DeviceHandle.INVALID) { retrieveDeviceRecord(handle); if (record.getStatus() != DEVICE_SUSPENDED) { pauseDevice(handle); clearDeviceWorkQueue(handle); closeDevice(handle); } else { logger.log(\u0026#34;Device suspended. Unable to shut down\u0026#34;); } } else { logger.log(\u0026#34;Invalid handle for: \u0026#34; + DEV1.toString()); } } ... } 위와 같은 방법을 사용하면 호출자 코드가 복잡해진다. 함수를 호출한 즉시 오류를 확인해야 하기 때문이다.\n오류가 발생하면 예외를 던지면, 실제 구현 로직이 오류 처리 코드와 섞이지 않게 되어 호출자가 깔끔해진다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class DeviceController { ... public void sendShutDown() { try { tryToShutDown(); } catch (DeviceShutDownError e) { logger.log(e); } } private void tryToshutDown() throw DeviceShutDownError { DeviceHandle hadle = getHandle(DEV1); DeviceRecord record = retrieveDeviceRecord(handle); pauseDevice(handle); clearDeviceWorkQueue(handle); closeDevice(handle); } private DeviceHandle getHandle(DeviceId id) { ... throw new DeviceShutDownError(\u0026#34;Invalid handle for: \u0026#34; + id.toString()); } ... } 뒤섞여있던 디바이스 종료 로직과 오류 처리 로직이 분리되었다. 이를 통해 각 개념을 독립적으로 살펴보고 이해할 수 있다.\nTry-Catch-Finally 문부터 작성하라 예외처리는 로직 내부에 범위를 정의한다.\ntry-catch-finally 문에서 try 블록에 들어가는 코드를 실행하면 어느 시점에서든 실행이 중단된 후 catch 블록으로 넘어갈 수 있다.\ntry 블록에서 무슨 일이 생겨도 catch 블록은 프로그램 상태를 일관성 있게 유지해야 한다.\n예외가 발생할 코드를 짤 때는 try-catch-finally 문을 만들어놓고 시작하면 try 블록에서 무슨 일이 생기든지 호출자가 기대하는 상태를 정의하기 쉬워진다.\n1 2 3 4 5 // 파일이 없으면 예외를 던지는지 알아보는 단위 테스트 @Test(expcted = StroageException.class) public void retrieveSectionShouldThrowOnInvalidFileName() { sectionStore.retrieveSection(\u0026#34;invalid - file\u0026#34;); } 1 2 3 public List\u0026lt;RecordedGrip\u0026gt; retrieveSection(String sectionName) { return new ArrayList\u0026lt;RecordedGrip\u0026gt;(); } 코드가 예외를 던지지 않으므로 단위 테스트는 실패한다. 아래 코드는 예외를 던진다.\n1 2 3 4 5 6 7 8 public List\u0026lt;RecordedGrip\u0026gt; retrieveSevtion(String sectionName) { try { FileInputStream stream = new FileInputStream(sectionName); } catch (Exception e) { throw new StorageException(\u0026#34;retrieval error\u0026#34;, e); } return new ArrayList\u0026lt;RecordedGrip\u0026gt;(); } 코드가 예외를 던지므로 이제는 테스트가 성공한다. 이 시점에서 리팩터링이 가능하다.\ncatch 블록에서 예외 유형을 좁혀 실제로 FileInputStream 생성자가 던지는 FileNotFoundException을 잡아낸다.\n1 2 3 4 5 6 7 8 9 public List\u0026lt;RecordedGrip\u0026gt; retrieveSevtion(String sectionName) { try { FileInputStream stream = new FileInputStream(sectionName); stream.close(); } catch (FileNotFoundException e) { throw new StorageException(\u0026#34;retrieval error\u0026#34;, e); } return new ArrayList\u0026lt;RecordedGrip\u0026gt;(); } try-catch 구조로 범위를 정의했으므로 TDD를 이용해 필요한 나머지 논리를 추가한다. 나머지 논리는 FileInputStream을 생성하는 코드와 close 호출문 사이에 넣으며 오류나 예외가 전혀 발생하지 않는다고 가정한다.\n미확인(unchecked) 예외를 사용하라 여러 해 동안 자바 프로그래머들은 확인된(checked) 예외의 장단점을 놓고 논쟁을 벌여왔다. 안정적인 소프트웨어를 제작하는 요소로 확인된 예외가 반드시 필요하지 않다는 사실이 분명해졌다.\nJava의 체크 된 예외와 체크되지 않은 예외의 차이점\n확인된 예외: 컴파일 과정에서 발견되는 예외\nRuntimeExeption 클래스를 제외한 Exeption 클래스의 모든 하위 클래스 Error클래스와 그 하위 클래스 확인되지 않은 예외: 프로그램 실행 중 발생하는 예외, 컴파일러가 확인할 수 없는 예외\nRuntimeExeption 클래스와 해당 하위 클래스 확인된 예외는 OCP(Open Closed Principle) 를 위반한다.\n메서드에서 확인된 예외를 던졌는데 catch 블록이 세 단계 위에 있다면 그사이 메서드 모두가 선언부에 해당 예외를 정의해야 한다.\n하위 단계에서 코드를 변경하면 상위 단계 메서드 선언부를 전부 고쳐야 한다. 최하위 함수를 변경하여 새로운 오류를 던진다고 가정하고 확인된 오류를 던진다면 함수는 선언부에 throws 절을 추가해야 한다.\n변경한 함수를 호출하는 함수 모두가 catch 블록에서 새로운 예외를 처리한다. 선언부에 throw 절을 추가한다. 결과적으로 최하위 단계에서 최상위 단계까지 연쇄적인 수정이 일어난다. 다르게 해석하면, throws 경로에 위치하는 모든 함수가 최하위 함수에서 던지는 예외를 알아야 하므로 캡슐화가 깨진다.\n💡 확인된 예외를 이용하여 구현하게 되면 안전한 로직을 만들 수 있지만, 일반적인 애플리케이션은 확인된 예외를 통한 이익보다, 의존성이 더 중요하다.\n예외에 의미를 제공하라 예외를 던질 때 전후 상황을 충분히 덧붙히면, 오류가 발생한 원인과 위치를 찾기 쉬워진다.\n실패한 코드의 의도를 파악하려면 호출 수택 만으로 부족한 경우가 많아. 오류 메시지에 정보(실패한 연산 이름과 실패 유형)를 담아 예외와 함께 던진다.\n애플리케이션에서 로깅 기능을 사용한다면 catch 블록에서 오류를 기록하도록 충분한 정보를 넘겨주면 좋다.\n호출자를 고려해 예외 클래스를 정의하라 오류를 분류하는 방법은 수없이 많다.\n오류가 발생한 위치 오류가 발생한 컴포넌트 오류 유형 디바이스 실패 네트워크 실패 프로그래밍 오류 어플리케이션 오류를 정의할 때 프로그래머에게 가장 중요한 관심사는 오류를 잡아내는 방법이 되어야 한다.\n나쁜예 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ACMEport port = new ACMEport(12); try { port.open(); } catch (DeviceResponseException e) { reportPortError(e); logger.log(\u0026#34;Device response exception\u0026#34;, e); } catch (ATM1212UnlokedException e) { reportPortError(e); logger.log(\u0026#34;Unlock exception\u0026#34;. e); } catch (GMXRrror e) { reportPortError(e); logger.log(\u0026#34;Device response exeption\u0026#34;); } finally { ... } 위 코드는 중복이 심하여, 대다수 상황에서 오류를 처리하는 방식은 비교적 일정하다.\n오류를 기록한다. 프로그램을 계속 수행해도 좋은지 확인한다. 위 경우는 예외에 대응하는 방식이 예외 유형과 무관하게 거의 동일하다. 그래서 코드를 간결하게 고치기 쉽다.\n1 2 3 4 5 6 7 8 9 10 LocalPort port = new LocalPort(12); try { port.open(); } catch (portDeviceFailure e) { reportError(e); logger.log(e.getMessage(), e); } finally { ... } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class LocalPort { private ACMEPort innerPort; public LocalPort(int portNumber) { innerPort = new ACMEPort(portNumber); } public void open() { try { innerPort.open(); } catch (DeviceResponseException e) { throw new PortDeviceFailure(e); } catch (ATM1212UnlockedException e) { throw new PortDeviceFailure(e); } catch (GMXError e) { throw new PortDeviceFailure(e); } } ... } 여기서 LocalPort클래스는 단순히 ACMEport클래스가 던지는 예외를 잡아 변환하는 wrapper 클래스 일뿐이다.\n하지만 이러한 wrapper 클래스는 매우 유용하다. 실제로 외부 API를 사용할 때는 감싸기 기법이 최선이다.\n외부 API를 감싸면 외부 라이브러리와 프로그램 사이에서 의존성이 크게 줄어든다. 나중에 다른 라이브러리로 갈아타도 비용이 적다. 감싸기 클래스에서 외부 API를 호출하는 대신 테스트 코드를 넣어주는 방법으로 프로그램을 테스트하기도 쉬워진다. 특정 업체가 API를 설계한 방식에 발목 잡히지 않는다. 프로글매이 사용하기 편한 API를 정의하면 그만이다. 예외 클래스가 하나만 있어도 충분한 코드가 많다.\n예외 클래스에 포함된 정보로 오류를 구분해도 괜찮은 경우. 한 예외는 잡아내고 다른 예외는 무시해도 괜찮은 경우라면 여러 예외 클래스를 사용하는 것이 좋다.\n정상 흐름을 정의하라 정상 흐름을 정확히 정의하지 않으면 딴길로 샌다.\n1 2 3 4 5 6 try { MealExpenses expenses = expenseReportDAO.getMeals(employee.getID()); m_total += expenses.getTotal(); } catch(MealExpensesNotFound e) { m_total += getMealPerDiem(); } 위에서 식비를 비용으로 청구했다면 직원이 청구한 식비를 총계에 더한다. 식비를 비용으로 청구하지 않았다면 일일 기본 식비를 총계에 더한다. 그런데 예외가 논리를 따라가기 어렵게 만든다.\n1 2 MealExpenses expenses = expenseReportDAO.getMeals(employee.getID()); m_total += expenses.getTotal(); ExpensesReportDAO를 고쳐 청구한 식비가 없다면, 일일 기본 식비를 반환하는 MealExpense객체를 반환한다.\n1 2 3 4 5 public class PerDiemMealExpenses implements MealExpenses { public in getTotal() { // 기본값으로 일일 기본 식비를 반환 } } 이러한 형태를 **특수 사례 패턴(Special Case Pattern)**이라 부른다. 클래스를 만들거나 객체를 조작해 특수 사례를 처리하는 방식이다.\n클라이언트 코드가 예외적인 상황을 처리할 필요가 없어진다.\nnull을 반환하지 마라 null 반환은 흔히 사용되어 오류를 유발하는 경우가 많다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 public void registerItem(Item item) { if (item != null) { ItemRegistry registry = peristentStore.getItemRegistry(); if (registry != null { Item existing = registry.getItem(item.getID()); if (existing.getBillingPeriod().hasRetailOwner()) { existing.register(item); } } } } null을 반환하기 때문에 정상적인 동작 처리를 위해 null 인지 아닌지 확인하는 로직이 필요하여 일거리를 늘린다.\n이러한 코드는 호출자가 null 처리를 잊을 경우 문제가 발생하게는 구조로, 문제를 호출자에게 떠넘기기 때문에 좋은 구조라고 볼 수 없다.\n이러한 경우 특수 사례가 좋은 해결책이 될 수 있다.\n1 2 3 4 5 6 7 List\u0026lt;Empoloyee\u0026gt; employees = getEmpoloyees(); if (employees != null { for(Employee e : employees) { totalPay += e.getPay(); } } 위 getEmployees는 null도 반호나한다. 하지만 이런 경우 null반환하는 것이 아니라 빈 리스트를 반환한다면 코드가 훨씬 깔끔해진다.\n1 2 3 4 5 List\u0026lt;Employee\u0026gt; employees = getEmployees(); for ( Employees e L employees) { totalPay += e.getPay(); } 자바에는 Collections.emptyList()가 있어 미리 정의된 읽기 전용 리스트를 반환한다.\n1 2 3 4 5 public List\u0026lt;Employee\u0026gt; getEmployees() { if ( ... 직원이 없다면 ..) { return Collections.emptyList(); } } 위와 같이 코드를 변경하면 코드도 깔끔해지고 NullPointerException이 발생할 가능성도 줄어든다.\nnull을 전달하지 마라 메서드에서 null을 반환하는 방식도 나쁘지만 메서드로 null을 전달하는 방식은 더 나쁘다.\n1 2 3 4 5 6 public class MetricsCalculator { public double xProjection(Point p1, Point p2) { return (p2.x - p1.x) * 1.5; } ... } 누군가 인수로 null을 전달하면 NullPointerException이 발생한다.\n1 2 3 4 5 6 7 8 9 public class MetricsCalculator { public double xProjection(Point p1, Point p2) { if (p1 == null || p2 === null) { throw InvalidArgumentException( \u0026#34;Invalid argument for MetricsCalculator.xProjection\u0026#34;); } return (p2.x - p1.x) * 1.5; } } 위 코드로 입력이 null일 경우를 예방 했지만, InvalidArgumentException 잡아내는 처리기를 추가해야 한다.\n1 2 3 4 5 6 7 public class MetricsCalculator { public double xProjection(Point p1, Point p2) { assert p1 != null : \u0026#34;p1 should not be null\u0026#34;; assert p2 != null : \u0026#34;pw should not be null\u0026#34;; return (p2.x - p1.x) * 1.5; } } 위 코드는 assert문을 사용하여 처리했다.\nJava의 assert 키워드\n문서화가 잘 되어 코드 읽기는 편하지만 문제를 해결하지는 못한다. 누군가 null을 전달하면 여전히 실행 오류가 발생한다.\n💡 대다수 프로그래밍 언어는 호출자가 실수로 넘기는 null을 적절히 처리하는 방법이 없기 때문에, 애초에 null을 넘기지 못하도록 금지하는 정책이 합리적일 수 있다.\n결론 깨끗한 코드는 읽기도 좋아야 하지만 안정성도 높아야 한다.\n이 둘은 상충하는 목표가 아님 오류 처리를 프로그램 논리와 분리해 별도의 사안으로 고려해야함 더욱 튼튼하고 깨끗한 코드를 작성할 수 있게됨 독립적인 추론이 가능해지며 코드 유지보수성도 크게 높아짐 프로그램 논리와 분리해 별도로 고민하라. 오류 처리를 만들기 전에 흐름을 정확히 파악하면 안 쓸수도 있다. 정상 흐름을 정의하라. 특수 상황 패턴등을 이용 null은 사용자의 실수를 유발하므로 되도록 자제해야 한다. ","date":"2023-04-20T16:12:13+09:00","image":"https://codemario318.github.io/post/clean_code_7/clean_code_cover_hud03d003727d53e154227b4e2dbea4cfd_18319_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/clean_code_7/","title":"클린코드: 7. 오류 처리"},{"content":"자료 추상화 사용자가 구현을 모른 채 자료의 핵심을 조작할 수 있어야 진정한 의미의 클래스다.\n1 2 3 4 public class Point { public double x; public double y; } 1 2 3 4 5 6 7 8 public interface Point { double getX(); double getY(); void setCartesian(double x, double y); double getR(); double getTheta(); void setPolar(double r, double theta); } 두 클래스 모두 2차원 점을 표현하지만 6-1은구현을 외부로 노출하고, 6-2는 구현을 완전히 숨긴다.\n6-1은 변수를 private 으로 선언하더라도 각 값마다 getter, setter를 제공한다면 외부로 노출하는 것이다.\n변수 사이에 함수라는 계층을 넣는다고 구현이 저절로 감춰지지는 않는다. 구현을 감추려면 어느정도의 추상화가 필요하다.\n예시 1\n1 2 3 4 public interface Vehicle { double getFuelTankCapacityInGallons(); double getGallonsOfGasoline(); } 예시 2\n1 2 3 public interface Vehicle { double getPercentFuelRemaining(); } 예시 1은 연료탱크의 용량과 휘발유의 양을 받아올 수 있고, 예시 2는 백분율로 얼마나 더 남았는가를 받아올 수 있다.\n둘 중 예시 2가 더 추상적이지만, 백분율의 기준값을 알 수 없으므로 정확한 정보를 표현하지 못한다.\n인터페이스나 조회/설정 함수만으로는 추상화가 이뤄지지 않는다. 개발자는 객체가 포함하는 자료를 표현 할 가장 좋은 방법을 심각하게 고민해야 한다.\n자료/객체 비대칭 객체: 추상화 두로 자료를 숨긴 채 자료를 다루는 함수만 공개한다. 자료구조: 자료를 그대로 공개하며 별다른 함수는 제공하지 않는다. 절차적인 구현 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 public class Square { public Point topLeft; public double side; } public class Rectangle { public Point topLeft; public double height; public double width; } public class Circle { public Point center; public double radius; } public class Geometry { public final double PI = 3.141592653589793; public double area(Object shape) throws NoSuchShapeExetion { if (shape instanceof Square) { Square s = (Square)shape; return s.side * s.side; } else if (shape instanceof Rectangle) { Rectangle r = (Rectangle)shape; return r.height * r.width; } else if (shape instanceof Circle) { Circle c = (Circle)shape; return PI * c.radious * c.radious; } throw new NoSuchShapeExcption(); } } 위 예시에서 만약 Geometry 클래스에 새로운 기능들을 추가해도 도형 클래스들은 영향을 받지 않는다. 위 예시에서 새 도형을 추가하고 싶다면 Geometry의 속한 기능들에 새로운 도형을 위한 코드를 추가해야 한다. 객체 지향적인 도형 클래스 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class Square implements Shape { private Point topLeft; private double side; public double area() { return s.side * s.side; } } public class Rectangle implements Shape { public Point topLeft; public double height; public double width; public double area() { return height * width; } } public class Circle implements Shape { public Point center; public double radius; public double area() { return PI * radius * radius; } } 위 예시에서 만약 Shape에 새로운 기능들을 추가하면 상속받은 모든 클래스에 변경이 필요하다. 위 예시에서 Shape를 상속받은 다른 도형을 추가하고 싶다면 하나 새로 만들면 된다. 목록 절차적인 구현과 객체 지향적인 구현은 근본적으로 반대이며 상호 보완적인 특성을 가진다. 그래서 객체와 자료 구조는 근본적으로 양분된다.\n💡 객체 지향 코드에서 어려운 변경은 절차적인 코드에서 쉬우며, 절차적인 코드에서 어려운 변경은 객체지향 코드에서 쉬운 경우가 많다. 따라서, 때로는 단순한 자료 구조와 절차적인 코드가 가장 적합한 상황도 있다.\n디미터 법칙 디미터의 법칙은 잘 알려진 휴리스틱으로, 모듈은 자신이 조작하는 객체의 속사정을 몰라야 한다는 법칙이다.\n디미터 법칙(Law of Demeter)\n이러한 이유로 Don’t Talk to Strangers(낮선 이에게 말하지 마라) 또는 Principle of least Knowledge(최소 지식 원칙)으로도 알려져 있다.\n객체는 자료를 숨기고 함수를 공개한다.\n즉, 객체는 조회 함수로 내부 구조를 공개하면 안된다는 의미다. 조금 더 정확하게 표현하자면, 디미터 법칙은 “클래스 C의 메서드 f는 다음과 같은 객체의 메서드만 호출해야 한다”고 주장한다.\n클래스 C f가 생성한 객체 f 인수로 넘어온 객체 C 인스턴스 변수에 저장된 객체 위 객체에서 허용된 메서드가 반환하는 객체의 메서드는 호출하면 안된다.\n1 final String ouputDir = ctxt.getOptions().getScratchDir().getAbsolutePath(); getOptions() 함수가 반환하는 객체의 getScratchDir() 함수를 호출한 후 getScratchDir() 함수가 반환하는 객체의 getAbsolutePath() 함수를 호출하기 때문이다 디미터의 법칙을 위반했다. 클래스 C의 메서드가 지정된 메서드만을 호출하지 않고 있다. 기차 충돌 메서드를 연속적으로 호출하여 코드가 여러 객차가 한 줄로 이어진 기차처럼 보이기 때문에 기차 충돌이라 부른다.\n1 2 3 Options opts = ctxt.getOptions(); File scratchDir = opts.getScratchDir(); final String outputDir = scratchDir.getAbsolutePath(); 위와 같이 기차 충돌을 제거했을 경우 연속적으로 호출되었을 때는 반환되는 객체를 정확히 파악할 수 없었는데 나눠놓으니 더 쉽게 파악할 수 있다.\n하지만 위 구조도 아래와 같은 전제를 이미 알고 있어야 하므로 디미터 법칙을 만족한다고 볼 수 없다.\nctxt 객체가 Options를 포함한다. Options가 ScratchDir을 포함한다. ScratchDir이 AbsolutePath를 포함한다. 위 코드를 사용하는 함수는 많은 객체에 대한 정보를 알고 있기 때문에 최소 지식 원칙을 만족한다고 볼 수 없다.\n디미터 법칙을 위반하는지는 호출된 ctxt, Options, ScratchDir이 객체인지 자료 구조 인지에 달렸다.\n객체라면 내부 구조를 숨겨야 하므로 디미터 법칙을 위반한다. 자료 구조라면 내부 구조를 노출하기 때문에 디미터 법칙 대상이 아니다. 위 예제는 조회 함수를 사용하는 바람에 혼란을 일으키게 되는데, 코드를 다음과 같이 구현했다면 디미터 법칙을 거론할 필요가 없어진다.\n1 final String ouputDir = ctxt.options.scratchDir.absolutePath; 자료구조를 이용하게 되어 다른 클래스의 내부 구조에 대해 알 수 없게 되므로 디미터의 법칙 대상이 아니게 된다.\n자료 구조는 무조건 함수 없이 공개 변수만 포함하고 객체는 비공개 변수와 공개 함수를 포함한다면, 문제는 훨씬 간단해진다.\n잡종 구조 하지만 단순한 자료 구조에도 조회 함수와 설정 함수를 정의하라 요구하는 프레임워크와 표준(ex. bean)이 존재하고 있다. 이런 혼란 때문에 절반은 객체, 절반은 자료 구조인 잡종 구조가 나온다.\n잡종 구조는 중요한 기능을 수행하는 함수도 있고, 공개 변수나 공개 조회/설정 함수도 있다.\n공개/조회 함수는 비공개 변수를 그대로 노출하게 되며, 이 때문에 다른 함수가 절차적인 프로그래밍의 자료 구조 접근 방식처럼 비공개 변수를 사용하게 유혹한다.\n위처럼 만들어진 잡종 구조는 새로운 함수는 물론이고 새로운 자료 구조도 추가하기 어렵다. 그러므로 이러한 구조는 되도록 피하는 편이 좋다.\n구조체 감추기 ctxt, options, scratchDir이 진짜 객체라면 앞에서 본 예제처럼 기차 충돌을 만들면 안된다.\n1 ctxt.getAbsolutePathOfScratchDirectoryOption(); ctxt 객체가 여러 메서드를 조작해야 하므로 공개해야 하는 메서드가 너무 많아진다. 1 ctxt.getScratchDiretoryOption().getAQbsolutePath(); 객체가 아니라 자료 구조를 반환한다고 가정한다. ctxt가 객체라면 뭔가를 하라고 말해야지 속으로 드러내라고 말하면 안된다.\n고칠때는 무슨 목적으로 만들어진 기능인지 살피면 더 좋은 코드로 바꿀 수 있다. 위 기능에서 절대 경로를 얻으려는 이유는 임시 파일을 생성하기 위해서였다.\n1 2 3 String outFile = outputDir + \u0026#34;/\u0026#34; + className.replace(\u0026#39;.\u0026#39;, \u0026#39;/\u0026#39;) + \u0026#34;.class\u0026#34;; FileOutputStream fout = new FileOutputStream(outFile); BufferedOutputStream bos = new BufferedOutputStream(fout); 이러한 경우 ctxt객체에 임시 파일을 생성하는 기능을 만드는 것이 더 좋아보인다.\n1 BufferedOutputStream bos = ctxt.createScratchFileStream(classFileName); 위 코드로 변경하여 ctxt는 내부 구조를 드러내지 않으며, 모듈에서 해당 함수는 자신이 몰라야 하는 여러 객체를 탐색할 필요가 없어졌다.\n❓ 메서드 체인으로 만들었던 outputDir 은 결국 className을 함께 이용하여 파일 경로를 만들어 주게 되므로 별도로 분리하는 것이 아니라 묶어서 감추는 것이 더 좋다는 의미인가?\n자료 전달 객체 DTO 자료 구조체의 전형적인 형태는 공개 변수만 있고 함수가 없는 클래스다. 이런 자료 구조체를 때로는 자료 전달 객체(Data Transfer Object, DTO)라 한다.\nDTO는 데이터베이스와 통신하거나 소켓에서 받은 메시지의 구문을 분석할 때 유용하다.\n흔히 DTO는 데이터 베이스에 저장된 가공되지 않은 정보를 애플리케이션 코드에서 사용할 객체로 변환하는 단계에서 가장 처음으로 사용하는 구조체다.\nDTO의 좀 더 일반적인 형태는 ‘빈(bean)’구조다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 public class Address { private String street; private String streetExtra; private String city; private String state; private String zip; public Address(String street, String streetExtra, String city, String state, String zip) { this.street = street; this.streetExtra = streetExtra; this.city = city; this.state = state; this.zip = zip; } public String getStreet() { return street; } public String getStreetExtra() { return streetExtra; } public String getCity() { return city; } public String getState() { return state; } public String getZip() { return zip; } } 빈은 비공개 변수를 조회/설정 함수로 조작한다. 일종의 사이비 캡슐화로, 별 다른 이익을 제공하지는 않는다.\n활성 레코드 활성 레코드는 데이터베이스 테이블이나 다른 소스에서 자료를 직접 변환한 결과로 DTO의 특수한 형태다. 공개 변수가 있거나 비공개 변수에 조회/설정 함수가 있는 자료 구조지만, 대개 save나 find와 같은 탐색 함수도 제공한다.\n활성 레코드를 사용할 때 비즈니스 로직을 추가해 이런 자료 구조를 객체로 취급하는 개발자가 많은데, 이러한 방식은 결국 잡종 구조를 만들게 된다.\n활성 레코드는 자료 구조로 취급하여, 비즈니스 규칙을 담으면서 내부 자료를 숨기는 객체를 따로 생성해야 한다.\n결론 객체는 동작을 공개하고 자료를 숨긴다. 그래서 기존 동작을 변경하지 않으면서 새 객체 타입을 추가는 쉽다. 하지만 기존 객체에 새 동작을 추가하는 것은 어렵다. 자료구조는 별다른 동작 없이 자료를 노출한다. 그래서 기존 자료 구조에 새 동작을 추가는 쉽다. 기존 함수에 새 자료 구조를 추가하기는 어렵다. 구현할 때, 새로운 자료 타입을 추가하는 유연성이 필요하면 객체가 더 적합하다. 다른 경우로 새로운 동작을 추가하는 유연성이 필요하면 자료 구조와 절차적인 코드가 더 적합하다.\n💡 우수한 개발자는 편견 없이 이 사실을 이해해 직면한 문제에 최적인 해결책을 선택해야 한다.\n읽고 싶은 책 엘레강트 오브젝트 객체지향을 조금 다른 관점에서 접근하여 깨끗한 코드를 만드는 방법을 추천하는 책 ","date":"2023-04-20T15:53:13+09:00","image":"https://codemario318.github.io/post/clean_code_6/clean_code_cover_hud03d003727d53e154227b4e2dbea4cfd_18319_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/clean_code_6/","title":"클린코드: 6. 객체와 자료구조"},{"content":"어떤 프로그램이든 가장 기본적인 단위는 함수다\n어떻게 해야 읽기 쉽고 이해하기 쉬운 함수를 만들 수 있을까 의도를 분명히 표현하는 함수를 어떻게 구현할수 있을까 함수에 어떤 속성을 부여해야 처음 읽는 사람이 프로그램 내부를 직관적으로 파악할 수 있을까 작게 만들어라 함수를 만드는 첫번째 규칙은 ‘작게!’, 두번째 규칙은 ‘더 작게!’ 다.\n이 규칙은 증명하긴 어렵지만 작가의 경험으로 작은 함수가 좋다고 확신한다.\n함수가 작을수록 한가지 일만 처리하게 만들기 용이하고 명백해진다.\n블록과 들여쓰기 조건문을 통해 처리될 블록은 한줄로 표현해야한다. 즉 코드를 함수로 만들어야 한다.\n블록에 들어가게 되는 함수 이름을 적절하게 사용한다면 코드를 이해하기 쉬워진다.\n이 말은 중첩 구조가 생길만큼 함수가 커져서는 안 된다는 뜻으로 함수의 들여쓰기 깊이는 2단을 넘지 않게 만드는 것이 좋다.\n한가지만 해라 함수는 한 가지 일을 해야야한다. 그 한가지를 잘 해야한다. 그 한 가지만을 해야한다.\n추상화 수준이 하나인 단위로 함수를 만들면 한가지 일을 하는 함수를 만들 수 있다.\n함수를 만드는 이유는 큰 개념(기능)을 다음 추상화 수준에서 여러 단계로 나눠 수행하기 위해서다. 의미를 유지하면서 더 쪼갤 수 없는 수준까지 줄여야한다.\n단순히 다른 표현이 아니라 의미 있는 이름으로 다른 함수를 추출할 수 있다면 그 함수는 여러 작업을 하는 셈이다.\n함수 내 섹션 섹션이 여러개 만들어진다면 함수가 여러개의 일을 한다는 뜻이다. 한가지 일 만 하는 함수는 자연스럽게 섹션으로 나누기 어렵다.\n함수 내 추상화 수준은 하나로 함수가 확실히 한 가지 작업만 하려면 함수 내 모든 문장의 추상화 수준이 동일해야 한다.\n한 함수 내에 추상화 수준을 섞으면 특정 표현이 근본 개념인지 세부사항인지 구분하기 어려워, 코드를 읽는 사람이 헷갈린다.\n또한 근본 개념과 세부사항을 뒤섞기 시작하면, 깨진 유리창처럼 사람들이 함수에 세부사항을 점점 더 추가한다.\n위에서 아래로 코드 읽기: 내려가기 규칙 코드는 위에서 아래로 이야기처럼 읽혀야 좋다. 한 함수 다음에는 추상화 수준이 한 단계 낮은 함수가 온다.\n즉 위에서 아래로 읽히려면 함수 추상화 수준이 한번에 한 단계씩 낮아진다.\n💡 내려간다는건 단순히 위에서 아래로 읽힌다는 의미보다, 깊이가 깊어질수록 조금 더 낮은 수준으로 표현되야 한다는 뜻같다.\n추상화 수준이 하나인 함수를 구현하는것은 어렵다. 핵심은 짧으면서도 한가지 일만 수행하는 함수이다. 한 단계씩 깊어지는 코드를 구현하면 추상화 수준을 일관되게 유지하기 쉬워진다.\nSwitch 문 Switch문은 본질적으로 switch 문은 N 가지를 처리하기 때문에 작게, 한 가지 작업만 수행하게 만들기 어렵다.\n완전히 사용하지 않을 방법은 없기 때문에 다형성을 사용하여 저차원 클래스에 숨기고 반복하지 않게 만들어야 한다.\n","date":"2023-04-20T15:48:13+09:00","image":"https://codemario318.github.io/post/clean_code_3/clean_code_cover_hud03d003727d53e154227b4e2dbea4cfd_18319_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/clean_code_3/","title":"클린코드: 3. 함수 잘 만드는 법"},{"content":" 코드는 요구사항을 표현하는 도구이다. 고도로 추상화된 언어나 특정 응용 분야 언어로 기술하는 명세 역시 코드이다. 제대로 명시한 요구사항은 코드만큼 정형적이며 테스트 케이스로 사용해도 좋다! 나쁜 코드 잘나가던 회사를 망하게한 원인은 나쁜코드였다. 그들은 출시에 바빠 코드를 마구 짰다. 기능을 추가할수록 코드는 엉망이 되어갔고, 결국은 감당이 불가능한 수준에 이르렀다.\n언급 되었던 회사는 20년 후 망했다. 장기적으로 살피지 않아도, 빠르게 진행되던 프로젝트가 1~2년 만에 정체되는 경우가 꽤 많이 일어난다.\n이렇게 만들어진 나쁜 코드들은 생산성 악순환을 만든다.\n나쁜 (더러운) 코드를 지속적으로 개선하지 않는다면 장기적으로 부정적인 결과를 가져오게 된다.\n나중은 절대 오지 않는다 - Later == Never ( later equals never!) 나중은 절대 오지 않는다. 따라서 시간을 들여 깨끗한 코드를 만드는 노력이 비용을 절감하는 방법일 뿐만 아니라 전문가로서 꼭 필요하다.\n좋은 코드가 나쁜 코드가 되는 이유 요구사항 변경 짧은 일정 등등 외적인 요인들 💡 모두 변명임. 잘못은 사실 개발자 자신에게 있다.\n기획, 사업 등 에게 적극적으로 정보를 제공하여 사전에 방지해야 한다.\n커뮤니케이션을 통해 이러한 요인들을 예방하는 것도 개발자의 역량 나쁜 코드의 위험을 이해하지 못하는 관리자 말을 그대로 따르는 행동은 전문가답지 못하다.\n원초적 난제 개발자는 근본적인 가치에서 난제에 봉착한다.\n기한을 맞추려면 나쁜 코드를 양산할 수 밖에 없다고 느끼지만, 오히려 엉망진창인 상태로 인해 속도가 늦어지고 기한을 놓치게 된다.\n💡 기한을 맞추는 유일한 방법은, 즉 빨리 가는 유일한 방법은, 언제나 코드를 최대한 깨끗하게 유지하는 습관이다.\n깨끗한 코드는 어떻게 작성할까? 코드감각 깨끗한 코드를 작성하려면 청결이라는 힘겹게 습득한 감각을 활용해 자잘한 기법들을 적용하는 절제와 규율이 필요하다.\n깨끗한 코드란? 비야네 스트롭스트룹 - Bjarne Stroustrup (C++ 창시자) 간단한 논리\n낮은 의존성\n성능을 최적화\n깨끗한 코드는 한 가지 일을 제대로 한다.\n나쁜 코드는 나쁜 코드를 유혹한다.\n나쁜 코드를 고치면서 오히려 더 나쁜 코드를 만든다. 깨진 창문 깨진 유리창 이론 - 위키백과, 우리 모두의 백과사전\n그래디 부치 - Grady Booch : UML 창시자 깨끗한 코드는 단순하고 직접적이다. 잘 쓴 문장처럼 읽힌다. 결코 설계자의 의도를 숨기지 않는다. 명쾌한 추상화와 단순한 제어문으로 가득하다. 가독성을 강조하고 있다.\n","date":"2023-04-20T15:42:13+09:00","image":"https://codemario318.github.io/post/clean_code_1/clean_code_cover_hud03d003727d53e154227b4e2dbea4cfd_18319_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/clean_code_1/","title":"클린코드: 1. 깨끗한 코드"},{"content":"Go 언어에서 채널은 고루틴을 연결해주는 통로(파이프)다. 기본적으로 채널은 양방향이고 고루틴이 아래 이미지와 같이 동일한 채널을 통해 데이터를 보내거나 받을 수 있다.\nGo 채널은 그 채널을 통하여 데이터를 주고 받는 통로라 볼 수 있다. 채널은 make() 함수를 통해 미리 생성되어야 하며, 채널 연산자 \u0026lt;- 을 통해 데이터를 보내고 받는다.\n채널은 흔이 고루틴들 사이에 데이터를 주고 받을때 사용되는데, 상대편이 준비될 때까지 채널에서 대기함으로써 별도로 lock을 걸지 않고 데이터를 동기화하는데 사용된다.\n아래 예제는 정수형 채널을 생성하고, 한 고루틴에서 그 채널에 123이란 정수 데이터를 보낸 후, 이를 다시 메인 루틴에서 채널로부터 123 데이터를 받는 코드이다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package main func main() { // 정수형 채널을 생성한다 ch := make(chan int) go func() { ch \u0026lt;- 123 //채널에 123을 보낸다 }() var i int i = \u0026lt;- ch // 채널로부터 123을 받는다 println(i) } 채널을 생성할 때는 make()함수에 어떤 타입 데이터를 채널에서 주고받을 지 미리 지정해 주어야 한다. 채널로 데이터를 보낼 때는 채널명 \u0026lt;- 데이터 와 같이 사용하고, 채널로부터 데이터를 받을 경우에는 \u0026lt;- 채널명 와 같이 사용한다.\n메인 루틴은 마지막에서 채널로부터 데이터를 받고 있는데, 상대편 고루틴에서 데이터를 전송할 때까지는 계속 대기하게 된다. 따라서, 이 예제에서는 time.Sleep()이나 fmt.Scanf() 같이 고루틴이 끝날 때까지 기다리는 코드를 적지 않는다.\nGo 채널의 수신자와 송신자가 서로를 기다리는 속성을 이용하여 Go루틴이 끝날 때까지 기다리는 기능을 구현할 수 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package main import \u0026#34;fmt\u0026#34; func main() { done := make(chan bool) go func() { for i := 0; i \u0026lt; 10; i++ { fmt.Println(i) } done \u0026lt;- true }() // 위의 Go루틴이 끝날 때까지 대기 \u0026lt;-done } 익명함수를 사용한 고루틴에서 어떤 작업이 실행되고 있을 때, 메인 루틴은 ←done에서 계속 수신하며 대기하고 있게 된다.\n익명함수 고루틴에서 작업이 끝난 후, done채널에 true를 보내면, 수신자 메인루틴은 이를 받고 프로그램을 끝내게 된다.\nGo 채널 버퍼링 Go 채널은 Unbufferd Channel과 Buffered Channel 2가지 형태가 있다.\nUnbufferd Channel 위 예제에서 Go 채널은 Unbuffered Channel로서 이 채널에서는 하나의 수신자가 데이터를 받을 때까지 송신자가 데이터를 보내는 채널에 묶여있게 된다. (결과를 반환할 때까지 기다린다. blocking?)\nBufferd Channel Bufferd Channel을 사용하면 수신자가 받을 준비가 되어 있지 않아도 지정된 버퍼만큼 데이터를 보내고 계속 다른 일을 수행할 수 있다.(unblocking?) 버퍼 크기까지 입력 작업이 블락되지 않는다.\n버퍼 채널은 make(chan type, N) 함수를 통해 생성되는데, 두번째 파라미터 N에 사용할 버퍼 갯수를 넣는다.\n예를들어 make(chan int, 10)은 10개의 정수형을 갖는 버퍼 채널을 만든다.\n1 2 3 4 5 6 7 8 9 package main import \u0026#34;fmt\u0026#34; func main() { c := make(chan int) c \u0026lt;- 1 //수신루틴이 없으므로 데드락 fmt.Println(\u0026lt;-c) //코멘트해도 데드락 (별도의 Go루틴없기 때문) } 버퍼 채널을 이용하지 않는 경우, 위 코드는 데드락 에러를 발생시킨다. 메인루틴에서 채널에 1을 보내면서 상대편 수신자를 기다리고 있는데, 이 채널을 받는 수신자 고루틴이 없기 때문이다.\n1 2 3 4 5 6 7 8 9 10 11 12 package main import \u0026#34;fmt\u0026#34; func main() { ch := make(chan int, 1) //수신자가 없더라도 보낼 수 있다. ch \u0026lt;- 101 fmt.Println(\u0026lt;-ch) } 위처럼 버퍼채널을 사용하면, 수신자가 당장 없더라도 최대버퍼 수까지 데이터를 보낼 수 있으므로 에러가 발생하지 않는다\n버퍼에 적재된 데이터를 언젠가 가져갈 것이라 판단하고 최대 버퍼수를 넘지 않을때까지 보내도 데드락 에러를 발생시키지 않는다.\nUnbufferd Channel 예제코드 오류 분석 1 2 3 4 5 6 7 8 package main import \u0026#34;fmt\u0026#34; func main() { c := make(chan int) c \u0026lt;- 1 } unbuffered channel에서 발생하는 일반적인 데드락의 의미인 2개 이상의 작업 서로의 작업이 완료되기를 대기하는 교착 상태와는 약간 다르다고 볼 수도 있다.\n왜냐하면 sender와 receiver중 누군가가 먼저 작업을 끝내야지 그 다음으로 누군가가 작업을 수행할 수 있는 것이 아니라 서로 동시에 협력해야만 unbuffered channel에 대한 대기를 끝낼 수 있는데 이 경우는 동시에 협력해줄 그 누군가(receiver)가 없어 무한정 기다리게되는 상황이다.\n1 2 3 4 5 6 7 8 9 package main import \u0026#34;fmt\u0026#34; func main() { c := make(chan int) c \u0026lt;- 1 \u0026lt;- c } 그렇다고해서 위와 같이 자기 혼자 send와 receive를 하려 해도 Unbuffered channel은 sender와 receiver가 모두 ready여야 작업을 진행할 수 있기 때문에 불가능하다.\n1 2 3 4 5 6 7 8 9 10 11 package main import \u0026#34;fmt\u0026#34; func main() { c := make(chan int) go func() { \u0026lt;- c }() c \u0026lt;- 1 } 1 2 3 4 5 6 7 8 9 10 11 package main import \u0026#34;fmt\u0026#34; func main() { c := make(chan int) go func() { c \u0026lt;- 1 }() \u0026lt;- c } 따라서 다른 goroutine에서 A에 대한 receiver or sender 역할을 해주면 된다.\n채널 파라미터 채널을 함수의 파라미터로 전달할 때, 일반적으로 송수신을 모두 하는 채널을 전달하지만, 특별히 해당 채널로 송신만 할 것인지 혹은 수신만 할 것 인지를 지정할 수 있다.\n송신 파라미터: chan\u0026lt;- 수신 파라미터: \u0026lt;-chan 파라미터에 다른 송수신을 바꿔 넣게 되면 에러가 발생한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import \u0026#34;fmt\u0026#34; func main() { ch := make(chan string, 1) sendChan(ch) receiveChan(ch) } func sendChan(ch chan\u0026lt;- string) { ch \u0026lt;- \u0026#34;Data\u0026#34; // x := \u0026lt;-ch // 에러발생 } func receiveChan(ch \u0026lt;-chan string) { data := \u0026lt;-ch fmt.Println(data) } 채널 닫기 채널을 열어 데이터를 보낸 후, close()함수를 사용하여 채널을 닫을 수 있다. (송신자만 가능) 채널을 닫게되면, 해당 채널로는 더이상 송신할 수 없지만, 계속 수신은 가능하다.\n채널 수신에 사용되는 \u0026lt;- ch 은 채널 메시지, 정상 수신 여부 2개의 반환값을 갖는다. 채널이 닫혔을 경우 두번째 리턴값은 false이다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package main func main() { ch := make(chan int, 2) // 채널에 송신 ch \u0026lt;- 1 ch \u0026lt;- 2 // 채널을 닫는다 close(ch) // 채널 수신 println(\u0026lt;-ch) println(\u0026lt;-ch) if _, success := \u0026lt;-ch; !success { println(\u0026#34;더이상 데이타 없음.\u0026#34;) } } 채널 range 문 채널에서 송신자가 송신을 한 후, 채널을 닫을 수 있다. 수신자는 임의의 갯수의 데이터를 채널이 닫힐 때까지 수신할 수 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package main func main() { ch := make(chan int, 2) // 채널에 송신 ch \u0026lt;- 1 ch \u0026lt;- 2 // 채널을 닫는다 close(ch) // 방법1 // 채널이 닫힌 것을 감지할 때까지 계속 수신(무한 for 루프) for { if i, success := \u0026lt;-ch; success { println(i) } else { break } } // 방법2 // 위 표현과 동일한 채널 range 문 (방법 1의 간결한 표현 세부 동작은 같음) for i := range ch { println(i) } } 채널 range문은 range 키워드 다음에 명시한 채널로부터 데이터를 계속 수신하다가 채널이 닫힌 것을 감지하면 for 루프를 종료한다.\n채널 select 문 select문은 복수 채널들을 기다리면서 준비된 채널을 실행하는 기능을 제공한다.\nselect문은 여러개의 case문에서 각각 다른 채널을 기다리다가 준비가 된 채널 case를 실행한다. select문은 case 채널들이 준비되지 않으면 계속 대기하게 되고, 가장 먼저 도착한 채널의 case를 실행한다. 만약 복수 채널에 신호가 오면, Go 런타임이 랜덤하게 그중 한 개를 선택하게 된다. select문에 default문이 있으면, case문 채널이 준비되지 않더라도 계속 대기하지 않고 바로 default문을 실행한다.\n","date":"2023-04-20T13:38:40+09:00","image":"https://codemario318.github.io/post/go_13/go_cover_huf88b72bb4a5683fe0689ce424afc49ae_12554_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://codemario318.github.io/post/go_13/","title":"Golang: 13. Go 채널"},{"content":"Go루틴(goroutine)은 Go 런타임이 관리하는 Lightweight 논리적 (혹은 가상) 쓰레드이다. Go에서 go 키워드를 사용하여 함수를 호출하면, 런타임시 새로운 goroutine을 실행한다.\n고루틴은 비동기적으로 함수루틴을 실행하므로, 여러 코드를 동시에 실행하는데 사용된다.\n고루틴은 OS 쓰레드보다 훨씬 가볍게 비동기 Concurrent(동시성) 처리를 구현하기 위하여 만든것으로, 기본적으로 Go 런타임이 자체 관리한다.\nGo 런타임 상에서 관리되는 작업단위인 여러 고루틴들을 하나의 OS 쓰레드 1개로도 실행되곤 한다. 고루틴들은 OS 쓰레드와 1대1로 대응되지 않고, Multiplexing(다중화)으로 훨씬 적은 OS 쓰레드를 사용한다. 메모리 측면에서도 OS쓰레드가 1MB 스택을 갖는 반면, 고루틴은 이보다 훨씬 작은 몇 KB 스택을 갖는다(필요시 동적으로 증가함). Go 런타임은 Go루틴을 관리하면서 Go 채널을 통해 Go 루틴간의 통신을 쉽게 할 수 있도록 했다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func say(s string) { for i := 0; i \u0026lt; 10; i++ { fmt.Println(s, \u0026#34;***\u0026#34;, i) } } func main() { // 함수를 동기적으로 실행 say(\u0026#34;Sync\u0026#34;) // 함수를 비동기적으로 실행 go say(\u0026#34;Async1\u0026#34;) go say(\u0026#34;Async2\u0026#34;) go say(\u0026#34;Async3\u0026#34;) // 3초 대기 time.Sleep(time.Second * 3) } main 함수를 보면, 먼저 say() 함수를 동기적으로 호출하고, 다음으로 동일한 say() 함수를 비동기적으로 3번 호출하고 있다. 첫번째 동기적 호출은 say() 함수가 완전히 끝났을 때 다음 문장으로 이동하고, 다음 3개의 go say() 비동기 호출은 별도 고루틴들에서 동작하면서, 메인루틴은 계속 다음 문장을 실행한다. 고루틴들은 비동기이므로 처리 순서가 일정하지 않으므로 프로그램 실행시 마다 다른 출력 결과를 나타낼 수 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 Sync *** 0 Sync *** 1 Sync *** 2 Sync *** 3 Sync *** 4 Sync *** 5 Sync *** 6 Sync *** 7 Sync *** 8 Sync *** 9 Async3 *** 0 Async3 *** 1 Async3 *** 2 Async3 *** 3 Async3 *** 4 Async3 *** 5 Async3 *** 6 Async3 *** 7 Async3 *** 8 Async3 *** 9 Async2 *** 0 Async2 *** 1 Async2 *** 2 Async2 *** 3 Async2 *** 4 Async1 *** 0 Async1 *** 1 Async1 *** 2 Async1 *** 3 Async1 *** 4 Async1 *** 5 Async1 *** 6 Async1 *** 7 Async1 *** 8 Async1 *** 9 Async2 *** 5 Async2 *** 6 Async2 *** 7 Async2 *** 8 Async2 *** 9 익명함수 Go루틴 고루틴은 익명함수에 대해 사용할 수도 있다. 즉, go 키워드 뒤에 익명함수를 바로 정의하는 것으로, 익명함수를 비동기로 실행하게 된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { // WaitGroup 생성. 2개의 Go루틴을 기다림. var wait sync.WaitGroup wait.Add(2) // 익명함수를 사용한 goroutine go func() { defer wait.Done() //끝나면 .Done() 호출 fmt.Println(\u0026#34;Hello\u0026#34;) }() // 익명함수에 파라미터 전달 go func(msg string) { defer wait.Done() //끝나면 .Done() 호출 fmt.Println(msg) }(\u0026#34;Hi\u0026#34;) wait.Wait() //Go루틴 모두 끝날 때까지 대기 } 첫번째 익명함수는 간단히 Hello를 출력하는데, 이를 고루틴으로 실행하면 비동기적으로 그 익명함수를 실행하게 된다. 두번째 익명함수는 파라미터를 전달하는 예제로 익명함수에 파라미터가 있는 경우, go 익명함수 바로 뒤에 파라미터를 함께 전달하게 된다.\n여기서 sync.WaitGroup을 사용하고 있는데, 이는 기본적으로 여러 고루틴들이 끝날 때까지 기다리는 역할을 한다. WaitGroup을 사용하기 위해서는 먼저 Add() 메소드에 몇 개의 Go루틴을 기다릴 것인지 지정하고, 각 고루틴에서 Done() 메서드를 호출한다.(여기서는 defer 사용)\n그리고 메인루틴에서는 Wait() 메서드를 호출하여, Go루틴들이 모두 끝나기를 기다린다.\n다중 CPU 처리 go는 디폴트로 CPU 1개를 사용한다. 여러 개 고루틴을 만들더라도, CPU 1개에서 작업을 시분할하여 처리한다. 만약 머신이 CPU 여러개를 가진 경우, Go 프로그램을 다중 CPU에서 병렬처리(Perallel)하게 할 수 있는데, 병렬처리를 위해서는 아래와 같이 runtime.GOMAXPROCS(CPU수) 함수를 호출하여야 한다.\nCPU 수는 Logical CPU 수를 가리킨다. 1 2 3 4 5 6 7 8 9 10 11 12 package main import ( \u0026#34;runtime\u0026#34; ) func main() { // 4개의 CPU 사용 runtime.GOMAXPROCS(4) //... } 동시성과 병렬성은 비슷하게 들리지만 전혀 다른 개념이다.\n","date":"2023-04-20T13:28:40+09:00","image":"https://codemario318.github.io/post/go_12/go_cover_huf88b72bb4a5683fe0689ce424afc49ae_12554_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://codemario318.github.io/post/go_12/","title":"Golang: 12. Go 루틴"},{"content":"지연실행 defer Go 언어의 defer 키워드는 특정 문장 혹은 함수를 나중에 (defer를 호출하는 함수의 결과를 반환하기 직전에) 실행된다.\n일반적으로 defer는 C#, Java 같은 언어에서 finally 블럭처럼 마지막에 Clena-up 작업을 위해 사용된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package main import \u0026#34;os\u0026#34; func main() { f, err := os.Open(\u0026#34;1.txt\u0026#34;) if err != nil { panic(err) } // main 마지막에 파일 close 실행 defer f.Close() // 파일 읽기 bytes := make([]byte, 1024) f.Read(bytes) println(len(bytes)) } 파일을 Open 한 후 바로 파일을 Close하는 작업을 defer로 쓰고 있다. 이는 차후 문장에서 어떤 에러가 발생하더라도 항상 파일을 Close할 수 있도록 한다. panic 함수 Go 내장함수인 panic()함수는 현재 함수를 즉시 멈추고 현재 함수에 defer 함수들을 모두 실행한 후 즉시 리턴한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package main import \u0026#34;os\u0026#34; func main() { // 잘못된 파일명을 넣음 openFile(\u0026#34;Invalid.txt\u0026#34;) // openFile() 안에서 panic이 실행되면 // 아래 println 문장은 실행 안됨 println(\u0026#34;Done\u0026#34;) } func openFile(fn string) { f, err := os.Open(fn) if err != nil { panic(err) } defer f.Close() } 이러한 panic 모드 실행 방식은 다시 상위함수에도 똑같이 적용되고, 계속 콜스택을 타고 올라가며 적용된다. 마지막에는 프로그램이 에러를 내고 종료하게 된다. recover 함수 Go 내장합수인 recover() 함수는 panic 함수에 의한 패닉상태를 다시 정상상태로 되돌리는 함수이다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) func main() { // 잘못된 파일명을 넣음 openFile(\u0026#34;Invalid.txt\u0026#34;) // recover에 의해 // 이 문장 실행됨 println(\u0026#34;Done\u0026#34;) } func openFile(fn string) { // defer 함수. panic 호출시 실행됨 defer func() { if r := recover(); r != nil { fmt.Println(\u0026#34;OPEN ERROR\u0026#34;, r) } }() f, err := os.Open(fn) if err != nil { panic(err) } defer f.Close() } recover 함수를 사용하면 panic 상태를 제거하고 openFile() 다음 문장인 println()을 호출하게 된다. ","date":"2023-04-20T13:26:40+09:00","image":"https://codemario318.github.io/post/go_11/go_cover_huf88b72bb4a5683fe0689ce424afc49ae_12554_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://codemario318.github.io/post/go_11/","title":"Golang: 11. defer와 panic"},{"content":"Go는 내장 타입으로 error 라는 인터페이스 타입을 갖는다. Go 에러는 이 error 인터페이스를 통해서 주고 받게 되는데, 메서드 하나를 갖는다.\n1 2 3 type error interface { Error() string } 개발자는 error 인터페이스를 구현하는 커스텀 에러 타입을 만들 수 있다.\nGo 에러처리 Go 함수가 결과와 에러를 함께 반환한다면, 이 에러가 nil 인지 체크하여 에러를 확인할 수 있다.\n예를들어 os.Open() 함수는 func Open(name string) (file *File, err error) 과 같은 함수 원형을 갖는데, File 포인터와 error 인터페이스를 함께 반환한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package main import ( \u0026#34;log\u0026#34; \u0026#34;os\u0026#34; ) func main() { f, err := os.Open(\u0026#34;C:\\\\temp\\\\1.txt\u0026#34;) if err != nil { log.Fatal(err.Error()) } println(f.Name()) } 그래서 반환된 두번째 error을 체크하여 nil 이면 에러가 없는 것이고, 아니라면 err.Error()로 부터 해당 에러를 알 수 있다.\nlog.Fatal()은 메시지를 출력하고 os.Exit(1)을 호출하여 프로그램을 종료한다. error Type을 이용한 에러처리 또 다른 에러처리로 error의 Type을 체크하여 에러 타입별로 별도의 에러 처리를 하는 방식이 있다.\n1 2 3 4 5 6 7 8 9 _, err := otherFunc() switch err.(type) { default: // no error println(\u0026#34;ok\u0026#34;) case MyError: log.Print(\u0026#34;Log my error\u0026#34;) case error: log.Fatal(err.Error()) } 예제에서 otherFunc()를 호출한 후 반환된 error의 타입을 통해 여러 유형의 에러를 처리할 수 있다.\n모든 에러는 error 인터페이스를 구현하므로 마지막 case문은 모든 에러에 적용된다. ","date":"2023-04-20T13:25:40+09:00","image":"https://codemario318.github.io/post/go_10/go_cover_huf88b72bb4a5683fe0689ce424afc49ae_12554_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://codemario318.github.io/post/go_10/","title":"Golang: 10. 에러"},{"content":"구조체가 필드들의 집합체라면, interface는 메서드들의 집합체이다.\n인터페이스는 타입(type)이 구현해야 하는 메서드 원형(prototype)들을 정의한다. 어떠한 사용자 정의 타입이 인터페이스를 구현하려면 선언한 인터페이스가 갖는 모든 메서드들을 구현하면 된다.\n1 2 3 4 type Shape interface { area() float64 perimeter() float64 } 인터페이스는 구조체와 마찬가지로 type문을 사용하여 정의한다.\n인터페이스 구현 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 //Rect 정의 type Rect struct { width, height float64 } //Circle 정의 type Circle struct { radius float64 } //Rect 타입에 대한 Shape 인터페이스 구현 func (r Rect) area() float64 { return r.width * r.height } func (r Rect) perimeter() float64 { return 2 * (r.width + r.height) } //Circle 타입에 대한 Shape 인터페이스 구현 func (c Circle) area() float64 { return math.Pi * c.radius * c.radius } func (c Circle) perimeter() float64 { return 2 * math.Pi * c.radius } Shape 인터페이스를 구현하기 위해서는 area(), perimeter() 2개 메서드만 구현하면 된다.\n인터페이스 사용 인터페이스를 사용하는 일반적인 예로 함수가 파라미터로 인터페이스를 받을 수 있다.\n함수 파라미터가 인터페이스인 경우, 어떤 타입이든 해당 인터페이스를 구현하기만 하면 모두 입력 파라미터로 사용될 수 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func main() { r := Rect{10., 20.} c := Circle{10} showArea(r, c) } func showArea(shapes ...Shape) { for _, s := range shapes { a := s.area() //인터페이스 메서드 호출 p := s.perimeter() println(a, p) } } Rect 구조체와 Circle 구조체는 Shape 인터페이스에서 선언한 area, perimeter 메서드를 구현하고 있기 때문에 Shape 인터페이스를 상속했다고 볼 수 있다. 따라서 showArea에서 Shape 인터페이스 파라미터 입력으로 사용 가능하다.\n인터페이스 타입 Go 프로그래밍을 하다보면 흔히 빈 인터페이스(empty interface)를 자주 접할 수 있는데, 이는 인터페이스 타입(interface type)으로 불린다.\n여러 표준패키지들의 함수 Prototype을 살펴보면, 빈 인터페이스가 자주 등장한다.\n빈 인터페이스는 interface{} 로 표현한다. 1 2 3 func Marshal(v interface{}) ([]byte, error); func Println(a ...interface{}) (n int, err error); 빈 인터페이스는 메서드를 전혀 갖지 않는 인터페이스이다.\nGo의 모든 Type은 적어도 0개의 메서드를 구현하므로, Go에서 모든 Type을 의미한다.\n즉, 빈 인터페이스는 어떠한 타입도 담을 수 있는 컨테이너로 볼 수 있고, 여러 다른 언어에서 흔히 일컫는 Dynamin Type으로 사용할 수 있다. (C#, java ⇒ object, C,C++ ⇒ void*)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package main import \u0026#34;fmt\u0026#34; func main() { var x interface{} x = 1 x = \u0026#34;Tom\u0026#34; printIt(x) } func printIt(v interface{}) { fmt.Println(v) //Tom } Type Assertion 인터페이스 타입의 x와 타입 T에 대하여 x.(T)로 표현했을 때, 이는 x가 nil이 아니며, x는 T 타입에 속한다는 것을 확인한다. 이러한 표현방식을 Type Assertion 이라고 부른다.\n만약 x가 nil 이거나 x의 타입이 T가 아니라면, 런타임 에러가 발생하고, x가 T 타입인경우는 T 타입 x를 반환한다.\n","date":"2023-04-20T13:08:40+09:00","image":"https://codemario318.github.io/post/go_9/go_cover_huf88b72bb4a5683fe0689ce424afc49ae_12554_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://codemario318.github.io/post/go_9/","title":"Golang: 9. 인터페이스"},{"content":"Go 언어는 OOP를 구조체와 메서드를 이용하는 방식으로 지원한다.\n다른 언어들이 클래스가 내부에 데이터와 메서드를 함께 갖는 것과 달리 Go 언어에서는 구조체가 데이터만을 가지고, 메서드는 별도로 분리하여 정의한다.\nGo 메서드는 특별한 형태의 함수이다. 메서드는 함수 정의에서 func 키워드와 함수명 사이에 “그 함수가 어떤 구조체를 위한 메서드인지” 표시한다.\nreceiver로 부르며 메서드가 속한 구조체 타입과 변수명을 지정하는데, 구조체 변수명은 함수 내에서 입력 파라미터처럼 사용된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package main //Rect - struct 정의 type Rect struct { width, height int } //Rect의 area() 메소드 func (r Rect) area() int { return r.width * r.height } func main() { rect := Rect{10, 20} area := rect.area() //메서드 호출 println(area) } area는 Rect의 메소드로 선언 되어 메서드를 입력처럼 사용할 수 있다.\n(value VS 포인터) receiver Value receiver value receiver는 구조체의 데이터를 복사하여 전달한다. value receiver는 메서드 내의 필드값 변경되더라도 실제 데이터는 변경되지 않는다.\n1 2 3 4 5 6 7 8 9 10 func (r Rect) area2() int { r.width++ return r.width * r.height } func main() { rect := Rect{10, 20} area := rect.area2() //메서드 호출 println(rect.width, area) // 10 220 출력 } 포인터 리시버 포인터 리시버는 구조체의 포인터를 전달한다. 메서드 내의 필드값 변경이 그대로 호출자에서 반영된다.\n","date":"2023-04-20T12:34:40+09:00","image":"https://codemario318.github.io/post/go_8/go_cover_huf88b72bb4a5683fe0689ce424afc49ae_12554_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://codemario318.github.io/post/go_8/","title":"Golang: 8. 메서드"},{"content":"Go 언어는 객체지향 프로그래밍을 고유의 방식으로 지원한다.\n클래스, 객체, 상속 개념이 없다. 전통적인 OOP의 클래스는 Go 언어에서 Custom Type을 정의하는 struct(구조체)로 표현한다.\nStruct Go에서 struct는 Custom Data Type을 표현하는데 사용된다(C 처럼)\n필드들의 집합체이며 필드들의 컨테이너이다. struct는 필드 데이터만을 가지며(자료 구조 역할), 메서드는 표현하지 않는다. 메서드는 별도로 분리하여 정의한다.\nStruct 선언 구조체를 정의하기 위해서 Custom Type을 정의하는데 사용하는 type 문을 사용한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 package main import \u0026#34;fmt\u0026#34; // struct 정의 type person struct { name string age int } func main() { // person 객체 생성 p := person{} // 필드값 설정 p.name = \u0026#34;Lee\u0026#34; p.age = 10 fmt.Println(p) } person 구조체를 패키지 외부에서 사용할 수 있게 하려면 struct명을 Person으로 변경하면 된다.\nstruct 객체 생성 선언된 struct 타입으로부터 객체를 생성하는 방법은 몇 가지 방법들이 있다.\n빈 객체를 먼저 할당하고, 나중에 그 필드값을 채워넣는 방법\n1 2 3 4 p := person{} p.name = \u0026#34;Lee\u0026#34; p.age = 10 초기값을 함께 할당하는 방법\n1 2 3 var p1 person p1 = person{\u0026#34;Bob\u0026#34;, 20} p2 := person{name: \u0026#34;Sean\u0026#34;, age: 50} 초기화가 생략된 필드들은 Zero value (정수인 경우 0, float인 경우 0.0, string인 경우 \u0026ldquo;\u0026rdquo;, 포인터인 경우 nil 등)를 갖는다.\nnew 내장함수 사용\n1 2 p := new(person) p.name = \u0026#34;Lee\u0026#34; // p가 포인터라도 . 을 사용한다 new()를 사용하면 모든 필드를 Zero value로 초기화하고 person 객체의 포인터를 반환한다.\n객체 포인터인 경우에도 필드 엑세스시 . 을 사용하는데 이 때 포인터는 자동으로 역참조된다. (c에서 → 과 동일한 동작)\nGo에서 struct는 기본적으로 mutable 개체로서 필드값이 변화할 경우 해당 개체 메모리에서 직접 변경된다. 하지만 struct 개체를 다른 함수의 파라미터로 넘기면, Pass by Value에 따라 객체를 복사해서 전달한다. 따라서 struct 개체의 값을 변경하려면 포인터를 전달해야 한다.\n생성자 함수 구조체 필드가 사용 전에 초기화되어야 하는 경우가 있다. 예를 들어 struct 필드가 map 타입인 경우 구조체 할당 후 map을 다시 할당받고 초기화 해야한다.\n이럴 때 map을 사전에 미리 초기화 하면, 외부에서 구조체를 사용할 때 별도로 초기화하는 번거로움을 줄일 수 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package main type dict struct { data map[int]string } //생성자 함수 정의 func newDict() *dict { d := dict{} d.data = map[int]string{} return \u0026amp;d //포인터 전달 } func main() { dic := newDict() // 생성자 호출 dic.data[1] = \u0026#34;A\u0026#34; } 생성자 함수인 newDict()는 dict라는 구조체의 map 필드를 초기화한 후 구조체 포인터를 반호나한다. main 함수에서 구조체 개체를 만들 때 dict를 직접 생성하지 않고 대신 생성자 함수를 통해 이미 초기환 된 data 맵 필드를 사용할 수 있다.\n","date":"2023-04-20T12:30:40+09:00","image":"https://codemario318.github.io/post/go_7/go_cover_huf88b72bb4a5683fe0689ce424afc49ae_12554_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://codemario318.github.io/post/go_7/","title":"Golang: 7. 구조체"},{"content":"Go는 패키지를 통해 모듈화, 재사용 기능을 제공한다. 패키지를 사용해서 작은 단위의 컴포넌트를 작성하고, 이러한 작은 패키지들을 활용해서 프로그램을 작성할 것을 권장한다.\nGo는 실제 프로그램 개발에 필요한 많음 패키지들을 표준 라이브러리로 제공한다. 이러한 표준 라이브러리 패키지들을 GOROOT/pkg 안에 존재한다. GOROOT 환경변수는 Go 설치 디렉토리를 가르키는데, 보통 Go 설치시 자동으로 추가된다.\nGo에 사용하는 표준 패키지들은 https://golang.org/pkg 에 자세히 설명되어 있다.\nMain 패키지 일반적으로 패키지는 라이브러리로서 사용되지만, main이라고 명명된 패키지는 Go Compiler에 의해 특별하게 인식된다. 패키지명이 main인 경우, 컴파일러는 해당 패키지를 공유 라이브러리가 아닌 실행 프로그램으로 만든다. 그리고 이 main 패키지 안의 main() 함수가 프로그램의 시작점, 즉 Entry Point가 된다. 패키지를 공유 라이브러리로 만들 때에는, main패키지나 main 함수를 사용해서는 안된다.\n패키지 Import 다른 패키지를 프로그램에서 사용하기 위해서는 import 키워드를 사용하여 패키지를 포함시킨다.\n예를 들어 Go 표준 라이브러리인 fmt 패키지를 사용하기 위해 import “fmt”와 같이 해당 패키지를 포함시킬 것을 선언해 준다.\n1 2 3 4 5 6 7 package main import \u0026#34;fmt\u0026#34; func main(){ fmt.Println(\u0026#34;Hello\u0026#34;) } 패키지를 import 할 때, Go 컴파일러는 GOROOT 혹은 GOPATH 환경 변수를 검색하는데, 표준 패키지는 GOROOT/pkg 에서 사용자 패키지나 3rd party 패키지의 경우 GOPATH/pkg에서 패키지를 찾는다.\nGOROOT 환경변수는 Go 설치시 자동으로 시스템에 설정되지만, GOPATH는 사용자가 지어해 주어야 한다. GOPATH 환경변수는 3rd party 패키지를 갖는 라이브러리 디렉토리나 사용자 패키지가 있는 작업 디렉토리를 지정하게 되는데, 복수 개일 경우 세미콜론을 사용하여 연결한다.\n패키지 scope 패키지 내에는 함수, 구조체, 인터페이스, 메서드 등이 존재하는데, 이름의 첫 문자를 대문자로 시작하면 public으로 사용할 수 있다. 패키지 외부에서 이들을 호출하거나 사용할 수 있게 된다.\n반면 , 이름이 소문자로 시작하면 이는 non-public으로 패키지 내부에서만 사용될 수 있다.\n패키지 init 함수와 alias 개발자가 패키지를 작성할 때, 패키지 실행시 처음으로 호출되는 init() 함수를 작성할 수 있다. init 함수는 패키지가 로드되면서 실행되는 함수로 별도의 호출 없이 자동으로 호출된다.\n1 2 3 4 5 6 7 package testlib var pop map[string]string func init() { // 패키지 로드시 map 초기화 pop = make(map[string]string) } 패키지를 import 하면서 그 패키지 안의 init() 만 호출하길 원한다면, import 시 _ 라는 alias를 지정한다.\n1 2 package main import _ \u0026#34;other/xlib\u0026#34; 패키지 이름이 동일하지만, 서로 다른 버전 혹은 서로 다른 위치에서 로딩하고자 할 때는 패키지 alias를 사용하여 구분할 수 있다.\n1 2 3 4 5 6 7 8 9 import ( mongo \u0026#34;other/mongo/db\u0026#34; mysql \u0026#34;other/mysql/db\u0026#34; ) func main() { mondb := mongo.Get() mydb := mysql.Get() //... } 사용자 정의 패키지 생성 사용자 정의 패키지를 만들어 재사용 가능한 컴포넌트를 만들어 사용할 수 있다. 사용자 정의 라이브러리 패키지는 일반적으로 폴더를 하나 만들고 그 폴더 안에 .go 파일들을 만들어 구성한다.\n하나의 서브 폴더안데 있는 .go 파일들은 동일한 패키지명을 가지며, 패키지명은 해당 폴더의 이름과 같게 한다. 해당 폴더에 있는 여러 .go 파일들은 하나의 패키지로 묶인다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package testlib import \u0026#34;fmt\u0026#34; var pop map[string]string func init() { pop = make(map[string]string) pop[\u0026#34;Adele\u0026#34;] = \u0026#34;Hello\u0026#34; pop[\u0026#34;Alicia Keys\u0026#34;] = \u0026#34;Fallin\u0026#39;\u0026#34; pop[\u0026#34;John Legend\u0026#34;] = \u0026#34;All of Me\u0026#34; } // GetMusic : Popular music by singer (외부에서 호출 가능) func GetMusic(singer string) string { return pop[singer] } func getKeys() { // 내부에서만 호출 가능 for _, kv := range pop { fmt.Println(kv) } } 패키지명은 폴더명과 동일하게 정해야 한다. 패키지 폴더 안에 여러 파일들이 있을 경우에도, 동일한게 폴더 이름을 패키지 이름으로 사용한다.\n💡 사이즈가 큰 목잡한 라이브러리 같은 경우, go install 명령을 사용하여 라이브러리를 컴파일 하여 cache 할 수 있는데, 다음 빌드시 빌드 타임을 크게 줄일 수 있다.\n1 2 cd {{package_dir}} go install 패키지를 찾기 위해 GOROOT와 GOPATH를 사용하는데, GOROOT와 GOPATH에 있는 각 루트폴더의 해당 패키지를 찾게 된다.\nGOPATH가 C:\\GoApp;C:\\GoSrc라면 지정된 라이브러리를 찾기 위해 폴더를 순차적으로 검색하게 된다.\n1 2 3 C:\\Go\\src\\testlib (from $GOROOT) C:\\GoApp\\src\\testlib (from $GOPATH) C:\\GoSrc\\src\\testlib ","date":"2023-04-20T12:28:40+09:00","image":"https://codemario318.github.io/post/go_6/go_cover_huf88b72bb4a5683fe0689ce424afc49ae_12554_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://codemario318.github.io/post/go_6/","title":"Golang: 6. 패키지"},{"content":"배열 Array 배열은 연속적인 메모리 공간에 동일한 타입의 데이터를 순차적으로 저장하는 자료구조이다.\n배열의 선언은 var 변수명 [배열크기] 데이터타입 과 같이 한다. Go에서 배열크기는 Type을 구성하는 한 요소이다. 따라서, [3]int와 [5]int는 서로 다른 타입으로 인식된다.\n1 2 3 4 5 6 7 8 9 package main func main() { var a [3]int //정수형 3개 요소를 갖는 배열 a 선언 a[0] = 1 a[1] = 2 a[2] = 3 println(a[1]) // 2 출력 } 배열 초기화 배열을 정의할 때, 초기값을 설정할 수 있다. 초기값은 [배열크기] 데이터타입 {초기값0, 초기값1 ...} 로 할당한다.\n초기화 과정에서 [\u0026hellip;]를 사용하여 배열 크기를 생략하면 자동으로 초기화 요소 개수만큼 배열 크기가 정해진다.\n1 2 var a1 = [3]int{1, 2, 3} var a3 = [...]int{1, 2, 3} //배열크기 자동으로 다차원 배열 1 2 var multiArray [3][4][5]int // 정의 multiArray[0][1][2] = 10 다차원 배열 초기화 1 2 3 4 5 6 7 func main() { var a = [2][3]int{ {1, 2, 3}, {4, 5, 6}, //끝에 콤마 추가 } println(a[1][2]) } 슬라이스 Slice Go 배열은 고정된 크기 안에 동일한 타입의 데이터를 연속적으로 저장하지만, 배열의 크기를 동적으로 증가시키거나 부분 배열을 추출하는 등의 기능은 없다.\nGo 슬라이스는 내부적으로 배열에 기초하여 만들어졌지만 편리하고 유용한 기능들을 제공한다.\n고정된 크기를 지정하지 않을 수 있음 크기를 동적으로 변경할 수 있음 부분 배열 추출 가능 등 Go 슬라이스 선언은 배열을 선언하듯이 var v []T 처럼 하는데 배열과 달리 크기는 지정하지 않는다.\n1 2 3 4 5 6 7 8 9 package main import \u0026#34;fmt\u0026#34; func main() { var a []int //슬라이스 변수 선언 a = []int{1, 2, 3} //슬라이스에 리터럴값 지정 a[1] = 10 fmt.Println(a) // [1, 10, 3]출력 } make() 슬라이스를 생성하는 다른 방법으로 내장함수 make()를 이용할 수 있다.\nmake함수로 슬라이스를 생성하면 슬라이스 길이(length), 용량(Capacity)을 임의로 지정할 수 있는 장점이 있다.\n1 2 3 4 func main() { s := make([]int, 5, 10) println(len(s), cap(s)) // len 5, cap 10 } → 슬라이스의 길이는 len(), 용량은 cap()을 써서 확인할 수 있다.\n1 2 3 4 5 6 7 8 func main() { var s []int if s == nil { println(\u0026#34;Nil Slice\u0026#34;) } println(len(s), cap(s)) // 모두 0 } make함수로 슬라이스를 생성하면 모든 요소가 Zero value인 슬라이스를 만들게 된다. 또한 슬라이스에 별도의 길이와 용량을 지정하지 않으면, 기본적으로 길이와 용량이 0인 슬라이스를 만드는데 이를 Nill Slice 라고 하며, nil 과 비교하면 참을 반환한다.\n#$# 부분 슬라이스\n슬라이스에서 일부를 발췌하여 부분 슬라이스를 만들 수 있다. 부분 슬라이스는 슬라이스[시작인덱스:마지막인덱스] 형식으로 만든다.\n시작 인덱스는 inclusive이며 마지막 인덱스는 Exclusive이다(파이썬과 동일함)\n1 2 3 4 5 6 7 8 package main import \u0026#34;fmt\u0026#34; func main() { s := []int{0, 1, 2, 3, 4, 5} s = s[2:5] fmt.Println(s) //2,3,4 출력 } 부분 슬라이스에서 인덱스는 생략 가능하다.\n처음 인덱스 생략: 0 자동 대입 마지막 인덱스 생략: 슬라이스 길이 자동대입 따라서 모두 생략하면 전체를 가져온다.\n1 2 3 4 s := []int{0, 1, 2, 3, 4, 5} s = s[2:5] // 2, 3, 4 s = s[1:] // 3, 4 fmt.Println(s) // 3, 4 출력 슬라이스 추가 배열은 고정된 크기로 그 크기 이상의 데이터를 임의로 추가할 수 없지만, 슬라이스는 자유롭게 새로운 요소를 추가할 수 있다.\n슬라이스에 새로운 요소를 추가하려면 내장함수 append()를 사용한다.\n1 2 3 4 5 6 7 8 9 10 func main() { s := []int{0, 1} // 하나 확장 s = append(s, 2) // 0, 1, 2 // 복수 요소들 확장 s = append(s, 3, 4, 5) // 0,1,2,3,4,5 fmt.Println(s) } append 동작 과정 슬라이스 용량이 남아있는 경우 슬라이스의 길이를 변경하여 데이터를 추가 슬라이스 용량을 초과하는 경우 현재 용량의 2배에 해당하는 새로운 Underlying array를 생성하고 기존 배열 값들을 모두 새 배열에 복제한 후 다시 슬라이스를 할당. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package main import \u0026#34;fmt\u0026#34; func main() { // len=0, cap=3 인 슬라이스 sliceA := make([]int, 0, 3) // 계속 한 요소씩 추가 for i := 1; i \u0026lt;= 15; i++ { sliceA = append(sliceA, i) // 슬라이스 길이와 용량 확인 fmt.Println(len(sliceA), cap(sliceA)) } fmt.Println(sliceA) // 1 부터 15 까지 숫자 출력 } 병합 한 슬라이스를 다른 슬라이스 뒤에 병합하기 위해서는 append()와 ellipsis(...)를 사용한다.\nellipsis(...) 은 파이썬 asterisk(*)와 같이 동작한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 package main import \u0026#34;fmt\u0026#34; func main() { sliceA := []int{1, 2, 3} sliceB := []int{4, 5, 6} sliceA = append(sliceA, sliceB...) //sliceA = append(sliceA, 4, 5, 6) fmt.Println(sliceA) // [1 2 3 4 5 6] 출력 } 복사 슬라이스는 내장함수 copy()를 사용하여 한 슬라이스를 다른 슬라이스로 복사할 수도 있다.\n1 2 3 4 5 6 7 func main() { source := []int{0, 1, 2} target := make([]int, len(source), cap(source)*2) copy(target, source) fmt.Println(target) // [0 1 2 ] 출력 println(len(target), cap(target)) // 3, 6 출력 } 슬라이스 내부구조 슬라이스는 내부적으로 사용하는 배열의 부분 영역인 세그먼트에 대한 메타 정보를 가지고 있다. 슬라이스는 크게 3개의 필드로 구성되어 있다.\n내부적으로 사용하는 배열에대한 포인터 세그먼트 길이 세그먼트 최대 용량 처음 슬라이스가 생성될 때, 길이와 용량이 지정되었다면, 내부적으로 용량만큼 크기의 배열을 생성하고, 슬라이스 첫번째 필드에 그 배열의 처음 메모리 위치를 지정한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package main const limit = 10 func main() { slice := []int{0, 1, 2, 3, 4, 5} subSlice := slice[2:5] subSlice[0] = 20 subSlice[1] = 30 subSlice[2] = 40 for _, v := range slice { println(v) } } 1 2 3 4 5 6 0 1 20 30 40 5 서브 슬라이스를 만들면 슬라이스 생성시와 마찬가지로 지정 인덱스만큼의 길이와 용량을 설정하게 되며, 배열 포인터는 시작 슬라이스 위치로 초기화 된다.\n위의 예시의 서브 슬라이스의 길이는 3 용량은 4로 만들어진다.\n따라서 서브 슬라이스의 값을 변경하면 원본 슬라이스의 값도 변경된다.\nMap 선언 Map은 키에 대응하는 값을 신속히 찾는 해시테이블을 구현한 자료구조이다. Go 언어는 Map 타입을 내장하고 있는데, map[key 타입]값타입 로 선언할 수 있다.\n1 var idMap map[int]string 이때 선언된 idMap은 레퍼런스 타입이므로 nil 값을 갖으며, 이를 Nil Map이라고 부른다. Nil map은 어떤 데이터를 쓸 수 없는데, map을 초기화하기 위해 make()함수를 사용할 수 있다.\n초기화 make() 1 idMap = make(map[int]string) make() 함수의 첫번째 파라미터로 map 키워드와 [키타입]값타입을 지정하는데, 이때 make()함수는 해시테이블 자료구조를 메모리에 생성하고 그 메모리를 가리키는 map value를 리턴한다.\n→ map value는 내부적으로 runtime.hmap 구조체를 가리키는 포인터이다.\n따라서 idMap 변수는 이 해시테이블을 가리키는 map을 가리키게 된다.\n초기화 - 리터럴 map은 make() 함수를 써서 초기화할 수도 있지만, 리터럴을 사용해 초기화할 수도 있다. 리터럴 초기화는 map[key타입]value타입 {key:value} 와 같이 Map 타입 뒤 중괄호 안에 \u0026lsquo;키:값\u0026rsquo;들을 결거하면 된다.\n1 2 3 4 5 ticker := map[string]string{ \u0026#34;GOOG\u0026#34;: \u0026#34;Google Inc\u0026#34;, \u0026#34;MSFT\u0026#34;: \u0026#34;Microsoft\u0026#34;, \u0026#34;FB\u0026#34;: \u0026#34;FaceBook\u0026#34;, } Map 사용 처음 map이 make() 함수에 의해 초기화 되었을 때는, 아무 데이터가 없는 상태이다. 이때 새로운 데이터를 추가하기 위해서는 map변수[키] = 값 처럼 해당 키에 그 값을 할당하면 된다.\n만약 키 값이 이미 존재한다면 추가 대신 값만 갱신한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package main func main() { var m map[int]string m = make(map[int]string) m[901] = \u0026#34;Apple\u0026#34; m[134] = \u0026#34;Grape\u0026#34; m[777] = \u0026#34;Tomato\u0026#34; str := m[134] println(str) noData := m[999] println(noData) println(m[777]) delete(m, 777) println(m[777]) } 만약 map안에 찾는 키가 존재하지 않는다면 reference 타입인 경우 nil, value 타입인 경우 zero를 리턴한다.\nmap에서 특정 키와 그 값을 삭제하기 위해서는 delete() 함수를 이용한다.\nMap 키 체크 map을 사용하는 경우 종종 map안에 특정 키가 존재하는지를 체크할 필요가 있다. 이를 위해 go에선 “map 변수[키]” 읽기를 수행할 때 2개 값을 반환한다.\n키에 상응하는 값 키 존재 여부 (bool) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package main func main() { tickers := map[string]string{ \u0026#34;GOOG\u0026#34;: \u0026#34;Google Inc\u0026#34;, \u0026#34;MSFT\u0026#34;: \u0026#34;Microsoft\u0026#34;, \u0026#34;FB\u0026#34;: \u0026#34;FaceBook\u0026#34;, \u0026#34;AMZN\u0026#34;: \u0026#34;Amazon\u0026#34;, } // map 키 체크 val, exists := tickers[\u0026#34;MSFT\u0026#34;] if !exists { println(\u0026#34;No MSFT ticker\u0026#34;) } } for 루프를 사용한 Map 열거 Map이 가진 모든 요소들을 출력하기 위해, for range 루프를 사용할 수 있다. Map 컬렉션에 for range를 사용하면, Map 키와 Map 값 2개 데이터를 반환한다.\n","date":"2023-04-20T12:17:40+09:00","image":"https://codemario318.github.io/post/go_5/go_cover_huf88b72bb4a5683fe0689ce424afc49ae_12554_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://codemario318.github.io/post/go_5/","title":"Golang: 5. 컬렉션"},{"content":"func 키워드를 사용하여 정의한다.\n함수 파라미터는 0개 이상 사용할 수 있는데, 각 파라미터는 파라미터명 뒤에 int, string 등 파라미터 타입을 정의한다.\n함수의 반환 타입은 파라미터 괄호 뒤에 적는다.\n함수는 패키지 안에 정의되며 호출되는 함수가 호출하는 함수의 반드시 앞에 위치해야 할 필요는 없다.\n1 2 3 4 5 6 7 8 9 package main func main() { msg := \u0026#34;Hello\u0026#34; say(msg) } func say(msg string) { println(msg) } Pass By Reference Go에서 파라미터를 전달하는 방식은 크게 Pass By Value와 Pass By Reference로 나뉜다.\nPass By Value 함수를 사용할 때 변수를 그대로 사용하면 함수 인자로 사용된 변수들의 값이 복사되어 함수에게 전달된다.\n따라서 함수 인자로 받은 값을 함수 내부에서 변경해도 실제 변수값은 영향을 전혀 받지 않는다.\nPass By Reference 변수 앞에 \u0026amp; 를 붙이면 주소를 표시한다. 흔히 포인터라 부르며, 포인터를 사용하면 함수에서 해당 변수를 사용할 때 복사본이 아닌 실제 메모리에 접근하여 변수를 지정하므로 함수 내에서 변경이 인자에 넘겨진 주소를 가진 변수의 실제 값이 변경된다.\n1 2 3 4 5 6 7 8 9 10 11 package main func main() { msg := \u0026#34;Hello\u0026#34; say(\u0026amp;msg) println(msg) //변경된 메시지 출력 } func say(msg *string) { println(*msg) *msg = \u0026#34;Changed\u0026#34; //메시지 변경 } 함수에서 파라미터를 선언할 때 *string 처럼 포인터임을 표시하면 해당 파라미터가 문자열이 아닌 문자열을 저장하고있는 메모리의 주소를 갖는다.\n함수 내에서 포인터 파라미터의 주소에 저장된 데이터를 변경하려면 *변수명 = 값 형태로 변수 이름에 역참조 심볼인 *을 붙여 접근하고 변경할 수 있다.\n가변인자함수 함수에 여러개ㅢ 파라미터를 전달하려면 가변 파라미터를 나타내는 ... 을 타입 앞에 붙여 사용한다.\n가변 파라미터를 갖는 함수를 호출할 때 n개 동일 타입 파라미터를 전달할 수 있다.\n1 2 3 4 5 6 7 8 9 10 11 package main func main() { say(\u0026#34;This\u0026#34;, \u0026#34;is\u0026#34;, \u0026#34;a\u0026#34;, \u0026#34;book\u0026#34;) say(\u0026#34;Hi\u0026#34;) } func say(msg ...string) { for _, s := range msg { println(s) } } 함수 반환값 기본형 함수에서 반환값이 있는 경우 func 문 마지막에 리턴 타입을 정의한다. 그리고 return 키워드를 사용해야 한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package main func main() { total := sum(1, 7, 3, 5, 9) println(total) } func sum(nums ...int) **int** { s := 0 for _, n := range nums { s += n } return **s** } 복수 개 반환값 go 언어에서 함수는 반환값이 여러개일 수 있다.\n여러개 값을 반환하기 위해서는 해당 반환 타입들을 괄호 안에 적어준다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package main func main() { count, total := sum(1, 7, 3, 5, 9) println(count, total) } func sum(nums ...int) (int, int) { s := 0 // 합계 count := 0 // 요소 갯수 for _, n := range nums { s += n count++ } return count, s } Named Return Parameter Named Return Parameter라는 기능을 제공하는데, 이는 반환되는 값들을 미리 선언하며, 값들이 여러 개 일때, 코드 가독성을 높힌다.\n1 2 3 4 5 6 7 func sum(nums ...int) (**count** int, **total** int) { for _, n := range nums { total += n } count = len(nums) return } 마지막에 빈 return이 있지만 named return parameter로 정의된 형태로 반환된다. return 은 반환값에 아무런 영향을 주지 않지만 생략하면 에러가 발생한다.\n","date":"2023-04-20T12:10:40+09:00","image":"https://codemario318.github.io/post/go_4/go_cover_huf88b72bb4a5683fe0689ce424afc49ae_12554_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://codemario318.github.io/post/go_4/","title":"Golang: 4. 함수"},{"content":"for 문 Go 언어에서 반복문은 for 하나뿐이다. 다른 언어들과 비슷하게 for 초기값; 조건식; 증감 {...} 형식을 따른다.\n초기값, 조건식, 증감식은 경우에 따라 생략할 수 있고, 초기값; 조건식; 증감 을 둘러싸는 괄호를 추가하면 에러가 발생한다.\n1 2 3 4 5 6 7 8 9 package main func main() { sum := 0 for i := 1; i \u0026lt;= 100; i++ { sum += i } println(sum) } 조건식만 사용하는 for 루프 초기값과 증감식을 생략하고 조건식만 사용하면 다른 언어의 while 루프와 같게 동작한다.\n1 2 3 4 5 6 7 8 9 10 11 12 package main func main() { n := 1 for n \u0026lt; 100 { n *= 2 //if n \u0026gt; 90 { // break //} } println(n) } 무한루프 초기값, 조건식, 증감을 모두 생략하면 무한루프로 동작한다.\n1 2 3 4 5 6 7 package main func main() { for { println(\u0026#34;Infinite loop\u0026#34;) } } range 문 for range문은 컬렉션으로 부터 한 요소씩 가져와 차례로 for 블럭 문장들을 실행한다. 다른 언어의 foreach와 비슷하다.\nfor range 문은 for 인덱스, 요소값 := range 컬렉션 형태로 for 루프를 구성하는데, range 키워드 다음에 명시한 컬렉션으로부터 하나씩 요소를 반환하여 그 요소의 인덱스와 값을 for 키워드 다음 2개 변수에 각각 할당한다.\n1 2 3 4 5 names := []string{\u0026#34;홍길동\u0026#34;, \u0026#34;이순신\u0026#34;, \u0026#34;강감찬\u0026#34;} for index, name := range names { println(index, name) } break, countinue, goto break: for 루프 내에서 즉시 빠져나옴 continue: 루프 중간에서 나머지 문장들을 실행하지 않고 다음 루프를 시작함 goto: 임의의 문장으로 이동 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package main func main() { var a = 1 for a \u0026lt; 15 { if a == 5 { a += a continue // for루프 시작으로 } a++ if a \u0026gt; 10 { break //루프 빠져나옴 } } if a == 11 { goto END //goto 사용예 } println(a) END: println(\u0026#34;End\u0026#34;) } break 레이블 break문은 보통 단독으로 사용되지만, 경우에 따라 레이블을 붙여 지정된 레이블로 이동할 수도 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package main func main() { i := 0 L1: for { if i == 0 { break L1 } } println(\u0026#34;OK\u0026#34;) } break의 레이블은 현재 보통 현재 for 루프 바로 위에 적게 되는데, 현재 루프를 빠져나와 지정된 레이블로 이동하고, 동작한 break문이 속한 for 루프 전체의 다음 문장을 실행한다.\n","date":"2023-04-20T12:05:40+09:00","image":"https://codemario318.github.io/post/go_3/go_cover_huf88b72bb4a5683fe0689ce424afc49ae_12554_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://codemario318.github.io/post/go_3/","title":"Golang: 3. 반복문"},{"content":"if 문 if 문은 해당 조건이 맞으면 {} 블럭 안의 내용을 실행한다.\n조건식을 ()로 둘러 싸지 않아도 된다. 조건 블럭 시작 { 를 if문과 같은 라인에 두어야 한다. 1 2 3 4 5 6 7 if k == 1 { println(\u0026#34;One\u0026#34;) } else if k == 2 { //같은 라인 println(\u0026#34;Two\u0026#34;) } else { //같은 라인 println(\u0026#34;Other\u0026#34;) } Optional Statement if문에서 조건식을 사용하기 이전에 간단한 문장(Optional Statement)을 함께 실행할 수 있다.\n1 2 3 4 5 6 if val := i * 2; val \u0026lt; max { println(val) } // 아래 처럼 사용하면 Scope 벗어나 에러 val++ val := i * 2 처럼 조건식 이전에 연산을 실행할 수 있는데, 정의된 변수 val의 범위는 if-else 블럭이다.\nif문 외에도 switch, for 에서도 사용할 수 있다.\nswitch 문 다른 언어들과 비슷하게 하나의 변수를 지정하고 case문에 해당 변수가 가질 수 있는 값들을 지정하여 case 블럭을 실행한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 package main func main() { var name string var category = 1 switch category { case 1: name = \u0026#34;Paper Book\u0026#34; case 2: name = \u0026#34;eBook\u0026#34; case 3, 4: name = \u0026#34;Blog\u0026#34; default: name = \u0026#34;Other\u0026#34; } println(name) // Expression을 사용한 경우 switch x := category \u0026lt;\u0026lt; 2; x - 1 { //... } } 다른 언어와 차이점 C++, C#, Java 등과 조금 다르게 동작한다.\nswitch 뒤에 expression이 없을 수 있음 다른 언어는 switch 키워드 뒤에 변수나 조건식을 두지만, Go는 쓰지 않아도 된다. 이런 경우 true로 간주하고 첫번째 case문으로 이동하여 검사한다.\ncase문에 조건식 쓸 수 있음 다른 언어는 일반적으로 값을 갖지만, Go는 조건식을 쓸 수 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func grade(score int) { switch { case score \u0026gt;= 90: println(\u0026#34;A\u0026#34;) case score \u0026gt;= 80: println(\u0026#34;B\u0026#34;) case score \u0026gt;= 70: println(\u0026#34;C\u0026#34;) case score \u0026gt;= 60: println(\u0026#34;D\u0026#34;) default: println(\u0026#34;No Hope\u0026#34;) } } No default fall through case문에 기본적으로 break를 적용한다. 다음 case로 넘어가려면 fallthrough 키워드를 쓴다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func check(val int) { switch val { case 1: fmt.Println(\u0026#34;1 이하\u0026#34;) fallthrough case 2: fmt.Println(\u0026#34;2 이하\u0026#34;) fallthrough case 3: fmt.Println(\u0026#34;3 이하\u0026#34;) fallthrough default: fmt.Println(\u0026#34;default 도달\u0026#34;) } } Type switch switch 뒤 변수의 타입으로 분기할 수 있다.\n1 2 3 4 5 6 7 8 9 10 switch v.(type) { case int: println(\u0026#34;int\u0026#34;) case bool: println(\u0026#34;bool\u0026#34;) case string: println(\u0026#34;string\u0026#34;) default: println(\u0026#34;unknown\u0026#34;) } ","date":"2023-04-20T12:00:40+09:00","image":"https://codemario318.github.io/post/go_2/go_cover_huf88b72bb4a5683fe0689ce424afc49ae_12554_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://codemario318.github.io/post/go_2/","title":"Golang: 2. 조건문"},{"content":"변수 기본 선언 변수는 Go 키워드 var을 사용하여 선언한다. var 키워드 뒤에 변수명을 적고 변수 타입을 적는다.\n변수를 선언하면서 초기값을 지정하지 않으면, Go는 Zero Value를 기본적으로 할당한다.\n1 var a int 초기값 지정 변수 선언문에서 변수 초기값을 할당할 수도 있다. float32 타입 변수 f에 11.0이라는 초기값을 할당하기 위해 아래같이 쓸 수 있다.\n1 var f float32 = 11. 할당 선언된 변수는 이후 해당 타입 값을 할당할 수 있다.\n1 2 a = 10 f = 12.0 →선언된 변수가 Go 프로그램 내에서 사용되지 않는다면, 에러를 발생시킨다.\nShort Assignment Statement 함수 내부라면 Short Assignment Statement를 사용할 수 있다.\n1 2 i := 1 s := \u0026#34;Hello\u0026#34; 함수 밖에서 선언시에는 var를 사용해야 한다.\n여러 개 변수 동일한 타입 변수가 여러개 있으면, 변수들을 나열하고 마지막에 타입을 한번만 지정할 수 있다.\n1 2 3 4 var i, j, k int // 선언과 동시에 초기화 가능 var i, j, k int = 1, 2, 3 타입 추론 Go 에서는 할당되는 값을 보고 그 타입을 추론하는 기능이 자주 사용된다.\n1 2 var i = 1 var s = \u0026#34;Hello\u0026#34; i는 정수형으로 1이 할당되고, s는 문자열로 Hello가 할당된다.\n상수 상수는 Go 키워드 const를 사용하여 선언한다. const 키워드 뒤에 상수명을 적고, 그 뒤에 상수 타입, 그리고 상수 값을 할당한다.\n1 2 const i int = 1 const s string = \u0026#34;Hello\u0026#34; 타입 추론 변수와 마찬가지로 타입을 생략하고 초기화 하면 Go에서 자동으로 타입을 추론한다.\n1 2 const i = 1 const s = \u0026#34;Hello\u0026#34; 여러개 상수를 묶어서 지정할 수 있다.\n1 2 3 4 5 const ( Visa = \u0026#34;Visa\u0026#34; Master = \u0026#34;Master\u0026#34; Amex = \u0026#34;American Express\u0026#34; ) iota iota 키워드를 사용하면 상수값을 0부터 순차적으로 부여할 수 있다.\n","date":"2023-04-20T11:56:40+09:00","image":"https://codemario318.github.io/post/go_1/go_cover_huf88b72bb4a5683fe0689ce424afc49ae_12554_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://codemario318.github.io/post/go_1/","title":"Golang: 1. 변수와 상수"},{"content":"Vue? 개발자에게 더 쉽고, 가볍고, 누구나 빨리 배울 수 있는 접근성이 뛰어난 프레임워크를 목표로 개발됨\n기존 HTML 마크업 기반의 템플릿을 그대로 활용 CSS를 작성하는 스타일도 기존 문법을 그대로 따름 라우팅, 상태 관리, 빌드 도구 등 공식적으로 지원하는 라이브러리와 패키지를 통해 배포하여 복잡한 로직의 프론트엔드 개발을 비교적 단순하고 쉽게 만듦 React, Anguler에 비해서 처음 접하는 사용자들이 진입하기에 부담스럽지 않음\nVue3 개선점 가상돔 최적화 AS-IS\n기존 Vue의 렌더링을 위한 가상 DOM 설계는 HTML 기반의 템플릿을 제공하고 이 템플릿 구문을 가상 DOM 트리로 반환한 후 실제로 DOM의 어떤 영역이 업데이트 되어야 하는지 재귀적으로 탐색하는 방식\n이러한 방식은 변경사항 확인을 위해 DOM 트리를 완전 탐색을 하게 되므로, 작은 변경도 트리 전체를 확인하게 되어 비효율적임 TO-BE\n불필요한 탐색을 위한 코드를 제거하여 렌더링 성능을 향상시켜 가상돔 최적화를 진행함\n탬플릿 구문에서 정적 요소와 동적 요소를 구분하여 트리를 탐색할 때 변경이 발생하는 동적 요소만 탐색할 수 있게 변경 렌더링 시 객체가 여러 번 생성되는 것을 방지하기 위해 컴파일러가 미리 템플릿 구문 내에서 정적 요소, 서브 트리, 데이터 객체 등을 탐지해 렌더러 함수 밖으로 호이스팅함 컴파일러가 미리 템플릿 구문 내에서 동적 바인딩 요소에 대해 플래그를 생성함 특정 요소가 동적 클래스 바인딩을 가지고 있고 정적인 값이 지정된 속성을 갖고 있다면 클래스만 처리하면 되므로, 컴파일러가 미리 생성해둔 플래그로 필요한 부분만 처리하여 렌더링 속도 향상 트리쉐이킹 강화 트리쉐이킹이란?\n나무를 흔들어 잎을 떨어트리듯 모듈을 번들링하는 과정에서 사용하지 않는 코드를 제거하여 파일 크기를 줄이는 최적화 방안\nVue3는 템플릿 컴파일러가 실제 사용하는 코드만 임포트 하도록 하였음.\n양방향 데이터 바인딩을 지원하는 v-model 디렉티브와 같은 대부분의 사용자 정의 기능에서 트리쉐이킹이 가능했는데, 이를 강화하여 번들 크기를 절반 이상으로 대폭 줄일 수 있음\nCompoistion API AS-IS\n기존 Vue에서 하나의 컴포넌트에 여러 기능이 포함되면, 기능별로 데이터영역, 메소드 영역, 컴퓨티드 영역, 라이프 사이클 훅, 와치 등 많은 로직이 추가되고, 이러한 기능 별로 분리된 코드들이 각각 기능에 맞는 메서드에 포함되게 되어 필연적으로 섞이게 됨.\n이에 따라 여러 기능이 활용될수록 코드는 커지며 복잡도가 증가함\nTO-BE\n컴포지션 API는 모든 코드를 독립적으로 정의할 수 있다. 각 기능을 함수로 묶어 모듈화 하기 때문에 특정 기능의 유지 보수를 위해 해당 기능을 수행하는 함수만 확인하면 된다.\n코드 재사용 AS-IS\n기존 Vue 에서도 mixin, slot 등으로 컴포넌트 코드를 재사용 할 수 있었으나, 믹스인은 한계가 존재했음\n프로젝트가 커져 믹스인을 다중으로 상속하게 되면 이름 충돌로 인해 컨벤션 룰이 필요했음 매개변수를 믹스인을 통해 전달할 수 없어 유연성이 떨어짐 TO-BE\n컴포지션 API를 사용하면 인스턴스의 특정 기능 단위로 모듈화된 로직을 여러 컴포넌트에서 재사용 할 수 있다.\nmixin?\nVue 컴포넌트에 재사용 가능한 기능을 배포하는 유연한 방법. mixin 객체는 모든 구성요서 옵션을 포함할 수 있으며, 컴포넌트에 mixin을 사용하면 해당 mixin의 모든 옵션이 컴포넌트의 고유 옵션에 “혼합”됨\n그 외 주요 변화 텔레포트 리엑트에서 기본으로 제공하는 포털과 유사한 기능. vue가 기존에 Portal-Vue 플러그인을 통해 제공하고 있었던 기능.\n모달이나 알림 등과 같은 요소를 렌더링하려는 위치가 템플릿 구문이 속하는 컴포넌트와 다른 컴포넌트에 존재할 때, 다른 태그 위치로 모달의 위치를 조정하는 것 처럼 보이게 만드는 것을 CSS를 통해 해결하기 번거롭기 때문에, 보통 모달이 포함된 컴포넌트를 하나 더 만들어 컴포넌트의 구조를 변경하는 방식으로 구현되었음.\nvue3는 텔레포트를 사용하여 모달 컴포넌트를 분리하지 않고도 내부의 HTML을 특정 태그로 옮겨 렌더링 할 수 있게 되었음\n서스펜스 서스팬스 컴포넌트는 리액트가 지원하던 컴포넌트 종류 중 하나로, 컴포넌트 내에 있는 조건인 Async 구문이 충족되지 않으면 조건이 충족될 때까지 템플릿 내에 Fallback 구문을 렌더링함.\n컴포지션 API를 통해 setup() 함수 내에서 외부 API에 접근해 데이터를 가져오는 비동기 작업을 수행하면 데이터를 모두 가져올 때까지 로딩 표시를 해야 할 수 있다. 이럴 때 서스펜스를 사용해 컴포넌트를 감싸면 대체할 템플릿 구문을 렌더링 할 수 있다.\n데이터를 가져오는 도중 오류가 발생하면 Vue3의 새로운 라이프사이클 훅인 OnErrorCaptured를 제공하여, 에러에 대한 처리 구문을 Fallback 구문 대신 표시할 수 있다.\n리액티비티 API 이전 버전의 Vue는 인스턴스 내부에 오브젝트를 선언하고 새로운 속성을 추가하는 것을 감지할 수 없었다. 그래서 기존에는 Vue.set 메소드를 사용하여 기존 객체에 반응성을 부여했다.\nVue3는 이러한 데이터 반응성을 해결하기 위해 리액티비티 API를 지원한다. 객체에 반응성을 추가하기 위해서 리액티브 메소드를 사용하면 된다.\n단순 값이라면 ref 메소드를 사용한다. 이외에도 Readonly, ToRef 등 반응성을 지원하는 여러 API 가 추가되었다.\n","date":"2023-04-18T20:05:16+09:00","image":"https://codemario318.github.io/post/vue3/vue3_cover_huce45f5603be21a224ec2957025110a35_3700_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://codemario318.github.io/post/vue3/","title":"Vue3 살펴보기"},{"content":" 화면이 수정될 때, 렌더링 과정을 최적화하는 방법\n재배치(Reflow)와 다시 그리기(Repainting) 처음 화면이 그려진 후 사용자의 인터렉션에 의해 요소가 변경되는 일이 발생하였을때, Render 트리가 변경되면서 발생한다.\n이 과정이 빈번하게 발생할 수록 성능 및 사용자 경험이 저하되기 때문에 이를 최소화하는 것이 좋다.\n다시 그리기(Repainting) 재배치가 발생하거나 요소의 색상등이 변경된 경우, 다시 화면에 표현하는 동작.\n화면의 구조가 변경되었을 때\nReflow 과정을 거쳐 화면 구조를 다시 계산한 후 Repaint 과정을 통해 화면을 다시 그린다.\n화면의 구조가 변경되었을 때에는 Reflow와 Repaint 모두 발생합니다. 화면의 구조가 변경되지 않는 화면 변화의 경우\nRepaint만 발생화면 구조(Layout)이 변경되었을 때, 뷰포트 내에서 렌더 트리의 노드의 정확한 위치와 크기를 계산하는 과정을 다시 수행해야 한다.\nopacity, background-color, visibility, outline 등의 스타일 변경 시에는 Repaint만 동작한다. Repaint는 변경된 화면을 실제 화면에 반영하는 과정으로 최적화할 수 있는 방법은 화면 변화를 최소화할 수 있는 방법 뿐이다.\n재배치(Reflow) 화면 구조(Layout)이 변경되었을 때, 뷰포트 내에서 렌더 트리의 노드의 정확한 위치와 크기를 계산하는 과정\nReflow가 발생하는 경우 DOM 노드의 추가, 제거 DOM 노드의 위치 변경 DOM 노드의 크기 변경(margin, padding, border, width, height 등..) CSS3 애니메이션과 트랜지션 폰트 변경, 텍스트 내용 변경 이미지 크기 변경 offset, scrollTop, scrollLeft과 같은 계산된 스타일 정보 요청 페이지 초기 렌더링 윈도우 리사이징 위의 내용에서 빠졌더라도 화면의 구조가 변경되었다면 Reflow가 발생한다.\nReflow 최적화 재배치 작업은 다시 그리기 작업을 동반하기 때문에 경우에 따라 Render 트리 전체를 재구성할 수도 있으므로 다시 그리기만 발생할 떄에 비해서 비용이 훨씬 비싸다.\n재배치, 다시 그리기 작업을 최소화 하는 과정을 통해 최적화를 한다.\nReflow는 렌더 트리의 변화를 최소화하는 등.. DOM의 depth를 최소화\nDOM의 깊이와 크기를 작게 구성하여 재배치를 더 빠르게 처리하게 만든다. 스타일 변경을 한번에 처리한다.\n1 2 3 4 5 .newstyles { width: 100px; height: 200px; margin: 10px; } 1 2 3 4 5 // 비효율적인 코드 예시 var myelement = document.getElementById(\u0026#39;myelement\u0026#39;); myelement.width = \u0026#39;100px\u0026#39;; myelement.height = \u0026#39;200px\u0026#39;; myelement.style.margin = \u0026#39;10px\u0026#39;; 1 2 3 // 개선된 예시 var myelement = document.getElementById(\u0026#39;myelement\u0026#39;); myelement.classList.add(\u0026#39;newstyles\u0026#39;); 미리 만들어놓은 스타일을 한번에 적용하여 재배치를 최소화 할 수 있다.\n주변에 영향을 주는 요소를 제한한다.\n인터렉션에 의해 크기나 위치가 변경되는 요소는 병경될 때 주변 요소들이 최대한 영향받지 않도록 정의한다.\n스타일을 변경할 경우 가장 하위 노드의 클래스를 변경 애니메이션이 있는 노드는 position을 fixed 또는 absolute 로 지정한다. 개발자 도구를 이용하여 분석\n개발자 도구를 이용하여 재배치와 다시 그리기가 얼마나 발생하는지 확인하고 해당 요소를 최적화 시도한다.\n라이브러리를 사용한다.\nReact, Vue는 트리 형태의 Object를 통해 Virtual DOM을 구성하고 요소가 변경될 때 업데이트한다. 그 후 최종 상태의 Virtual DOM을 실제 DOM에 반영하여 재배치와 다시 그리기를 최소화 시켜 렌더링 최적화를 구현한다.\n스타일을 변경할 경우 가장 하위 노드의 클래스를 변경\nDOM 노드의 크기 또는 위치가 변경되면 하위 노드와 상위 노드까지 영향을 미칠 수 있다. 따라서 가장 하위 노드의 스타일을 변경할 경우, 전체 노드가 아니니 일부 노드로 영향을 최소화 할 수 있다.\n하지만 실무에서는 보통 변경해야 할 노드들이 정해져 있기 때문에 적용 범위가 크지 않을 수 있다.\n애니메이션이 있는 노드는 position을 fixed 또는 absolute로 지정한다. 애니메이션 효과는 많은 Reflow 비용이 발생하게 됨.\nposition 속성을 fixed 또는 absolute 로 지정하면, 해당 노드를 전체 노드에서 분리시켜 일부만 Reflow가 발생하도록 제한시킬 수 있다.\n애니메이션 효과를 줘야 하는 노드에 position 속성이 적용되지 않았다면 애니메이션 시작 시 position 속성 값을 fixed 또는 absolute로 변경하였다가 애니메이션 종료 후 다시 원복 시켜 렌더링을 최적화할 수 있다.\n\u0026lt;table\u0026gt; 레이아웃을 피한다. \u0026lt;table\u0026gt; 은 점진적으로 렌더링 되지 않고, 모두 로드되고 테이블 너비가 계산된 후 화면에 그려진다. 테이블 안의 콘텐츠의 값에 따라 테이블 너비가 계산된다.\n콘텐츠의 값에 따라 테이블 너비가 계산되기 때문에, 테이블 콘텐츠의 작은 변경만 있어도 테이블 너비가 다시 계산되고 테이블의 모든 노드들이 Reflow가 발생한다.\n부득이하게 \u0026lt;table\u0026gt;을 사용할 때는 table-layout:fixed 값을 지정하는 것이 좋다.\ntable-layout:fixed는 테이블의 콘텐츠의 길이에 따라 테이블의 너비가 계산되는 것이 아니기 때문에, table-layout의 기본 값인 auto에 비해 성능이 더 좋다. \u0026lt;table\u0026gt;을 레이아웃 용도가 아닌 데이터 표시 용도로 사용할 때도 table-layout:fixed를 지정하는 것이 성능 면에서 더 좋습니다. IE의 CSS 표현식을 사용하지 않는다. CSS 표현식은 비용이 매우 높기 때문에 사용을 피해야 함\n1 2 3 .expression { width: expression(document.documentElement.clientWidth \u0026gt; 0 ? \u0026#39;1000px\u0026#39; : \u0026#39;auto\u0026#39;); } Reflow가 발생할 때마다 자바스크립트 표현식이 다시 계산되기 때문에 CSS 표현식은 비용이 비싸다.\n애니메이션이 동작한다면, 애니메이션에 의한 Reflow가 발생할 때마다 자바스크립트 표현식이 계산됨. CSS 하위 선택자를 최소화한다. 1 2 3 4 5 6 7 8 /* 잘못된 예 */ .reflow_box .reflow_list li .btn{ display:block; } /* 올바른 예 */ .reflow_list .btn { display:block; } CSS 하위 선택자를 최소화하는 것이 렌더링 성능에 더 좋다.\n렌더 트리는 DOM과 CSSOM이 합쳐져서 만들어 지는데, DOM은 HTML이 파싱 되어 만들어진 트리이고, CSSOM은 CSS가 파싱 되어 만들어진 트리이다.\n두 트리를 결합하여 렌더 트리를 만드는데, CSS 하위 선택자가 많아지만 CSSOM 트리의 깊이가 깊어지게 되고 결국 렌더 트리를 만드는 시간이 더 오래 걸릴 수 있다.\n숨겨진 노드의 스타일을 변경한다. display:none으로 숨겨진 노드를 변경할 때는 Reflow가 발생하지 않기 때문에 숨겨진 노드를 표시하기 전에 노드의 콘텐츠를 먼저 변경한 후 화면에 나타내면 Reflow를 줄일 수 있다.\n클래스를 사용하여 한 번에 스타일을 변경한다. 스타일을 변경할 때, 스타일을 각각 변경할 경우 추가 Reflow가 발생할 수 있기 때문에 한번에 스타일을 변경하는 것이 좋다.\n요약 Repaint(Redraw)는 화면에 변화가 있을 때 화면을 그리는 과정 Reflow(Layout)는 뷰포트 내에서 렌더 트리의 노드의 정확한 위치와 크기를 계산하는 과정 Repaint가 발생하는 경우는 화면이 변경되는 모든 경우 Reflow가 발생하는 경우는 화면의 구조가 바뀌었을 경우 Reflow를 최적화하는 방법 스타일을 변경할 경우 가장 하위 노드의 클래스를 변경한다. 인라인 스타일을 사용하지 않는다. 애니메이션이 있는 노드는 position을 fixed 또는 absolute로 지정한다. 퀄리티, 퍼포먼스의 타협점을 찾는다. \u0026lt;table\u0026gt; 레이아웃을 피한다. IE의 CSS 표현식을 사용하지 않는다. CSS 하위 선택자를 최소화한다. 숨겨진 노드의 스타일을 변경한다. 클래스를 혹은 cssText 사용하여 한 번에 스타일을 변경한다. DOM 사용을 최소화한다. 캐시를 활용한다. 라이브러리를 사용한다. ","date":"2023-04-18T19:48:26+09:00","image":"https://codemario318.github.io/post/rendering_optimize/browser_cover_huc408e1e4bc0026ab219b7f7573db946e_26010_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/rendering_optimize/","title":"랜더링 업데이트 최적화"},{"content":" CRP 최적화란 HTML, CSS 및 JS 간 종속성을 이해하고 최적화 하는것이다.\nCritical Rendering Path란? 브라우저가 페이지의 초기 출력을 위해 실행해야 하는 순서\nDOM 트리 구축 CSSOM 트리 구축 JS 실행 렌더트리 구축 레이아웃 생성 페인팅 CSS CSS는 렌더링 차단 리소스이므로 최초 렌더링에 걸리는 시간을 최적화하려면 클라이언트에 최대한 빠르게 다운로드되어야 한다.\n렌더 트리를 만들 때 사용되는 HTML, CSS 모두 렌더링 차단 리소스 CSS가 없는 페이지는 상대적으로 사용성이 떨어지기 때문에 브라우저는 DOM과 CSSOM을 모두 사용할 수 있게 될 때까지 렌더링을 차단한다.\nCSS를 간단하게 유지하고 가능한 빨리 제공하고 최대한 빨리 렌더링의 차단을 해제해야 한다.\n미디어 쿼리, 미디어 유형 미디어 쿼리를 사용하면 특정한 사용 사례와 동적인 조건에 맞게 렌더링이 차단되므로 효율을 높힐 수 있다.\n미디어 유형과 미디어 쿼리를 통해 일부 CSS 리소스를 렌더링 비차단 리소스로 표시할 수 있음 브라우저는 차단 동작이든 비차단 동작이든 관계없이 모든 CSS 리소스를 다운로드함 미디어 쿼리는 하나의 미디어 유형과 특정 미디어 기능의 조건을 확인하는 0개 이상의 식으로 구성된다.\n1 2 3 4 5 6 \u0026lt;!-- 1 --\u0026gt; \u0026lt;link href=\u0026#34;style.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34;\u0026gt; \u0026lt;!-- 2 --\u0026gt; \u0026lt;link href=\u0026#34;print.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34; media=\u0026#34;print\u0026#34;\u0026gt; \u0026lt;!-- 3 --\u0026gt; \u0026lt;link href=\u0026#34;other.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34; media=\u0026#34;(min-width: 40em)\u0026#34;\u0026gt; 조건이 없는 경우\n미디어 유형이나 미디어 쿼리를 제공하지 않아서 모든 경우에 적용됨 즉 항상 렌더링을 차단함 미디어 유형을 적용\n콘텐츠가 인쇄될 때만 적용 처음에 로드될 때 페이지 렌더링을 차단할 필요가 없음 미디어 쿼리 적용\n조건이 일치하면 스타일시트가 다운로드되고 처리될 때까지 브라우저가 렌더링을 차단. JS 자바스크립트는 파서 차단 리소스(parser blocking resource)이며, JS를 사용하면 콘텐츠, 스타일, 사용자와의 상호작용등 거의 모든것을 수정할 수 있다.\nJS실행은 DOM 생성을 차단하고 페이지 렌더링을 지연하게 된다.\n자바스크립트를 비동기로 설정하고, CRP에서 불필요한 JS를 제거해야 한다. JS와 HTML의 종속성 HTML 파서는 script 태그를 만나면 DOM 생성 프로세스를 중지하고 자바스크립트 엔진에 권한을 넘긴다. 자바스크립트 엔진의 실행이 완료된 후 브라우저가 중지했던 시점부터 DOM 생성을 다시 시작하게 된다.\nscript 태그의 뒷부분에서 정의된 어떠한 태그들도 아직 생성되지 않았기 때문에 노드를 찾을 수 없다. 또한, 인라인 스크립트를 실행하면 DOM 생성이 차단되고, 이로 인해 초기 렌더링도 지연된다.\n이러한 이유로 인하여 자바스크립트는 화면에 그려지는 태그들이 모두 파싱 된 후인, \u0026lt;body\u0026gt; 태그를 닫기 직전에 \u0026lt;script\u0026gt; 태그를 선언하는 것이 좋다.\nJS와 CSS의 종속성 CSS를 파싱 하는 동안 자바스크립트에서 스타일 정보를 요청하는 경우, CSS가 파싱이 끝나지 않은 상태라면 자바스크립트 오류가 발생할 수 있다. CSS 파싱으로 생성되는 CSSOM과 JavaScript에서 스타일 수정 시 발생하는 CSSOM 수정 사이에 경쟁 조건(race condition)이 발생할 수 있다.\n브라우저는 이 문제를 해결하기 위해 CSSOM을 생성하는 작업이 완료할 때까지 자바스크립트 실행 및 DOM 생성을 지연시킨다. DOM, CSSOM, 자바스크립트 실행 간에 종속성 때문에 브라우저가 화면에 페이지를 처리하고 렌더링 할 때 상당한 지연이 발생할 수 있습니다.\n비동기 JS HTML을 파싱 하면서 script 태그를 만나면 DOM 생성을 중지시키고 자바스크립트 엔진에게 제어 권한을 넘겨 자바스크립트를 실행한 후, DOM 생성을 진행한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 \u0026lt;!-- index.html --\u0026gt; \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width,initial-scale=1\u0026#34;\u0026gt; \u0026lt;link href=\u0026#34;style.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Critical Path: Script\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Hello \u0026lt;span\u0026gt;web performance\u0026lt;/span\u0026gt; students!\u0026lt;/p\u0026gt; \u0026lt;script src=\u0026#34;app.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 1 2 3 4 5 6 7 8 9 // app.js var span = document.getElementsByTagName(\u0026#39;span\u0026#39;)[0]; span.textContent = \u0026#39;interactive\u0026#39;; // change DOM text content span.style.display = \u0026#39;inline\u0026#39;; // change CSSOM property // create a new element, style it, and append it to the DOM var loadTime = document.createElement(\u0026#39;div\u0026#39;); loadTime.textContent = \u0026#39;You loaded this page on: \u0026#39; + new Date(); loadTime.style.color = \u0026#39;blue\u0026#39;; document.body.appendChild(loadTime); 위에서 살펴본 인라인 스크립트뿐만 아니라 위의 코드와 같이 script 태그를 통해 포함된 자바스크립트 역시 파싱을 중지시킨다.\nscript 태그를 사용하여 자바스크립트를 실행할 경우, 서버에서 자바스크립트를 가져올 때까지 기다려야하며 이로 인해 수십~수천 밀리초의 지연이 추가로 발생할 수 있다.\n기본적으로 자바스크립트가 실행될 때, 스크립트가 페이지에서 무엇을 수행할지 모르기 때문에 브라우저는 최악의 대비하여 파서를 차단한다.\n브라우저에 자바스크립트를 바로 실행할 필요가 없음을 알려준다면, 브라우저는 계속해서 DOM을 생성할 수 있고 DOM 생성이 끝난 후에 자바스크립트를 실행할 수 있게 된다.\n이때 사용할 수 있는 것이 비동기 자바스크립트이다.\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width,initial-scale=1\u0026#34;\u0026gt; \u0026lt;link href=\u0026#34;style.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Critical Path: Script Async\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Hello \u0026lt;span\u0026gt;web performance\u0026lt;/span\u0026gt; students!\u0026lt;/p\u0026gt; \u0026lt;script src=\u0026#34;app.js\u0026#34; async\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 위의 코드와 같이 단순히 script 태그에 async 속성을 추가해 주면 됩니다. async 속성을 script 태그에 추가하여 자바스크립트가 사용 가능해질 때까지 브라우저에게 DOM 생성을 중지하지 않아도 괜찮다는 것을 알릴 수 있다.\n리소스 우선순위 지정 브라우저는 가장 중요한 리소스(스크립트나 이미지보다 CSS 우선)를 우선 로드하기 위해 가장 중요하다 생각되는 리소스를 추측하여 먼저 로드한다. 하지만 브라우저에게 리소스의 우선순위를 전달하여 중요한 리소스를 먼저 처리하게 할 수 있다.\npreload 속성 현재 페이지에서 빠르게 가져와야 하는 리소스에 사용되는 속성이다.\n\u0026lt;link rel=\u0026quot;preload\u0026quot; as=\u0026quot;...\u0026quot;\u0026gt;는 브라우저에게 현재 리소스가 필요하며, 가능한 한 빨리 가져오기를 시도해야 한다고 알리는 역할을 한다.\n1 2 \u0026lt;link rel=\u0026#34;preload\u0026#34; as=\u0026#34;script\u0026#34; href=\u0026#34;super-important.js\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;preload\u0026#34; as=\u0026#34;style\u0026#34; href=\u0026#34;critical.css\u0026#34;\u0026gt; as 속성을 사용하여 리소스의 유형을 알려줘야 한다. 브라우저는 올바른 유형이 설정되어 있지 않으면 미리 가져온 리소스를 사용하지 않는다. preload는 브라우저가 반드시 리소스를 가져오게 만들며, 리소스를 두 번 가져오게 하거나, 필요하지 않은 것을 가져오지 않도록 주의해야한다.\npreload를 이용하여 리소스를 가져왔지만 현재 페이지에서 즉시 사용되지 않는 리소스는 위의 그림과 같이 워닝 로그가 노출된다.\nprefetch 속성 미래에 필요할 수 있는 리소스를 가져와야 할 때 사용되는 속성이다. \u0026lt;link rel=\u0026quot;prefetch\u0026quot;\u0026gt;는 현재 페이지 로딩이 마치고 다운로드할 여유가 생겼을 때 가장 낮은 우선순위로 리소스를 가져온다.\nprefetch는 사용자가 다음에 할 행동을 미리 준비하는 역할을 한다. 예를 들어, 현재 페이지가 1페이지 라면,\n1 \u0026lt;link rel=\u0026#34;prefetch\u0026#34; href=\u0026#34;page-2.html\u0026#34;\u0026gt; 위의 코드와 같이 사용하여 2페이지를 먼저 가져와 준비하게 된다.\npage-2.html의 HTML만 가져오고 page-2.html에서 사용되는 리소스는 가져오지 않는다.\n요약 CSS 최적화 방법\n미디어 유형, 미디어 쿼리를 사용 JavaScript 최적화 방법\nbody 태그 닫기 직전 \u0026lt;script\u0026gt; 태그를 선언 \u0026lt;script ... async\u0026gt;와 같이 async 속성을 사용 리소스 우선순위 지정\n현재 페이지에서 빠르게 가져와야 하는 리소스에 \u0026lt;link rel=\u0026quot;preload\u0026quot; as=\u0026quot;...\u0026quot;\u0026gt;와 같이 preload 속성을 사용 미래에 사용할 수 있는 리소스는 \u0026lt;link rel=\u0026quot;prefetch\u0026quot;\u0026gt;와 같이 prefetch 속성을 사용 ","date":"2023-04-18T19:27:35+09:00","image":"https://codemario318.github.io/post/crp_optimize/browser_cover_huc408e1e4bc0026ab219b7f7573db946e_26010_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/crp_optimize/","title":"Critical Rendering Path 최적화"},{"content":"브라우저 기본 구조 사용자 인테페이스\n요청한 페이지를 보여주는 부분의 제외한 나머지 부분\n브라우저 엔진\n사용자 인터페이스와 렌더링 엔진 사이의 동작을 제어\n랜더링 엔진\n요청한 콘텐츠 표시\nHTML을 요청하면 HTML과 CSS를 파싱하여 화면에 표시함 통신\nHTTP 요청과 같은 네트워크 호출에 사용됨.\n플랫폼 독립적인 인터페이스이고 각 플랫폼 하부에서 실행됨. UI 백앤드\n콤보 박스와 창 같은 기본적인 장치를 그림\n플랫폼에서 명시하지 않은 일반적인 인터페이스로서, OS 사용자 인터페이스 체계를 사용 자바스크립트 해석기\n자바스크립트 코드를 해석하고 실행\n자료 저장소\n자료를 저장하는 계층으로 쿠키와 같은 모든 종류의 자원을 하드디스크에 저장.\nHTML5에는 브라우저가 지원하는 \u0026lsquo;웹 데이터 베이스\u0026rsquo; 가 정의되어 있다. 크롬은 대부분의 브라우저와 달리 각 탭마다 별도의 렌더링 엔진 인스턴스를 유지하여, 각 탭이 독립된 프로세스로 처리된다.\n렌더링 렌더링 엔진 요청받은 내용을 브라우저 화면에 표시함. HTML 및 XML 문서와 이미지를 표시할 수 있다.\n렌더링 엔진의 역할은 요청받은 내용을 브라우저 화면에 나타내는 일이다. HTML, CSS JS 등의 파일을 브라우저가 화면에 표시할 수 있도록 변환하여 픽셀 단위로 나타낸다.\n렌더링 엔진 동작과정 렌더링 엔진은 요청한 문서의 내용을 얻는 것에서 시작하며, 보통 8KB 단위로 전송된다.\n렌더링 엔진은 HTML 문서를 파싱하고 콘텐츠 트리 내부에서 태그를 DOM 노드로 변환한다. 그 다음 외부 CSS 파일과 함께 포함된 스타일 요소도 파싱한다. 스타일 정보와 HTML 표시 규칙은 렌더 트리 라고 부르는 또 다른 트리를 생성한다.\n파싱 문서를 통해 파싱트리를 만드는 과정\n어휘분석: Tokenizer\n문서를 읽어 정해놓은 규칙을 통해 토큰을 추출하는 도구, 과정을 의미한다.\nToken: 의미적으로 더이상 나눌 수 없는 기본적인 언어 요소를 표현하는 데이터 단위\n구문분석: Lexer\n토큰에 약속된 의미를 부여하는 도구, 과정\n어휘분석과 구문분석의 결과물을 이용하여 파싱트리를 만드는 과정이다. 컴파일 파싱을 통해 만들어진 결과물을 기계 코드로 변환하는 과정이다\nDOM - 문서 객체 모델: Document Object Model HTML, XML 문서의 프로그래밍 인터페이스이다. HTML 문서의 객체 표현\n문서의 구조화된 표현을 제공하며 프로그래밍 언어가 DOM 구조에 접근할 수 있는 방법을 제공하여 그들이 문서 구조, 스타일, 내용 등을 변경할 수 있게 돕는다.\nnodes와 property와 method 를 갖고 있는 objects로 문서를 표현한다. 이들은 웹 페이지를 스크립트 또는 프로그래밍 언어들에서 사용될 수 있게 연결시켜주는 역할을 담당한다.\n동일한 문서를 표현, 저장, 조작하는 방법을 제공하는 웹 페이지의 객체 지향 표현\n따라서, DOM은 마크업과 1:1 관계를 맺는다.\n1 2 3 4 5 6 \u0026lt;html\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Hello World\u0026lt;/p\u0026gt; \u0026lt;div\u0026gt;\u0026lt;img src=\u0026#34;example.png\u0026#34; /\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; CSSOM(CSS Object Model) 위의 그림과 같이 DOM을 생성하는 과정 그대로 CSSOM을 생성한다.\n브라우저는 DOM을 생성하는 동안 외부 CSS를 참조하는 \u0026lt;link\u0026gt; 태그를 만나게 되면 브라우저에 리소스를 요청함. CSS의 원시 바이트가 문자열로 변환 된 후 차례로 토큰과 노드로 변환되고 마지막으로 CSSOM이라는 트리 구조를 만든다. CSSOM은 하향식으로 규칙을 적용하기 때문에 트리 구조를 가진다. 최종 스타일을 계산할 때 브라우저는 해당 노드에 적용 가능한 가장 일반적인 규칙으로 시작해 더 구체적인 규칙을 적용하는 방식으로 처리된다.\nDOM 트리를 바탕으로 CSSOM 트리를 만들기 때문에 해당 하는 스타일룰이 적용이 된 트리 형태로 구성되는 것 같다.\n어태치먼트: 랜더링 트리 생성 과정 DOM 트리와 CSSOM 트리를 결합하여, 표시해야 할 순서로 내용을 그려냏 수 있도록 하기 위해 렌더트리를 형성한다. 이 과정을 웹킷에서는 어테치먼트라고 한다.\n렌더트리는 화면에 표시되는 각 노드의 위치를 계산하는 레이아웃에 사용되고 픽셀을 하면에 그리는 페인트 과정에도 사용됨\n랜더 트리 생성 과정 DOM 트리 구축을 위한 HTML 파싱 HTML 파싱 → DOM 트리 구축 CSSOM 트리 구축을 위한 CSS 파싱 CSS → CSSOM 트리 생성 DOM 트리와 CSSOM 트리를 활용하여 랜더 트리 구축 DOM Tree + CSSOM Tree = Rendering Tree 랜더링 트리 생성 과정 2 DOM 트리의 루트에서 시작하여 표시되는 노드 각각을 탐색함 스크립트 태그, 메타 태그 등 랜더링된 출력에 반영되지 않는 트리들이 생략됨 CSS를 속성을 통해 숨겨지는 노드들이 생략됨 ex) display: none 표시된 각 노드에 대해 적절하게 일치하는 CSSOM 규칙을 찾아 적용 표시된 노드를 콘텐츠 및 계산된 스타일과 함께 내보냄 visibility: hidden은 비어 있는 상자로 렌더링되지만 display: none은 랜더링에서 제외됨. 따라서 후자는 스크린 리더기에서 읽을 수 없음, 전자는 일부 스크린 리더기에서 인식하지 않기 때문에 접근성을 위한 IR 처리시 주의해야 한다.\n최종 출력은 화면에 표시되는 모든 노드의 콘텐츠 및 스타일 정보를 포함하는 렌더링 트리\n레이아웃 렌더 트리가 생성되고, 기기의 뷰포트 내에서 렌더 트리의 노드가 정확한 위치와 크기를 계산하는 과정.\n모든 상대적인 측정값은 화면에서 절대적인 픽셀로 변환됨. 즉 CSS에 상대적인 값인 %로 할당된 값들은 절대적인 값인 PX 단위로 변환.\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width,initial-scale=1\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Critial Path: Hello world!\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div style=\u0026#34;width: 50%\u0026#34;\u0026gt; \u0026lt;div style=\u0026#34;width: 50%\u0026#34;\u0026gt;Hello world!\u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 뷰포트 내에서 각 요소의 정확한 위치와 크기를 정확하게 캡처하는 상자 모델이 출력된다. 모든 상대적인 측정값은 화면에서 절대적인 픽셀로 변환된다.\n페인팅 렌더링 트리의 각 노드를 화면의 실제 픽셀로 변환하는 마지막 단계로 이러한 정보를 전달할 수 있습니다.\n\u0026lsquo;Layout\u0026rsquo; 이벤트는 타임라인에서 렌더링 트리 생성, 위치 및 크기 계산을 캡처. 레이아웃이 완료될 때 브라우저가 Paint Setup 및 Paint 이벤트를 발생. 이러한 작업은 렌더링 트리를 화면의 픽셀로 변환. 렌더링 트리 생성, 레이아웃 및 페인트 작업을 수행하는 데 필요한 시간은 문서의 크기, 적용된 스타일 및 실행 중인 기기에 따라 달라진다.\n문서가 클수록 브라우저가 수행해야 하는 작업도 더 많아지며, 스타일이 복잡할수록 페인팅에 걸리는 시간도 늘어나게 된다.\nex) 단색은 페인트하는 데 시간과 작업이 적게 필요한 반면, 그림자 효과는 계산하고 렌더링하는 데 시간과 작업이 더 필요하다. 요약 HTML 마크업을 처리하고 DOM 트리를 빌드 (DOM 파싱) CSS 마크업을 처리하고 CSSOM 트리를 빌드 (CSS 파싱) DOM 및 CSSOM을 결합하여 렌더 트리를 형성 (Attachment) 렌더 트리에서 레이아웃을 실행하여 각 노드의 기하학적 형태를 계산 (Layout) 개별 노드를 화면에 페인트(Painting) 참고 자료\nhttps://developers.google.com/web/fundamentals/performance/critical-rendering-path?hl=ko https://janghanboram.github.io/2018/06/06/browser-rendering/ https://d2.naver.com/helloworld/59361 http://taligarsiel.com/Projects/howbrowserswork1.htm#Render_tree_construction https://grosskurth.ca/papers/browser-refarch.pdf https://yilpe93.github.io/2018/06/18/etc/web-browser/ https://sangbui.com/sb-files/BrowserArchitecture_ClientSide.pdf https://medium.com/@monica1109/how-does-web-browsers-work-c95ad628a509 https://blog.lgcns.com/1911 https://cisctbd.github.io/Report.pdf https://blog.asamaru.net/2017/05/04/understanding-the-critical-rendering-path/ ","date":"2023-04-18T18:48:11+09:00","image":"https://codemario318.github.io/post/browser/browser_cover_huc408e1e4bc0026ab219b7f7573db946e_26010_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/browser/","title":"브라우저"},{"content":"Message Queue란? MQ란 메시지 기반의 미들웨어로 메시지를 이용하여 여러 어플리케이션, 시스템, 서비스들을 연결해주는 솔루션이다. MOM(Message Oriented Middleware)를 구현한 솔루션으로 비동기 메시지를 사용하는 서비스들 사이에서 데이터를 교환해주는 역할을 한다.\nProducer(sender)가 메시지를 큐에 전송하면 Consumer(receiver)가 처리하는 방식으로, Producer와 Consumer에 message 프로세스가 추가되는 것이 특징이다.\nMQ를 사용하여 비동기로 요청을 처리하고 Queue 에 저장하여 Consumer에게 병목을 줄여줄 수 있으나 제품마다 구현이 다르고 장단이 있다.\n대표 솔루션 IBM MQ 가장 많이 사용되는 상용 MQ 제품으로 표준 JMS 메시지 ㅇ기반으로 MQTT 프로토콜을 지원한다.\nApache ActiveMQ 자바 기반의 JMS Queue를 지원하는 오픈소스로 MQTT, AMQP, OpenWire, STOMP 프로토콜을 지원한다. 다양한 언어를 지원하며 크러스터링이 가능하다. 단 모니터링 도구는 없다. REST API를 통해 웹기반 메시징 API를 지원하며 Ajax를 통해 순수한 DHTML을 사용한 웹스트리밍을 지원 Rabbit MQ 고성능을 목표로 AMQP 프로토콜을 사용하여 개발된 MQ 로 Erlang OTP 기반으로 개발되었다. 실시간 모니터링이 용이하고 다양한 언어 및 OS 지원, RabbitMQ 서버간 클러스터링이 가능하다. Kafka Linkedin에서 구직정보들을 처리할 수 있는 플랫폼으로 개발이 시작되었다. 실시간 로그 처리에 특화되어 설계된 시스템으로 개발되어 타 MQ 대비 TPS가 매우 우수하나 특화된 솔루션이기 때문에 타 MQ솔루션에서 제공하는 다양한 기능들은 제공되지 않는다. AMQP, JMS 이 아닌 단순 메시지 헤더를 이용한 TCP 통신이다. MQ는 broker가 pruducer에게 메세지를 받아서 consumer 에게 push해주는 방식인데 반해, kafka는 consumer가 Broker로 부터 직접 메시지를 가지고 가는 pull 방식으로 동작한다. Consumer는 자신의 처리능력 만큼의 메시지만 broker로부터 가져오기 때문에 최적의 성능을 낼 수 있다. 많은 데이터 전송과 최대 처리량을 유지하기에 대량 데이터 스트리밍에 적합하다. 상태 변경이 시간순으로 기록되어야 하는 응용 프로그램인 이벤트 소싱(Event Sourcing) 저장소로 적합하다. ","date":"2023-04-18T17:19:16+09:00","image":"https://codemario318.github.io/post/message_queue/mq_cover_hu0d801aafbbe1fc1c7c4e885cbcd16691_10519_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/message_queue/","title":"Message Queue"},{"content":"What is Type Annotation in TypeScript 타입스크립트는 타입 어노테이션을 사용하여 변수, 함수, 객체 등과 같은 식별자의 유형을 명시적으로 지정한다.\n: type 구문을 식별자 뒤에 붙이는 타입 어노테이션으로 사용한다.\ntype은 모든 유효한 유형 가능 식별자에 타입 어노테이션을 추가하면 해당 타입으로만 사용할 수 있다. 식별자가 다른 유형으로 사용되면 타입스클입트 컴파일러에서 오류를 발생시킨다.\nType annotations in variables and constants 1 2 3 let variableName: type; let variableName: type = value; const constantName: type = value; 위 코드에서 타입 어노테이션은 변수, 상수 이름 뒤에 :을 붙이고 그 뒤에 타입이 온다.\n지정한 타입 외 다른 타입 값을 할당하면 컴파일 에러를 발생시킨다.\nType annotation examples 배열\n배열 타입 어노테이션은 : type[] 로 표시한다.\n1 2 let arrayName: type[]; let names: string[] = [\u0026#39;John\u0026#39;, \u0026#39;Jane\u0026#39;, \u0026#39;Peter\u0026#39;, \u0026#39;David\u0026#39;, \u0026#39;Mary\u0026#39;]; 객체\n1 2 3 4 5 6 7 8 9 let person: { name: string; age: number }; person = { name: \u0026#39;John\u0026#39;, age: 25 }; 함수 인자와 반환형\n1 2 3 4 5 let greeting : (name: string) =\u0026gt; string; greeting = function (name: string) { return `Hi ${name}`; }; 위와 같이 타입 어노테이션을 사용할 경우 string을 인자로 받고, string을 반환하는 모든 함수를 greeting에 할당할 수 있다.\nBase Type number\n타입스크립트에서 모든 숫자는 부동 소수점값과 큰 정수값에 포함된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 let price: number; let price = 9.95; let counter: number = 0; let x: number = 100, y: number = 200; let bin = 0b100; let anotherBin: number = 0B010; let octal: number = 0o10; let hexadecimal: number = 0XA; let big: bigint = 9007199254740991n; string\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 let firstName: string = \u0026#39;John\u0026#39;; let title: string = \u0026#34;Web Developer\u0026#34;; let description = `This TypeScript string can span multiple lines `; let firstName: string = `John`; let title: string = `Web Developer`; let profile: string = `I\u0026#39;m ${firstName}. I\u0026#39;m a ${title}`; console.log(profile); /** result I\u0026#39;m John. I\u0026#39;m a Web Developer. **/ boolean\n1 2 3 4 5 let pending: boolean; pending = true; // after a while // .. pending = false; Object Type 타입스크립트 object 타입은 원시 타입이 아닌 모든 값을 표현할 수 있다.\n타입스크립트 원시 타입 number bigint string boolean null undfined symbol object로 선언된 변수는 원시 타입을 제외한 모든 자료형을 할당할 수 있다.\n1 2 3 4 5 6 7 8 9 10 let employee: object; employee = { firstName: \u0026#39;John\u0026#39;, lastName: \u0026#39;Doe\u0026#39;, age: 25, jobTitle: \u0026#39;Web Developer\u0026#39; }; console.log(employee); 1 2 3 4 5 6 { firstName: \u0026#39;John\u0026#39;, lastName: \u0026#39;Doe\u0026#39;, age: 25, jobTitle: \u0026#39;Web Developer\u0026#39; } 만약 object로 선언된 변수를 다른 원시 타입으로 다시 할당하려고 하면 에러가 발생한다.\n1 2 employee = \u0026#34;Jane\u0026#34;; // error TS2322: Type \u0026#39;\u0026#34;Jane\u0026#34;\u0026#39; is not assignable to type \u0026#39;object\u0026#39;. object 타입은 선언될 때 지정한 프로퍼티 목록을 고정적으로 가지게 되어, 선언되지 않은 프로퍼티를 호출하게 되면 에러를 발생시킨다.\n1 2 console.log(employee.hireDate); // error TS2339: Property \u0026#39;hireDate\u0026#39; does not exist on type \u0026#39;object\u0026#39;. 💡 자바스크립트는 보유하지 않은 프로퍼티를 호출하면 undefined를 반환한다.\nobject 타입 내부에 지정되는 프로퍼티들의 타입을 지정할 수 도 있다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 let employee: { firstName: string; lastName: string; age: number; jobTitle: string; }; employee = { firstName: \u0026#39;John\u0026#39;, lastName: \u0026#39;Doe\u0026#39;, age: 25, jobTitle: \u0026#39;Web Developer\u0026#39; }; 1 2 3 4 5 6 7 8 9 10 11 let employee: { firstName: string; lastName: string; age: number; jobTitle: string; } = { firstName: \u0026#39;John\u0026#39;, lastName: \u0026#39;Doe\u0026#39;, age: 25, jobTitle: \u0026#39;Web Developer\u0026#39; }; object VS Object 타입스크립트는 첫 번째 대문자만 다른 Object 타입도 있다.\nobject 타입은 원시 타입이 아닌 모든 값들을 표현하고, Object 타입은 동작하는 모든 객체들을 의미한다.\n💡 자바스크립트에 포함된 모든 생성자들은 Object를 extend한다. 따라서 Object에는 모든 객체가 할당될 수 있다. 즉 동작하는 모든 객체를 의미한다.\nThe empty type 타입스크립트에서 비어있는 타입을 표현하는 다른 방법으로 {} 가 있는데, object 타입과 유사하게 동작한다.\n1 2 3 4 let vacant: {}; vacant.firstName = \u0026#39;John\u0026#39;; //error TS2339: Property \u0026#39;firstName\u0026#39; does not exist on type \u0026#39;{}\u0026#39;. 1 2 3 4 let vacant: {} = {}; console.log(vacant.toString()); // [object Object] 1 2 3 4 5 6 7 8 9 let vacant: {} = { firstName: \u0026#39;John\u0026#39; }; console.log(vacant); // { firstName: \u0026#39;John\u0026#39; } console.log(vacant.firstName); // error TS2339: Property \u0026#39;firstName\u0026#39; does not exist on type \u0026#39;{}\u0026#39;. Array 타입스크립트의 Array는 순서가 있는 데이터 리스트를 의미한다.\n1 let 이름: 타입[]; 1 2 3 4 5 6 let skills: string[]; skills[0] = \u0026#34;Problem Solving\u0026#34;; skills[1] = \u0026#34;Programming\u0026#34;; skills.push(\u0026#39;Software Design\u0026#39;); 1 let skills = [\u0026#39;Problem Sovling\u0026#39;,\u0026#39;Software Design\u0026#39;,\u0026#39;Programming\u0026#39;]; 1 2 let skills: string[]; skills = [\u0026#39;Problem Sovling\u0026#39;,\u0026#39;Software Design\u0026#39;,\u0026#39;Programming\u0026#39;]; 위처럼 선언된 skills에 다른 타입을 넣을 경우 에러가 발생한다\n1 2 skills.push(100); // Argument of type \u0026#39;number\u0026#39; is not assignable to parameter of type \u0026#39;string\u0026#39;. 배열 타입이 가진 속성과 메소드 1 2 let series = [1, 2, 3]; console.log(series.length); // 3 유용한 메서드로 forEach(), map(), reduce(), filter() 등이 있다.\n1 2 3 4 5 let series = [1, 2, 3]; let doubleIt = series.map(e =\u0026gt; e* 2); console.log(doubleIt); [ 2, 4, 6 ] 여러 타입 섞어 저장하기 1 let scores = [\u0026#39;Programming\u0026#39;, 5, \u0026#39;Software Design\u0026#39;, 4]; 1 2 let scores : (string | number)[]; scores = [\u0026#39;Programming\u0026#39;, 5, \u0026#39;Software Design\u0026#39;, 4]; Tuple Tuple은 array에 추가 제약사항이 붙은 형태이다.\n내부 요소 갯수 고정 내부 요소의 타입을 선언할 때 같을 필요는 없음 1 2 let skill: [string, number]; skill = [\u0026#39;Programming\u0026#39;, 5]; 1 2 3 let skill: [string, number]; skill = [5, \u0026#39;Programming\u0026#39;]; // error TS2322: Type \u0026#39;string\u0026#39; is not assignable to type \u0026#39;number\u0026#39;. 1 let color: [number, number, number] = [255, 0, 0]; Optional Tuple Elements 타입스크립트 3.0부터 선택적으로 사용할 수 있는 요소 선언이 추가되었다. 선택적으로 사용할 요소 앞에 ?를 앞에 붙인다.\n1 2 3 let bgColor, headerColor: [number, number, number, number?]; bgColor = [0, 255, 255, 0.5]; headerColor = [0, 255, 255]; Enum Enum은 상수 값들을 그룹으로 묶어 이름 붙인 타입이다.\n1 enum name {constant1, constant2, ...}; constant1, constant2, ...는 enum의 멤버가 된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 enum Month { Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec }; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 function isItSummer(month: Month) { let isSummer: boolean; switch (month) { case Month.Jun: case Month.Jul: case Month.Aug: isSummer = true; break; default: isSummer = false; break; } return isSummer; } isItSummer의 인자인 month는 Month enum에 해당하는 값을 받을 수 있다.\n1 2 3 console.log(isItSummer(Month.Dec)); //false console.log(isItSummer(11)); //false console.log(isItSummer(MonthSecond.Dec)); //error TS2345: Argument of type \u0026#39;MonthSecond.Dec\u0026#39; is not assignable to parameter of type \u0026#39;Month\u0026#39;. ","date":"2023-04-18T17:09:29+09:00","image":"https://codemario318.github.io/post/typescript_tutorial_2/ts_cover_hua836966f7fcda4b3d2856eb0c525b4e2_8490_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://codemario318.github.io/post/typescript_tutorial_2/","title":"TypeScript Tutorial - 2. Basic Types"},{"content":"Setup Tools Node.js: TS 컴파일러 실행을 위해 필요함 TypeScript 컴파일러: TS를 JS로 컴파일해준다. ts-node TS 코드를 실행하고 REPL(read-eval-print loop: 스크립트 실행 환경) 사용할 수 있다. TypeScript 컴파일러 설치 npm을 이용해 Typescript를 전역 환경에 설치 1 npm install -g typescript 설치 완료 후 tsc 가 정상적으로 설치되었는지 확인 1 tsc --v ts-node 를 전역 환경에 설치 1 npm install -g ts-node What is TypeScript 타입스크립트는 자바스크립트 상위집합(superset)이다. 타입스크립트가 자바스크립트의 특성을 침범하지 않고 지원한다. 타입스크립트는 자바스크립트를 기반으로 만들어졌다. 타입스크립트 코드를 작성 후, 타입스크립트 컴파일러를 사용하여 일반 자바스크립트 코드로 컴파일 한다.\n평범한 자바스크립트 코드가 만들어지기 때문에 자바스크립트가 실행 가능한 모든 환경에서 배포할 수 있다. 기본적으로 자바스크립트 문법을 사용하고, 타입 지원을 위한 추가 구문이 있다.\n결과적으로 syntax 에러가 없는 자바스크립트 코드는 타입 스크립트 코드 이다.\n모든 자바스크립트 프로그램이 타입스크립트 프로그램이라는 뜻 기존 자바스크립트 코드 베이스를 타입 스크립트로 마이그레이션하는 경우 유용하다.\nWhy TypeScript 타입스크립트는 버그를 피할 수 있게 도와주기 때문에 생산성을 향상시킨다. 타입은 많은 실수를 피하는 데 도움을 준다. 이를 통해 런타임에 버그가 발생하지 않고 컴파일 시간에 버그를 처리할 수 있다.\n1 2 3 4 5 6 function add(x, y) { return x + y; } let result = add(input1.value, input2.value); console.log(result); // result of concatenating strings add 함수는 x+y를 반환한다. 하지만 input이 html \u0026lt;input\u0026gt;이라면 .value는 값이 숫자인 것과 상관없이 문자열로 결과를 반환하는데 자바스크립트는 문자열 + 연산을 concat으로 처리하므로 add 함수는 의도한 동작을 수행하지 않고 이어진 문자열을 반환하게 된다.\n1 2 3 4 5 function add(x: number, y: number) { return x + y; } let result = add(input1.value, input2.value); 타입스크립트는 인자에 들어올 타입을 정할 수 있어서 input.value가 number타입이 아닐 경우 컴파일 에러를 발생시킨다.\n따라서 실수로 다른 값을 넣었을 때 발생하는 오동작을 예방할 수 있다.\n타입스크립트는 미래의 자바스크립트를 현재로 가져온다.\n타입스크립트는 현재 자바스크립트 엔진에 대해 ES Next에서 계획된 기능을 미리 지원한다. 따라서 웹 브라우저나 다른 환경에서 새로운 기능을 완전히 지원하기 전에 새로운 자바스크립트 기능을 사용할 수 있다. 매년 TC39에서 자바스크립트 표준인 ECMAScript에 대한 새로운 기능을 출시하는데 일반적으로 5단계를 거쳐 완전히 적용된다.\nStage 0: Strawperson(?: Strowman, 허수아비?) Stage 1: Proposal(제안) Stage 2: Draft(초안, 신인 선발) Stage 3: Candidate(후보) Stage 4: Finished() 타입스크립트는 일반적으로 Stage 3부터 지원한다.\n\u0026ldquo;Hello, World!\u0026rdquo; in node.js 1 2 let message: string = \u0026#39;Hello, World!\u0026#34;; console.log(message); tsc 을 이용해 .ts 파일을 컴파일하여 js 파일을 만들 수 있다.\n1 tsc app.ts 1 node app.js ts-node 이용 시 컴파일 하지 않아도 실행 가능\n1 ts-node app.ts in Web Browsers 1 2 3 4 5 6 7 8 9 10 11 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;TypeScript: Hello, World!\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;script src=\u0026#34;app.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 1 2 3 4 5 6 const message: string = \u0026#39;Hello, World!\u0026#39;; const heading = document.createElement(\u0026#39;h1\u0026#39;); heading.textContent = message; document.body.appendChild(heading); 1 tsc app.ts ","date":"2023-04-18T16:43:29+09:00","image":"https://codemario318.github.io/post/typescript_tutorial_1_1_1/ts_cover_hua836966f7fcda4b3d2856eb0c525b4e2_8490_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://codemario318.github.io/post/typescript_tutorial_1_1_1/","title":"TypeScript Tutorial - 1. Gettig Started(1)"},{"content":"타입 스크립트를 사용해야하는 2가지 중요한 이유가 있다.\nJS의 동적 타이핑으로 발생하는 여러 문제들을 예방할 수 있다. 앞으로 반영될 JS 문법을 당장 사용할 수 있다. (ES Next) JS 동적 타이핑으로 발생하는 문제를 예방하는 코딩은 매우 귀찮기때문에 방치되는 경우가 많다.\nJS 최신 문법은 간편한 기능을 제공하는 경우가 많고, 여러 오류들이 수정되어있다.\nJS 동적 타이핑이란 1 2 3 let box; box = \u0026#34;hello\u0026#34;; box = 100; 1 2 3 4 5 6 7 8 let box; console.log(typeof(box)); // undefined box = \u0026#34;Hello\u0026#34;; console.log(typeof(box)); // string box = 100; console.log(typeof(box)); // number 동적 타이핑은 할당 코드 수행 시점에 해석하여 자료형을 결정한다.\n이로 인해 코드가 간결해지고, 로직을 명확하게 보여줄 수 있지만. 할당 될 때 마다 자료형을 결정하는 과정으로 인해 정적 타이핑보다 상대적으로 느리고, 변수를 여러 유형 값을 사용할 여지를 만들어 코드에 혼란을 준다.\n동적 타이핑의 문제 1 2 3 4 5 6 7 function getProduct(id){ return { id: id, name: `Awesome Gadget ${id}`, price: 99.5 } } 1 2 3 4 5 const product = getProduct(1); console.log(`The product ${product.Name} costs $${product.price}`); // result // The product undefined costs $99.5 오타로 인해 undefined가 출력되었다. 1 2 3 const showProduct = (name, price) =\u0026gt; { console.log(`The product ${name} costs ${price}$.`); }; 1 2 3 4 5 const product = getProduct(1); showProduct(product.price, product.name); // result // The product 99.5 costs $Awesome Gadget 1 인자 순서 실수로 인해 다른 의도로 출력되었다. 타입스크립트는 어떤 방식으로 동적 타이핑 문제를 해결했을까? interface 1 2 3 4 5 interface Product{ id: number, name: string, price: number }; interface를 통해 Product객체의 형태를 정의했다.\n1 2 3 4 5 6 7 function getProduct(id) : Product{ return { id: id, name: `Awesome Gadget ${id}`, price: 99.5 } } getProduct함수를 Product타입을 반환하도록 선언할 수 있다.\n1 2 const product = getProduct(1); console.log(`The product ${product.Name} costs $${product.price}`); 함수에 반환 인터페이스를 설정하여 입력이 미리 정의한 타입이 아닐 경우 코드 에디터에서 잘못된 코드임을 표시한다.\n실수를 빠르게 알아차릴 수 있다. 1 2 3 const showProduct = (name: string, price:number) =\u0026gt; { console.log(`The product ${name} costs ${price}$.`); }; 인자로 받을 타입도 지정할 수 있다. 1 2 const product = getProduct(1); showProduct(product.price, product.name); 결론 자바스크립트는 동적 타이핑을 지원하여 유연하지만 그로 인해 많은 문제들이 발생한다. 타입스크립트는 타입을 통해 동적 타이핑에서 발생하는 문제들을 예방한다. ","date":"2023-04-18T16:43:29+09:00","image":"https://codemario318.github.io/post/typescript_tutorial_1_1_2/ts_cover_hua836966f7fcda4b3d2856eb0c525b4e2_8490_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"https://codemario318.github.io/post/typescript_tutorial_1_1_2/","title":"TypeScript Tutorial - 1.2 Why use TypeScript"},{"content":"\nStop-the-world GC를 실행하기 위해 JVM이 애플리케이션 실행을 멈추는 것이다.\nstop-the-world가 발생하면 GC를 실행하는 쓰레드를 제외한 나머지 쓰레드는 모두 작업을 멈춘다. GC작업을 완료한 이후에야 중단했던 작업을 다시 시작한다. 어떤 GC 알고리즘을 사용하더라도 Stop-the-world는 발생한다. 대개의 경우 GC 튜닝이란 이 Stop-the-world 시간을 줄이는 것이다. GC 필요성 Java의 경우 (대부분의 언어) 프로그램 코드에서 메모리를 명시적으로 지정하여 헤제하지 않는다. 따라서 가비지 컬렉터가 더이상 필요 없는 객체를 찾아 지우는 작업을 수행하여 메모리 공간을 확보한다.\n가끔 명시적으로 해제하려고 해당 객체를 null로 지정하거나 System.gc() 메서드를 호출하는 경우가 있다. null로 지정하는 것은 큰 문제가 안되지만, System.gc() 메서드를 호출하는 것은 시스템의 매우 큰 영향을 끼치므로 System.gc() 메서드는 절대 사용하면 안된다.\nGarbage Collector 가비지 컬렉터는 두 가지 가설 하에 만들어졌다.(가정 또는 전제 조건이라 표현하는 것이 맞다.)\nWeak generational hypothesis 대부분의 객체는 금방 접근 불가능 상태(Unreachable)가 된다. 오래된 객체에서 젊은 객체로의 참조는 아주 적게 존재한다. Young 영역과 Old 영역 이 가설의 장점을 최대한 살리기 위해 HotSpot VM 에서는 크게 2개로 물리적 공간을 나누었다.\nYoung 영역\n새롭게 생성한 객체의 대부분이 여기에 위치한다. 대부분의 객체가 금방 접근 불가능 상태가 되기 때문에 매우 많은 객체가 young 영역에 생성되었다가 사라진다. 이 영역에서 객체가 사라질 때 Minor GC가 발생한다고 말한다.\nOld 영역\n접근 불가능 상태로 되지 않아 Young 영역에서 살아남은 객체가 여기로 복사된다. 대부분 Young 영역보다 크게 할당하며, 크기가 큰 만큼 Young 영역보다 GC는 적게 발생한다. 이 영역에서 객체가 사라질 때 Major GC(Full GC)가 발생한다고 말한다.\nMinor GC 새로 생성된 대부분의 객체는 Eden 영역에 위치한다. Eden 영역에서 GC가 한 번 발생한 후 살아남은 객체는 Survivor 영역 중 하나로 이동된다.\n이 과정을 반복하다가 계속해서 살아남아 있는 객체는 일정시간 참조되고 있다는 뜻이므로 Old 영역으로 이동시킨다.\nMajor GC Old 영역에 있는 모든 객체들을 검사하여 참조되지 않은 객체들을 한꺼번에 삭제한다.\n가비지 컬렉션은 어떤 원리로 소멸시킬 대상을 선정하는가? 알고리즘에 따라 동작 방식이 매우 다양하지만 공통적인 원리가 있다.\n가비지 컬렉터는 힙 내의 객체 중에서 가비지를 찾아내고 찾아낸 가비지를 처리해서 힙의 메모리를 회수한다.\n참조되고 있지 않은 객체를 가비지라고 하며 객체가 가비지인지 아닌지 판단하기 위해서 reachablitiy라는 개념을 사용한다.\n어떤 힙 영역에 할당된 객체가 유효한 참조가 있으면 reachability, 없다면 unreachability로 판단한다. 하나의 객체는 다른 객체를 참조하고, 다른 객체는 또 다른 객체를 참조할 수 있기 때문에 참조 사슬이 형성되는데, 이 참조 사슬 중 최초에 참조한 것을 Root Set이라고 칭한다.\n힙 영역에 있는 객체들은 총 4가지 경우에 대하여 참조를 가지게 된다.\n힘 내의 다른 객체에 의한 참조 Java스택, 즉 Java 메서드 실행 시에 사용하는 지역변수와 파라미터들에 의한 참조 네이티브 스택에 의해 생성된 객체에 대한 참조 메서드 영역의 정적 변수에 의한 참조 2, 3, 4는 Root set이다. 즉 참조 사슬 중 최초에 참조한 것이다.\n인스턴스가 가비지 컬렉션의 대상이 되었다고 해서 바로 소멸이 되는 것은 아니다. 빈번한 가비지 컬렉션의 실행은 시스템에 부담이 될 수 있기에 성능에 영향을 미치지 않도록 가비지 컬렉션 실행 타이밍은 별도의 알고리즘을 기반으로 계산이 되며, 이 계산 결과를 기반으로 가비지 컬렉션이 수행된다.\nSerial GC 적은 메모리와 CPU 코어 개수가 적을 때 적합한 방식으로 위에서 언급한 방식으로 동작\nParallel GC 기본적인 GC 알고리즘은 Serial GC와 동일하지만 Parallel GC는 GC를 처리하는 스레드가 여러 개라서 보다 빠른 GC를 수행할 수 있다.\n메모리가 충분하고 코어의 개수가 많을 때 유리하다.\nParallel Old GC (Parallel Compacting GC) 별도로 살아있는 객체를 식별한다는 부분에서 보다 복잡한 단계로 수행된다.\n","date":"2023-04-18T16:24:22+09:00","image":"https://codemario318.github.io/post/jvm_gc/jvm_cover_hu0ae05cc4d1c0ca93a8c2f5fc57548620_55838_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/jvm_gc/","title":"JVM - Garbage Collection"},{"content":"JVM 이란? JVM이란 Java Virtual Machine, 자바 가상 머신의 약자를 따서 줄여 부르는 용어이다. JVM의 역할은 자바 애플리케이션을 클래스 로더를 통해 읽어 들여 자바 API와 함께 실행하는 것이다.\nJVM은 Java와 OS 사이에서 중개자 역할을 수행하여 JAVA가 OS에 구애받지 않고 재사용을 가능하게 해준다. 메모리 관리, Garbage collction을 수행한다. 스택기반의 가상머신이다. ARM 아키텍쳐 같은 하드웨어는 레지스터 기반으로 동작하는데 비해 JVM은 스택 기반으로 동작한다.\n자바프로그램 실행과정 프로그램이 실행되면 JVM은 OS로 부터 프로그램이 필요로 하는 메모리를 할당받는다. JVM은 이 메모리를 용도에 따라 여러 영역으로 나누어 관리한다. 자바 컴파일러(javac)가 자바 소스코드(.java)를 읽어들여 자바 바이트 코드(.class)로 변환시킨다. Class Loader를 통해 class 파일들을 JVM으로 로딩한다. 로딩된 class 파일들은 Execution engine을 통해 해석된다. 해석된 바이트 코드는 Runtime Data Areas에 배치되어 실질적인 수행이 이루어지게 된다. 이러한 실행 과정속에서 JVM은 필요에 따라 Thread Synchronizeation과 GC같은 관리작업을 수행한다.\nJVM 구성 클래스 로더 Class Loader JVM 내로 클래스 파일을 로드하고, 링크를 통해 배치하는 작업을 수행하는 모듈이다. Runtime시에 동적으로 클래스를 로드한다. jar파일 내 저장된 크래스들을 JVM위에 탑재하고 사용하지 않는 클래스들은 메모리에서 삭제한다. (컴파일러 역할)\n자바는 동적코드, 컴파일 타임이 아니라 런타임에 참조한다. 즉, 클래스를 처음으로 참조할 때, 해당 클래스를 로드하고 링크한다. 그 역할을 클래스 로더가 수행한다.\n실행 엔진 Execution Engine 클래스를 실행시킨다. 클래스 로더가 JVM내의 런타임 데이터 영역에 바이트 코드를 배치하면 실행엔진에 의해 실행된다. 자바 바이트코드는 기계가 바로 수행할 수 있는 언어보다는 비교적 인간이 보기 편한 형태로 기술된 것이다.\n그래서 실행엔진은 이와 같은 바이트코드를 실제로 JVM내부에서 기계가 실행할 수 있는 형태로 변경한다. 이 때 두가지 방식을 사용하게 된다.\n인터프리터 Interpreter\n실행 엔진은 자바 바이트 코드를 명령어 단위로 읽어서 실행한다.\n인터프리터 언어의 단점을 그대로 갖고 있다. 한 줄 씩 수행하기 때문에 느리다. JIT Just-In-Time\n인터프리터 방식의 단점을 보완하기 위해 도입된 JIT 컴파일러이다. 인터프리터 방식으로 실행하다가 적절한 시점에 바이트 코드 전체를 컴파일하여 네이트브 코드로 변경하고, 이후에는 해당 코드를 더이상 인터프리팅 하지 않고 네이티브 코드로 직접 실행한다.\n네이티브 코드는 캐시에 보관하기 때문에 한 번 컴파일 된 코드는 빠르게 수행하게 된다. JIT 컴파일러가 컴파일 하는 과정은 바이트코드를 인터프리팅하는 것보다 훨씬 오래걸리므로 한 번만 실행되는 코드라면 컴파일하지 않고 인터프리팅 하는 것이 유리하다. JIT 컴파일러를 사용하는 JVM들은 내부적으로 해당 메서드가 얼마나 자주 수행되는지 체크하고, 일정 정도를 넘을 때에만 컴파일을 수행한다. Garbage Collector GC를 수행하는 모듈 (쓰레드)를 가진다.\nRuntime Data Area 프로그램을 수행하기 위해 OS에서 할당받은 메모리 공간\nPC Register Thread가 시작될 때 생성되며 생성될 때마다 생성되는 공간으로 스레드마다 하나씩 존재한다.\n쓰레드가 어떤 부분을 어떤 명령으로 실행해야할 지에 대한 기록을 하는 부분으로 현재 수행중인 JVM 명령의 주소를 갖는다.\nJVM 스택 영역 프로그램 실행과정에서 임시로 할당되었다가 메소드를 빠져나가면 바로 소멸되는 특성의 데이터를 저장하기 위한 영역이다.\n각종 형태의 변수나 임시 데이터, 스레드나 메소드의 정보를 저장한다. 메소드 호출 시마다 각각의 스택 프레임(그 메서드 만을 위한 공간)이 생성된다. 메서드 수행이 끝나면 프레임 별로 삭제를 한다. 메소드 안에서 사용되는 값들(local variable)을 저장한다. 호출된 메소드의 매개변수, 지역변수, 리턴 값 및 연산 시 일어나는 값들을 임시로 저장한다. Native method stack 자바 프로그램이 컴파일 되어 생성되는 바이트 코드가 아닌 실제 실행할 수 있는 기계어로 작성된 프로그램을 실행시키는 영역이다.\n자바가 아닌 다른 언어로 작성된 코드를 위한 공간이다. Java Native Interface를 통해 바이트 코드로 전환하여 저장하게 된다. 일반 프로그램처럼 커널이 스택을 잡아 독자적으로 프로그램을 실행시키는 영역이다. 이 부분을 통해 C code를 실행시켜 Kernel에 접근할 수 있다. Method Area (= Class area = Static area) 클래스 정보를 처음 메모리 공간에 올릴 때 초기화되는 대상을 저장하기 위한 메모리 공간.\n올라가게 되는 메소드의 바이트코드는 프로그램의 흐름을 구성하는 바이트 코드이다. 자바 프로그램은 메인 메소드의 호출에서 부터 계속된 메소드의 호출로 흐름을 이어가기 때문이다. 대부분 인스턴스의 생성도 메소드 내에서 명령하고 호출한다. 사실상 컴파일 된 파이트코드의 대부분이 메소드 바이트코드이기 때무넹 거의 모든 바이트코드가 올라간다고 봐도 상관없다. Runtime Constat Pool이라는 별도의 관리 영역도 함께 존재하여, 상수 자료형을 저장하여 참조하고 중복을 막는 역할을 수행한다. 올라가는 정보의 종류 Feild Information 멤버 변수의 이름 데이터 타입 접근 제어자에 대한 정보 Method Information 메소드의 이름, 리턴타입, 매개변수, 접근 제어자에 대한 정보 Type Information Class인지 interface인지의 여부 저장 Type의 속성 전체 이름 Super class의 전체 이름 (interface이거나 object인 경우 제외) Heap 객체를 저장하는 가상 메모리 공간\n생성된 객체와 배열을 저장한다. class area영역에 올라온 클래스들만 객체로 생성할 수 있다. Permanent Generation 생성된 객체들의 정보 주소값이 저장된 공간이다. class loader에 의해 load되는 class, method 등에 대한 meta 정보가 저장되는 영역이고, JVM에 의해 사용된다.\nReflection을 사용하여 동적으로 클래스가 로딩되는 경우에 사용된다. 내부적으로 Reflection 기능을 자주 사용하는 Spring Framework를 이용할 경우 이 영역에 대한 고려가 필요하다.\nNew/Young 영역 Eden 객체들이 최초로 생성되는 공간 Survivor 0 / 1 Eden에서 참조되는 객체들이 저장되는 공간 Old 영역 New area에서 일정 시간 참조되고 있는, 살아남은 객체들이 저장되는 공간\nEden 영역에 객체가 가득차게 되면 첫번째 GC(minor GC)가 발생한다. Eden 영역에 있는 값들을 Survivor 1 영역에 복사하고 이 영역을 제외한 나머지 영역의 객체를 삭제한다.\n인스턴스는 소멸 방법과 소멸 시점이 지역 변수와는 다리기에 힙이라는 별도의 영역에 할당된다. 자바 가상머신은 매우 합리적으로 인스턴스를 소멸시킨다. 더이상 인스턴스의 존재 이유가 없을 때 소멸시킨다.\n","date":"2023-04-18T16:07:19+09:00","image":"https://codemario318.github.io/post/jvm/jvm_cover_hu0ae05cc4d1c0ca93a8c2f5fc57548620_55838_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/jvm/","title":"JVM"},{"content":"제너레이터는 제너레이터 함수가 호출될 때 반환되는 이터러블 객체이다. 제네레이터 함수는 일반적인 함수와 비슷하게 생겼지만 yield 구문을 사용해 데이터를 원하는 시점에 반환하고 처리를 다시 시작할 수 있다. 일반적인 함수는 진입점이 하나라면 제네레이터는 진입점이 여러개라고 생각할 수 있다. 이러한 특성때문에 제네레이터를 사용하면 원하는 시점에 원하는 데이터를 받을 수 있게된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 def generator(): yield 1 yield \u0026#39;string\u0026#39; yield True gen = generator() print(gen) # \u0026lt;generator object generator at 0x10a47c678\u0026gt; next(gen) #1 next(gen) # \u0026#39;string\u0026#39; next(gen) # True next(gen) \u0026#39;\u0026#39;\u0026#39; Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; StopIteration \u0026#39;\u0026#39;\u0026#39; 동작 yield 문이 포함된 함수를 실행하면 제너레이터 객체가 반환되는데 이 때는 함수의 내용이 실행되지 않는다. next() 라는 빌트인 메서드를 통해 제네레이터를 실행시킬 수 있으며 next() 메서드 내부적으로 iterator 를 인자로 받아 이터레이터의 __next__() 메서드를 실행시킨다. 처음 __next__() 를 호출하면 함수의 내용을 실행하다 yield 문을 만났을 때 처리를 중단한다. 이 때 모든 local state는 유지되는데 변수의 상태, 명령어 포인터, 내부 스택, 예외 처리 상태를 포함한다. 그 후 제어권을 상위 컨텍스트로 양보(yield)하고 또 __next__() 가 호출되면 제네레이터는 중단된 시점부터 다시 시작한다. yield 문의 값은 어떤 메서드를 통해 제네레이터가 다시 동작했는지에 따라 다른데, __next__() 를 사용하면 None이고 send() 를 사용하면 메서드로 전달 된 값을 갖게되어 외부에서 데이터를 입력받을 수 있게 된다.\n장점 List, Set, Dict 표현식은 iterable 하기에 for 표현식 등에서 유용하게 쓰일 수 있다. 하지만 해당 객체들은 Collection 특성상 가진 데이터를 메모리에 담고 있어야 하기 때문에 큰 값을 다룰 때는 성능상 불리하다. 제너레이터는 yield 를 통해 필요한 값만 받아 쓰기 때문에 모든 값을 메모리에 들고 있을 필요가 없게 된다.\n1 2 3 4 5 6 7 import sys a = [i for i in range(100000)] sys.getsizeof(a) #824464 b = (i for i in range(100000)) sys.getsizeof(b) #88 리스트가 여러번 사용될 수 있는 반면 b 제네레이터는 한번 사용된 후 소진된다. 이는 모든 이터레이터가 마찬가지인데 List, Set 등은 이터러블하지만 이터레이터는 아니기에 소진되지 않는다.\n1 2 len(list(b)) # 100000 len(list(b)) # 0 while True 구분으로 제공받을 데이터가 무한하거나, 모든 값을 한번에 계산하기엔 시간이 많이 소요되어 그때 그때 필요한 만큼만 받아 계산하고 싶을 때 제네레이터를 활용할 수 있다.\n","date":"2023-04-18T14:31:00+09:00","image":"https://codemario318.github.io/post/python_cover/python_cover_hu071c6006b6148c050030e26fb108bd62_83564_120x120_fill_box_smart1_3.png","permalink":"https://codemario318.github.io/post/python_cover/","title":"Python - Generator"},{"content":"\n엘라스틱서치는 검색 엔진인 아파치 루씬 (Apache Lucene)으로 구현한 RESTful API 기반의 검색 엔진이다. 엘라스틱서치 아키텍쳐는 클러스터 기반으로 구성되어 있다.\n클러스터 기본 특징 수평 확장\n클러스터를 사실상 무한으로 확장할 수 있다.\n인덱스 샤딩\n엘라스틱서치는 인덱스를 조각내서 \u0026ldquo;샤드 (shard)\u0026ldquo;라는 조각난 데이터로 만든다. 때문에 나누어진 데이터를 편하게 각 호스트에 분리해서 보관할 수 있다.\n엘라스틱서치 특징 Schemaless와 문서지향 엘라스틱 서치는 JSON 구조를 사용하여 기존 RDBMS와 같은 엄격한 구조를 적용하지 않는다.\n스키마가 다이나믹하게 변할 수 있다\n전통적인 관계형 구조로 구성할 경우 프로젝트 막바지에 모든 스키마르 ㄹ변경하고, 데이터를 다시 구성하는 문제에 봉착할 수 있는데 JSON 구조는 이런 문제들을 사전에 막을 수 있다. 데이터 공간을 절약할 수 있다.\n컬럼을 동적으로 정의하여, 필요한 데이터만 넣게 되어 데이터 공간 및 CPU 사용량, 네트워크 트래픽도 줄일 수 이쓴 효과를 볼 수 있다. 검색능력(Searching) 기본적인 검색 기능 뿐만 아니라 특히 Full-text 검색 능력이라는 강력한 기능을 탑재하고 있다.\n관계형 데이터베이스의 문자열 컬럼에 대해 실행되는 단순한 SQL 질의와는 다르다.\n기본적으로 엘라스틱은 검색을 할 수 있는 Term(의미의 최소한위)로 단어의 형태소 분석을 수행하고, 이 단어들과 연관된 문서를 매핑하여 검색을 시켜주는 개념으로 문서를 통쨰로 like 검색하는 DB와는 구조적으로 다르다.\n분석(Analytics) 엘라스틱 서치를 탑재하여 만든 사이트에 접속하는 사람들의 OS가 무엇인지, 어느나라에서 접속했는지 등을 알고 싶을 때 분석 기능을 사용하면 편리하게 알 수 있다.\n풍부한 API와 REST 지원 기본적으로 20개의 프로그래밍 언어를 지원하며, 기본적으로 REST API를 제공하여 REST API를 사용하는 모든 언어에서 HTTP 형식으로 사용할 수 있다.\n쉬운 작동, 쉬운 확장 Single Node Instance로 작동하며, 수백개의 스케일 아웃을 쉽게 할 수 있다. 대부분의 빅데이터 플랫폼들이 그러하듯 Horizontal Scaling을 사용한다.\nNear real-time(근접 실시간) 검색엔진은 기본적으로 형태소를 분석하고 색인을 해야 하는 시간이 다른 DBMS보다 오래 걸린다. 엘라스틱 역시 데이터를 삽입한 순간 약 몇 초 정도는 이 단계를 거친 후 검색을 할 수 있다.\nLightning-fast (빠른 속도) 엘라스틱 서치의 DNA는 루씬이기 떄문에 단어 입력후 문서를 찾는 속도가 다른 NoSQL들에 비해 매우 빠르다.\nFault-tolerant(내고장성) 노드 실패시 replicate된 다른 노드에서 데이터를 가져오며, 네트워크 실패 시 다른 마스터 복제본으로 선택한다.\n엘라스틱서치 데이터 구조 엘라스틱서치는 위와 같이 문서를 엘라스틱 인덱스로 만든 뒤, 샤드로 분리하여 보관한다.\n샤드는 논리적/물리적으로 분할 된 인덱스인데, 각각의 엘라스틱서치 샤드는 루씬 인덱스이기도 하다.\n루씬은 새로운 문서를 엘라스틱서치 인덱스에 저장할 때 \u0026ldquo;세그먼트\u0026quot;를 생성하는데, 루씬의 인덱스 조각인 이 세그먼트를 조합해 저장한 데이터의 검색을 할 수 있다.\n색인 처리량이 매우 중요할 때는 세그먼트를 더 생성하기도 한다. 루씬은 순차적으로 세그먼트를 검색하므로 세그먼트 수가 많아지면 검색속도도 따라서 느려지게 된다.\n엘라스틱서치 데이터 설명 인덱스(색인) 데이터를 저장 및 색인 하는 곳으로, 관계형 DB의 데이터베이스 개념과 유사하다.\n실제로는 각 샤드를 가리키고 있는 논리적인 네임스페이스 Shard 샤드는 엘라스틱서치에서 사용하는 검색 엔진인 루씬의 인스턴스.\n인덱스를 한 개의 샤드로 구성할 수도 있지만, 인덱스 사이즈가 증가할 경우 여러개의 물리서버에 나누어 보관하기 위해 보통은 여러개의 샤드로 구성함. Segment 각 샤드는 다수의 세그먼트를 가지고 있고, 샤드에서 검색 시, 먼저 각 세그먼트를 검색하여 결과를 조합한 최종 결과를 해당 샤드의 결과로 리턴하게 된다.\nsearchable\n엘라스틱서치에 데이터(문서)를 저장하면, 엘라스틱서치는 이것을 메모리에 모아두고 새로운 세그먼트를 디스크에 기록하여 검색을 리프레시함. 이로 인해 새로운 검색 가능한 세그먼트가 만들어지게 된다.\ncommited\n그러나 세그먼트가 fsync되지 않았으므로 여전히 데이터 손실의 위험이 남아있다. 그래서 엘라스틱서치는 세그먼트를 fsync하는 \u0026ldquo;flush\u0026quot;를 주기적으로 진행하고, 불필요한 트랜젝션 로그를 비운다.\nmerge process\n세그먼트는 불변임, 데이터(document)가 업데이트되면 실제로는 그저 삭제되었다고 마크하고 새로운 데이터(document)를 가리킬 뿐이다. 이러한 오래된 삭제된 데이터를 지우는 것\n엘라스틱서치 클러스터 구조 위 다이어그램은 3개의 엘라스틱서치 인스턴스 환경에서, 4개의 샤드를 2개의 복제본으로 구성했을 때의 구조이다.\n엘라스틱서치는 클러스터 구조로 구성되어 있으며 샤드와 복제본의 수를 설정해두면 스스로 각 노드에 샤드를 분배하여 장애발생 시 데이터 손실을 최소화한다.\n프라이머리 샤드가 손실되었을 경우에는 레플리카를 프라이머리로 승격시켜 데이터 손실을 방지한다.\n","date":"2023-04-18T14:13:19+09:00","image":"https://codemario318.github.io/post/elasticsearch/elasticsearch_cover_hu19466caf2459bbcd9b4d95bc6d53e495_16781_120x120_fill_box_smart1_3.png","permalink":"https://codemario318.github.io/post/elasticsearch/","title":"Elasticsearch"},{"content":" 검색 엔진은 컴퓨터 시스템에 저장된 정보를 찾아주는 것을 도와주도록 설계된 정보 검색 시스템이다. 검색 엔진을 사용하여정보를 찾는데 필요한 시간을 최소화할 수 있다.\n웹 검색 엔진 웹 사이트를 검색하기 위한 프로그램이다.\nFTP 서버나 웹 사이트의 파일 검색 결과를 포함하며, 이미지나 토렌트 파일 또는 특정 부류의 웹 사이트에 특화된 웹 검색 엔진도 있다.\n서버에서는 \u0026lsquo;로봇\u0026rsquo;이라 불리는 특별한 프로그램을 이용하 웹 사이트들을 돌아다니며 웹 사이트들에 대한 정보를 미리 자동적으로 수집한다. 이휴 검색 엔진 사이트에서 특정 검색어를 입력하면 검색 엔진이 수집한 정보 중 그에 맞는 결과를 볼 수 있다.\n로봇이 참조와 어휘를 분헉하는 방식에 따라 검색 품질이 결정됨 원리 검색 엔진은 사용자가 검색 엔진을 사용하기 전에 미리 웹 상에서 정보를 수집하여 색인을 만들어 놓는다. 그리고 나서 사용자가 찾고자 하는 정보의 키워드를 입력하면, 미리 만들어 놓은 색인 중에서 입력된 키워드에 해당하는 정보들을 찾아서 보여준다.\n문서 수집 현재 대부분의 검색 엔진에서는 엡상의 방대한 정보들을 검색하고 색인화 하는 과정을 크롤러라고 부르는 정보 수집 프로그램을 사용하여 수행하고 있다.\n크롤러가 주기적으로 웹에 접속된 사이트들을 방문하여 해당 웹 사이트가 가지고 있는 정보에 대해 색인을 작성한 후 그것을 데이터베이스에 저장하여 검색시 활용하게된다.\n크롤러\n웹상의 문서나 이미지, 영상 등을 주기적으로 검색하고 취합하여, 자동으로 데이터베이스화 시키는 프로그램으로 봇(Bot)이라고도 부른다.\n검색 엔진의 종류 수집한 정보를 색인하는 방법에 따라 구분된다.\n로봇 검색 엔진 크롤라라고 불리는 로봇을 이용하여 웹상의 데이터를 효율적으로 수집하고, 이렇게 수집한 데이터 키워드 색인을 통해 사용자에게 제공하는 검색 엔진\nGoogle, Naver등 현재 사용되는 대부분의 검색 엔진이 이 방식을 채택하고 있다. 디렉토리 검색 엔진 주제 분류에 의한 검색을 제공하는 검색 엔진이며, 데이터의 분류를 사람이 직접 슈행해야 한다.\n현재 주류인 방식은 아니며, 1990년대 Yahoo등에서 사용되었음 메타 검색 엔진 자체적으로 정보를 보유하고 있지 않으면서 사용자가 입력한 키워드를 복수의 다른 검색 엔진으로 전송하여 결과를 얻고, 그 결과들을 종합하여 표시만 해주는 검색 엔진\n여러 검색 엔진의 결과를 동시에 보여주기 때문에 결과를 한눈에 살펴보기에는 편하지만, 메타 검색이라는 과정을 한 번 더 거쳐야 하므로 속도가 느를 수 있다.\n검색 엔진 최적화(Search Engine Optimization, SEO) 검색 결과의 상위에 자신의 웹 페이지가 노출되기 위해 검색 엔진이 자료를 수집하고 결과를 산출하는 방식에 맞춰 웹 페이지의 구성을 조정하는 것을 의미한다.\n각각의 검색 엔진에 맞처 웹 페이지 내의 키워드나 링크 등을 최적화 하는 작업을 SEO라고 한다.\n","date":"2023-04-18T14:04:15+09:00","image":"https://codemario318.github.io/post/search_engine/search_engine_cover_hu920de5c22e59a77d3210239e6515a52e_9451_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/search_engine/","title":"검색 엔진"},{"content":"용어정리 MOM (Message Oriented Middleware, 메시지 지향 미들웨어) 독립된 어플리케이션 간에 데이터를 주고받을 수 있도록 하는 시스템 디자인 함수 호출, 공유메모리 등이 방식이 아닌, 메시지 교환을 이용하는 중간 계층에 대한 인프라 아키텍쳐 개념 분산 컴퓨팅이 가능해지며, 서비스간의 결합성이 낮아짐 지동기로 메시지를 전달하는 것이 특징 Queue, Broadcast, Multicast 등의 방식으로 메시지 전달 Pub/Sub 구조 메시지를 발행하는 Publisher(Producer), 메시지를 소비하는 Subscribe(Consumer)로 구성 Message Broker 메시지처리 또는 메시지 수신자에게 메시지를 전달하는 시스템이며, 일반적으로 MOM 기반으로 구축됨 MQ (Message Queue, 메시지 큐) Message bBroker와 MOM을 구현한 소프트웨어 (RabbitMQ, ActiveMQ, Kafka 등) MOM은 메시지 전송 보장을 해야하므로 AMQP를 구현함 AMQP (Advanced Message Queueing Protocol) 메시지를 안정적으로 주고박기 위한 인터넷 프로토콜 RabbitMQ, Kafka 등은 AMQP를 구현한 MOM 시스템이다.\n메시징 시스템이란? 로그 데이터, 이벤트 메시지 등 API로 호출할 떄 보내는 데이터들을 처리하는 시스템\n예를 들어, 다음과 같이 자동 메일을 발송 시스템이 있다고 가정하면,\n회원가입을 했을 때, 이메일을 발송하는 MemberService 주문완료가 되었을 때, 이메일을 발송하는 OrderService 메일을 실제 발송하는 MailService 이렇게 서비스가 분리되었을 때 프로세스는 다음과 같이 처리될 수 있다.\nMemberService에서 회원가입, OrderService에서 주문완료 이벤트가 발생 Messaging Client로 메일 전송에 필요한 데이터( 받는/보내는 사람 이메일 주소, 메시지 제목/내용 등.. )를 API 호출 Messaging Client에서 MOM을 구현한 소프트웨어(ex. kafka)로 메시지를 생산 MailService에서 메시지가 존재하는지 구독하고 있다가 메시지가 존재하면 메시지를 소비 MailService에서 API 정보들을 통해 User에게 메일 발송 장점 서비스간의 결합성이 낮아지므로 각자의 비즈니스 로직에만 집중할 수 있다. 메시지 처리 방식은 Message Broker에 위임 각 서비스는 Client를 통해 메시지를 보내고 받기만 하면 됨 각 서비스는 비동기 방식으로 메시지를 보내기만 하면, Message Broker에서 순서 보장, 메시지 전송 보장 등을 처리 메시징 시스템이 잠깐 다운되어도 각 서비스에는 직접적인 영향을 미치지 않음 단점 Message Broker 구축, 예를 들면 kafka 클러스터 구축에 필요한 금전, 인적 자원에 대한 비용 비동기의 양면성 - 정말 메시지가 잘 전달되었는가? 함수호출, 공유 메모리 사용 방식보다 메시징 시스템을 사용했을 때 호출 구간이 늘어나므로 네트워크 비용 발생 MOM, 메세지 지향 미들웨어(Message-Oriented-Middleware) 미들웨어: 어플리케이션들을 연결해 이들이 서로 데이터를 교환할 수 있게 해주는 소프트웨어 메시지 지향(=메시징 시스템): 메시지 API를 통해 각 분산되어 있는 어플리케이션간의 다리 역할을 함으로써 데이터를 교환 할 수 있도록 하는 시스템 메시지 지향 미들웨어란? 메시지를 통해 여러 분산되어 있는 시스템 간의 Connector 역할로 결합성을 낮추고, 이들이 서로 실시간 비동기식 데이터를 교환할 수 있도록 하는 소프트웨어\nMessage Queue 기반 패턴 메시지 대기열 패턴은 일종의 지점 간(peer to peer) 메시징 시스템이다. Queue 대기열의 메시지는 Consumer가 소비하면 지워지는 형태\n소비하면 지워지는 형태라는 의미는 Producer 서버가 메시지를 Queue에 보내고 서버가 다운이 되도 Consumer가 소비하지 않았다면 Queue 대기열에 데이터가 존재한다는 걸 의미한다.\n발행(Publish)-구독(Subscribe) 메시지 패턴 메시지 큐와 마찬가지로 메시지를 생산하는 Producer와 메시지를 소비하는 Consumer로 구성되어 있다.\n차이점은 여러 소비자가 하나의 주제에서 각 메시지를 수신할 수 있다는 점. 또한 모든 Consumer가 메시지를 사용하는 경우에만 메시지가 대기열에서 지워진다.\nkafka와 같은 메시징 시스템에는 메시지가 대기열에 있어야 하는 기간을 지정한 보존 정책이 있다. 따라서 메시지는 모든 Consumer가 소비하더라도 지정된 기간 동안 대기열에 사용할 수 있다.\n언제 쓰이는가? 분산 시스템 여러 컴퓨터를 분산시켜 네트워크를 연결하여 데이터들을 나눠서 처리하면 서버의 과부하를 분산할 수 있으며, 성는개선과 장애요소를 최소화하기 위해 분산 시스템을 사용함 과거 분산 시스템의 단점과 웹 API 통신의 한계 과거 분산시스템의 단점 수많은 데이터를 처리하기 위하여 분산 시스템을 운영하였지만, 시스템이 거대해질수록 분산 시스템의 설계도의 복잡성 문제가 발생한다. 하나의 응용프로그램이 변경되면, 다른 응용프로그램에도 영향을 미쳐 분산 시스템 간의 결합도가 강한 단점을 가지고 있었다.\n웹 API 통신의 특성 MSA를 사용한 분산 시스템은 웹 API 서버로 요청 시 응답을 기다려야 한다. 여러 분산되어있는 서비스 간에는 실시간으로 비동기식으로 데이터를 처리해야 하기 떄문에 웹 API로도 비동기식 구현이 가능하지만 순서가 보장되지 않는다는 특성이 있다. 메시지를 보내는 A어플리케이션은 메시지를 보낼 때 B라는 어플리케이션의 목적지(도착점)을 알아야 통신할 수 있다. 두 어플리케이션간 불필요한 결합도가 발생되고, 응답을 취하는 B어플리케이션이 서버 장애시 요청되었던 데이터 때문에 A어플리케이션에게도 장애가 전파될 수 있다. 메시징 지향 미들웨어의 필요성 메시지 API는 비동기 프로토콜을 지원하며, 메시지 순서를 보장합니다. 메시지가 대기열에 전달되면, 응답을 즉시 할 필요가 없다. 메시지 대기열에 전달 된 상황이라면 메시지는 시스템에 보존되어 있어, 다른 어플리케이션간의 의존성이 낮게 된다. Message Broker 송신자와 수신자 사이에서 메시지의 전달을 중재하는 컴퓨터 프로그램 모듈\n메시지 브로커는 정형화된 메시지의 교환을 통해 어플리케이션간의 소통이 이뤚디는 네트워크 엘리먼드이다.\n목적 메시지의 유효성, 정송, 라우팅을 위한 아키텍처 패턴\n어플리케이션 사이의 커뮤니케이션 중재 어플리케이션간의 메시지 전달을 위한 상호 인식(mutal awareness)를 줄여 어플리케이션간의 결합성을 낮춘다(decoupling) 기능 엔드 포인트 분리 NFR(non-functional requirement) 충조 중재함수 (intermediary function)의 간편한 재사용 하나이상의 목적지로의 메시지 라우팅 메시지의 형태 변형 메시지를 수집하여 여러 메시지로 분해하고 대상으로 보내 응답을 하나의 메시지로 재구성하여 사용자에게 반환 메시지 양 증가 또는 저장을 위한 외부 저장소와 상호작용 데이터 검색을 위한 웹 서비스 호출 이벤트 또는 에러의 응담 발행-구독 패턴을 활용한 컨텐츠와 토픽 기반 메시지 라우팅 제공 설계 허브 앤 스포크(hub and spoke)\n중앙 서버가 통합 서비스를 제공하는 메커니즘으로 작동 메시지 버스(message bus)\n메시지 브로커가 버스에서 작동하는 통신 백본 또는 분산 서비스 ","date":"2023-04-17T19:42:33+09:00","image":"https://codemario318.github.io/post/messaging_system/messaging_cover_huc80ec853f6ab161a17ff43aa6052ff01_60754_120x120_fill_box_smart1_3.png","permalink":"https://codemario318.github.io/post/messaging_system/","title":"메시징 시스템이란?"},{"content":"Not Only SQL: SQL만을 사용하지 않는 데이터베이스 관리 시스템을 지칭하는 단어. \u0026lsquo;데이터를 저장하는 데에는 SQL 외에 다른 방법들도 있다.\u0026rsquo;\n정의 NoSQL에 내려진 구체적인 정의는 없으나 공통적인 성향을 가지고 있다.\n대부분 클러스터에서 실행할 목적으로 만들어졌기 때문에 관계형 모델을 사용하지 않는다. 오픈 소스이다. 스키마 없이 동작하며, 구조에 대한 정의를 변경할 필요 없이 데이터베이스 레코드에 자유롭게 필드를 추가할 수 있다. 21세기 초반에 개발 된 SQL을 사용하지 않는 Schema-less 데이터베이스\n클러스터\n저렴한 상용 제품 여러 대를 조합하여 더 빠르고 안정적인 시스템을 목표로 만들어진 방법\n등장배경 여러 대의 컴퓨터에 데이터를 분산 저장하는 것을 목표로 등장했다.\n기존에는 안정적인 데이터 관리가 가장 중요했기 때문에, 트랙잭션을 통한 관리가 가능한 RDBMS가 많이 이용되었지만 웹 2.0 환경과 빅데이터가 등장하면서 RDBMS는 데이터와 트래픽 양이 기하급수적으로 증가함에 따라 한 대에서 실행되도록 설계된 RDBMS를 사용하는 데 필요한 비용 증가 이슈가 생겨났다.\nNoSQL은 데이터의 일관성을 약간 포기한 대신 여러 대의 컴퓨터에 데이터를 분산하여 저장하는 것을 목표로 등장하였고, NoSQL의 등장으로 작고 값싼 장비 여러 대로 대량의 데이터와 컴퓨팅 부하를 처리하는 것이 가능하게 되었다.\n특징 일관성과 확장성 사이의 Trade-off\n일관성이 데이터베이스의 절대적인 요소가 아님을 주장하는 움직임이 생기기 시작했다. 다수가 동시에 읽고 쓰는 상황에서의 성능 향상을 위해서. 분산 환경에서 노드들이 잘 작동하고 있음에도, 시스템의 일부가 고장나면 데이터베이스를 사용할 수 없게 되는 문제를 해결하기 위해서. 분산 저장\n데이터와 트래픽이 증가함에 따라 기존의 장비로는 원할한 데이터의 처리가 어려워졌다. 이를 해결하기 위한 방법으로 장비의 성능을 키우는 수직적 확장과 처리하는 장비 수를 늘리는 수평적 확장이 있다. 수직적 확장은 큰 비용적인 문제가 발생하므로 수평적 확장을 고려했지만, RDBMS가 클러스터 상에서 효율적으로 동작하도록 설계되지 않았다. 샤딩(Sharding)\n샤드키를 기준으로 하나의 테이블을 수평 분할하여 서로 다른 클러스터에 분산 저장하고 질의할 수 있는 기법. RDBMS에서도 사용 가능하지만 어플리케이션 레벨에서 모든 샤딩을 제어해야 한다.(어떤 데이터를 어느 클러스터에서 처리해야 하는지 등) 또한 여러 샤드에 걸치는 쿼리나 참조 정합성, 트랜잭션, 일관성 문제가 발생할 수 있다. 분산 저장을 지원하는 NoSQL 데이터베이스의 경후, 집합-지향(Aggregtae-oriented) 모델을 사용하여 이러한 문제를 해결한다. 연관된 데이터들이 함께 분산되므로, 관계형 모델에서처럼 복잡한 제어가 필요하지 않게 된다. 데이터 일치\nRDBMS에서 관계형 튜플 안의 값은 단순해야 하며 중첩된 레코드나 리스트 등 다른 구조를 포함할 수 없느 반면, 메모리 내 데이터 구조에서는 이런 제약이 없어 훨씬 복잡한 구조를 사용한다.(리스트, 딕셔너리, 중첩된 객체 구조) 그 결과 복잡한 메모리내 데이터 구조를 데이터베이스에 저장하려면 먼저 관계형 표현으로 변환해야 한다. (ORM 프레임워크등을 이용) NoSQL은 메모리 내의 데이터가 어떤 구조이든지 상관하지 않고 하나의 Aggregation으로 취급하여 저장하기 때문에 자유롭다. Impedance mismatch\n관계형 모델과 메모리 내 데이터 구조 간의 불일치\nSchema-less\nNoSQL 데이터베이스의 공통적인 특징은 스키마 없이 동작한다는 점이다. 장점 데이터 구조를 미리 정의할 필요가 없다. 시간이 지나더라도 언제든지 바꿀 수 있기 때문에 비형식적인 데이터를 저장하는 데 용이하다. 단점 단일 값에 대한 데이터 타입에서 불일치가 발생할 수 있다. 데이터베이스가 스키마를 직접 관리하지 않는 것을 의미할 뿐, 데이터 타입에 따른 암묵적인 스키마는 여전히 존재하기 때문 종류 네 가지 모델로 나눌 수 있다.\nkey-value Document Column-family Graph 이 중 그래프 모델을 제외한 나머지 세 모델은 집합-지향(Aggregate-orented)모델이다.\n집합-지향 (Agregate-orented) 모델 집합 지향 데이터베이스는 집합 자료구조로 이루어져 있다.\n집합\n연산의 한 단위로 취급되는 연관된 객체들의 집합.\n관계형 모델처람 하나의 엔티티에 대한 ACID 트랜잭션을 지원하지는 않지만, 하나의 집합에 대한 연산에서는 트랜잭션을 지원한다.\n장점\n집합 지향 데이터베이스는 여러 대의 클러스터로 이루어진 시스템에서 사용하기 적합하다. 수평적 확장이 용이하다. 이는 관계형 데이터베이스와는 달리 연관된 데이터들이 함께 움직이기 떄문이다. 메모리 내의 자료구조와 집합 간 데이터가 잘 일치하므로, 관계형 데이터베이스처럼 객체-관계 매핑 프레임워크가 필요하지 않다. 데이터의 검색도 아주 쉬운편으로, key나 ID를 사용하면 쉽게 집합 레코드를 찾아낼 수 있다. 단점\n집합 지향 데이터베이스는 조인 연산이 불가능 MongoDB나 Cassandra등의 데이터베이스에서는 맵리듀스(MapReduce) 기능을 제공함으로써 조인과 유사한 연산을 가능하도록 설계했지만 사용법이 어렵고 Hadoop의 맵 리듀스에 비하면 속도도 매우 느리다. Key-Value 키 값 저장소는 가장 단순한 형태의 NoSQL\n장점\n수평적 확장이 용이하다. 아주 간단한 API만을 제공하기 떄문에 배우는 것이 어렵지 않다. 간단한 API를 제공하는 만큼 질의의 속도가 굉장히 빠른편 어떠한 형태의 데이터라도 담을 수 있다. 이미지나 비디오도 가능 단점\n값의 내용을 사용한 쿼리가 불가능하다. 키를 사용해 값을 읽어들인 뒤, 어플리케이션 레벨에서 적절히 처리해야 한다. Document 데이터가 키와 문서 형태로 저장되는 키-값 모델의 개선 형태\n키-값 모델과의 차이점\nValue가 계층적인 형태인 도큐먼트로 저장된다. 객체지향의 객체와 유사하며, 하나의 단위로 취급되어 저장된다.\n장점\n하나의 객체를 여러 테이블에 나눠 저장할 필요가 없다. 도큐먼트 내의 item을 이용한 쿼리가 가능하다. 단, Xquery나 다른 도큐먼트 질의 언어가 필요 객체-관계 매핑이 필요하지 않다. 객체를 도큐먼트의 형태로 바로 저장 가능하기 떄문 검색에 최적화 되어있다. 단점\n사용이 번거롭고 쿼리가 SQL과 다르다. 질의의 결과가 JSON이나 XML 형태로 출력되기 때문에 사용방법이 RDBMS와 다르다. 질의 언어가 SQL과 다르기 떄문에 사용에 익숙해지기까지 다소 어려움이 있을 수 있음. 종류 MongoDB 도큐먼트 지향 데이터 베이스이다.\nbson 데이터 구조로 저장 문서를 기본 저장 단위로 이용하면서 내장 문서와 배열을 이용하여 복잡한 계층구조를 하나의 레코드로 표현한다. 스키마가 없다. 필드 추가 제거는 자유로우며 필요할 때 마다 자유자재로 변경 가능하다. RDBMS 보다 매우 빠르다. 조인과 트랜잭션을 지원하지 않으며 여러 제약조건에 대한 처리도 없다. →버전에 따라 다름 Redis(REmote DIctionary Server) 메모리 기반의 \u0026ldquo;Key-Value\u0026rdquo; 구조 데이터 관리 시스템이며, 모든 데이터를 메모리에 저장하고 조회하기에 빠른 Read, Write 속도를 보장하는 비 관계형 데이터베이스이다.\nString, set, Sorted Set, Hash, List 데이터 형식을 지원한다. Redis는 빠른 오픈 소스인 메모리 키-값 데이터 구조 스토어이며, 다양한 인메모리 데이터 구조 집합을 제공하므로 사용자 정의 어플리케이션을 손쉽게 생성 할 수 있다.\n특징 영속성을 지원하는 인메모리 데이터 저장소\n읽기 성능 증대를 위한 서버측 복제 지원\nRedis가 실행중인 서버가 충돌하는 경우 장애 조치 처리와 함께 더 높은 읽기 성능을 지원하기 위해 슬레이브가 마스터에 연결하고 전체 데이터베이스의 초기 복사본을 받는 마스터/ 슬레이브 복제를 지원. 마스터에서 쓰기가 수행되면 슬레이브 데이터 세트를 실시간으로 업데이트 하기 위해 연결된 모든 슬레이브로 전송됨 쓰기 성능 증대를 위한 클라이언트\n","date":"2023-04-17T19:24:48+09:00","image":"https://codemario318.github.io/post/nosql/nosql_cover_hu705a0f96b7606376fe264778ca77daa9_6424_120x120_fill_box_smart1_3.png","permalink":"https://codemario318.github.io/post/nosql/","title":"NoSQL이란?"},{"content":"Apache 아파치는 클라이언트 요청을 받으면 MPM(Multi Processing Module : 다중처리모듈) 방식으로 처리한다.\n스레드/프로세스 기반 구조 동작 ServerSocket으로 request A가 들어오면 Thread를 할당해준다. Thread는 해당 socket을 가지고 read, write작업 등을 수행한다. 수행 도중 ServerSocket으로 request B가 들어오면, context switching이 일어난다. 새로 들어온 요청에 쓰레드를 배분하고, 또 해당 소켓을 가지고 작업을 수행한다. 아직 마무리되지 않은 A를 처리하기 위해 일정 기간마다 지속적으로 context switching을 반복하고 모든 작업을 마무리 한다. Prefork MPM 실행중인 프로세스를 복제하여 처리하는 방식\n각 프로세스는 한번에 한 연결만 처리하고, 요청량이 많아질수록 프로세스를 복제하여 동작한다.\n프로세스를 복제하는 방식이기 떄문에 메모리가 많이 소비된다\n연결 수 = 프로세스 수\nWorker MPM Prefork 방식은 한개의 프로세스가 한개의 스레드로 처리되지만, Worker 방식은 한개의 프로세스가 여러 쓰레드를 사용하여 처리한다.\n쓰레드를 사용하기 떄문에 Prefork 방식보다 메모리 소모가 적고, 통신량이 많을 때 유리하다.\n문제점 아파치는 접속마다 프로세스 또는 쓰레드를 생성하는 구조이다.\n동시 접속 요청이 많을수록 그만큰 생성 비용이 들고 대용양 요청을 처리할 수 있는 웹 서버로서 한계가 나타난다.\nNginx 한개 또는 고정된 프로세스만 생성하고, 프로세스 내부에서 비동기 방식으로 작업을 처리한다. 따라서 동시 접속 요청이 많아도 프로세스 또는 쓰레드 생성 비용이 존재하지 않는다.\nEvent-Driven 방식 Event-Driven 방식은 Reactor pattern을 사용한다.\nReactor는 이벤트가 들어오면 알맞는 handler로 dispatch 해준다. Handler는 dispatch된 이벤트를 받아서 처리하는 역할을 수행 Reactor pattern\n이벤트 처리(event handling)디자인 패턴으로 하나의 Reactor가 계속 이벤트를 찾고 이벤트가 발생(trigger)하면 해당 이벤트 처리기(event handler)에게 알린다.\nNginx와 Apache의 차이점 컨텐츠의처리 방식 정적 컨텐츠 처리\nApache: 전통적인 파일기반 방식의 정적 컨텐츠 Nginx: 이벤트 처리/비동기식/논블로킹 방식 처리로 인해 정적 컨텐츠 제공시 고속 처리 가능 동적 컨텐츠 처리\nApache: 서버 내에서 처리 기본적으로 유연성과 범용성을 갖추는 방식으로 서버 자체에서 동적 컨텐츠 처리가 가능하다. Nginx: 동적 컨텐츠를 처리하지 않음 동적 웹 페이지 컨텐츠를 가진 모든 요청을 위해 외부 자원과 연계한다. 따라서 최종적으로 동적 컨텐츠가 다시 돌아올 때까지 기다렸다가 클라이언트에게 전달하는 방식을 가지고 있다. OS 지원에 대한 범용성 Apache: 리눅스, BSD, UNIX, WINDOW 역사가 있는 만큼 지원 범위가 다양하기 때문에 일관성 있는 웹 서비스 아키텍쳐를 구현할 수 있다. Nginx: LINUX, BSD, UNIX, WIN(부분 지원) 다양한 운영체제를 지원하지만 아파치 만큼 완벽히 지원하지 않는다. 분산/중앙집중식 구성 방식 Apache: 분산/중앙집중식 구성 채택 .htaccess를 통해 디렉토리별로 추가 구성을 할 수 있다. 단일 기반 뿐만 아니라 분산형 구칙이 가능하므로 대용량 서버 아키텍쳐에서 자원만 충분하다면 여러 웹 서비스를 구현 할 수 있다. Nginx: 중앙집중식 구성 채택 아파치처럼 .htaccess를 지원하지 않는다. 따라서 추가 구성을 할 수 없는 단점이 있다. 하지만 이러한 방식은 가상화, 클라우드, MSA와 같은 아키텍쳐에서는 오히려 경량화와 성능 보장이라는 측면에서 단점이 되지 않을 수도 있다. 모듈 및 확장성/보안 Apache 60개 이상의 다양한 기능과 모듈을 지원하며, 필요에 따라 활성화 또는 비활성 시킬 수 있다. 동적 모듈을 통해 웹 서버의 사용자 지정도 가능하게 할 수 있는 등 다양한 디자인과 확장이 가능하다. 보안을 위해 다양한 Web기반 DDoS 방어 기술을 제공한다. Nginx 다른 코어 모듈을 동적으로 로딩할 수 없도록 되어있다. 옵션을 최소화 해서 태생 부터 성능에 포커싱 했다. 보안에 대한 다양한 기술 문서를 제공하며, 코드 자체가 가볍고 경량화 되어 있어서 보안에 유리한 측면도 있다.https://youngmind.tistory.com/entry/Apache-vs-Nginx ","date":"2023-04-17T19:10:21+09:00","image":"https://codemario318.github.io/post/nginx_vs_apache/web_cover_hu71ff0ea2f7ce80fa0f2ad0c2fcb44a04_52909_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/nginx_vs_apache/","title":"Nginx VS Apache"},{"content":"웹 동작 방식 클라이언트(브라우저)가 HTTP(URL)을 통해 요청을 보내면 HTML, CSS, 이미지와 같은 정적 콘텐츠를 응답으로 보내게 되고 그것을 받은 클라이언트가 해석하여 페이지로 보여준다.\nStatic pages와 Dynamic Pages Static Pages Web Server는 파일 경로의 이름을 받아 경로와 일치하는 file contents를 반환 항상 동일한 페이지를 반환 Ex) image, html, css, javascript 파일과 같이 컴퓨터에 저장되어 있는 파일들 Dynamic Pages 인자의 내용에 맞게 동적인 Contents를 반환 웹 서버에 의해서 실행되는 프로그램을 통해서 만들어진 결과물(WAS)위에서 돌아가는 프로그램 Web Server와 WAS의 차이 Web Server 소프트웨어와 하드웨어로 구분된다.\n하드웨어 Web 서버가 설치되어 있는 컴퓨터 소프트웨어 웹 브라우저 클라이언트로 부터 HTTP 요청을 받아 정적인 컨텐츠(.html, .jpeg, .css 등)을 제공하는 컴퓨터 프로그램 Web Server의 역할 HTTP 프로토콜을 기반으로 하여 클라이언트의 요청을 서비스 하는 기능 담당\n요청에 따라 두 가지 기능 중 적절하게 선택하여 수행\n정적인 컨텐츠 제공 WAS를 거치지 않고 바로 자원을 제공한다 동적인 컨텐츠 제공을 위한 요청 전달 클라이언트의 요청을 WAS에 보내고, WAS가 처리한 결과를 클라이언트에게 전달한다. Web Server의 예 Apache Server Nginx IIS 등 WAS(Web Application Server) DB 조회나 다양한 로직 처리를 요구하는 동적인 컨텐츠를 제공하기위해 만들어진 Application Server\nHTTP를 통해 컴퓨터나 장치에 어플리케이션을 수행해주는 미들웨어이다.\n웹 컨테이너(Web Container), 서블릿 컨테이너(Servlet Container)라고도 불림\nWAS의 역할 WAS = Web Server + Web Container\n웹서버 기능들을 구조적으로 분리하여 처리하고자하는 목적으로 제시됨\n분산 트랜잭션 보안 메시징 쓰레드 처리 등 DB와 서버와 같이 수행됨\nWAS의 주요 기능 프로그램 실행 환경과 DB 접속 기능 제공 여러 개의 트랜잭션 관리 기능 업무를 처리하는 비지니스 로직 수행 WAS가 필요한 이유 웹 페이지는 정적 컨텐츠와 동적 컨텐츠가 모두 존재한다.\n사용자의 요청에 맞게 적절한 동적 컨텐츠를 만들어서 제공해야 한다. 웹 서버만을 이용하게 되면 그에 맞는 결과가 정적 파일로 존재해야 한다. 따라서 WAS를 통해 요청에 맞는 데이터를 DB에서 가져와 비즈니스 로직에 맞게 결과를 만들어 제공함으로 자원을 효율적으로 사용할 수 있다.\nWAS와 Web Server를 분리하는 이유 기능 분리를 통한 서버 부하 방지\nWAS만으로도 웹서비스를 제공 가능하지만 WAS는 DB조회 등 동적인 웹 페이지를 위한 다양한 동작을 하기 때문에 바쁘다. 따라서 웹 서버를 통해 정적인 컨텐츠를 제공하여 부하를 방지한다.\n물리적으로 분리하여 보안 강화\nSSL에 대한 암복호화 처리에 웹서버를 사용한다.\n여러대의 WAS를 연결 가능\nLoad Balancing을 위해 Web Server를 사용 가능하다\nfail over(장애 극복), fail back 처리에 유리 여러대의 서버를 사용하는 대용량 웹 어플리케이션의 경우 웹 서버와 WAS를 분리하여 무중단 운영을 위한 장애 극복에 쉽게 대응할 수 있다. 여러 웹 어플리케이션 서비스 가능\n하나의 웹 서버로 다양한 WAS를 이용하게 만들 수 있다. ","date":"2023-04-17T18:28:10+09:00","image":"https://codemario318.github.io/post/web/web_cover_hu71ff0ea2f7ce80fa0f2ad0c2fcb44a04_52909_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/web/","title":"Web"},{"content":"클로저는 두개의 함수로 만들어진 환경으로 이루어진 특별한 객체의 한 종류이다. 여기서 환경이라 함은 클로저가 생성될 때 그 범위에 있던 여러 지역 변수들이 포함 된 context를 말한다. 이러한 범위는 자바스크립트 코드를 실행하기 위해 발생하는 컴파일 단계에서 결정된다.\n클로저를 통해서 자바스크립트에는 없는 비공개 속성/메소드, 공개 속성/메소드 처럼 구현 할 수 있다.\nLexical Scope 자바스크립트 코드를 실행할 때 컴파일 단계에서 몇가지 일이 일어난다. 그중 하나인 토크나이징과 렉싱이 있다.\n토크나이징 문자열을 나누어 토큰으로 만드는 과정\n1 var num = 5; 위와 같은 구문을 만나게 되면, 아래와 같은 토큰으로 나눈다.\n1 2 3 4 5 var num = 5 ; 렉스타임 토크나이징의 결과물인 토큰을 분석하여 생성된 토큰에 의미를 부여하는 것을 렉싱이라고 하며, 이 과정을 렉스타임이라고 한다.\n렉시컬 스코프 개발자가 코드를 작성할때 변수를 어디에 작성하는가를 바탕으로 렉스타임에 토큰이 분석되며 스코프가 결정된다. 이때 구성된 유효 범위를 렉스컬 스코프라고 한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 var a = 10; function foo() { var b = 20; function bar() { var c = 30; colsole.log(a + b + c); // 60 } bar(); } foo(); 위의 코드가 실행될때 스코프 버블은 bar 안쪽에서 부터 시작되어 올라간다.\n코드를 해석하는 과정에서 상위에서 하위로 쌓이는 구조로 해석되기 때문에, scope에 대한 검색은 기본적으로 하위에서 상위는 되지만 상위에서 하위로의 검색은 불가능하다.\n1 2 3 4 5 6 7 8 9 var a = 10; function foo () { var b = 20; console.log(a); // 10 console.log(b); // 20 } console.log(b); // error 정리 컴파일레이션의 렉싱 단계에서 모든 변수들이 어디서 어떻게 선언되었는지 바탕으로 실행 단계에서 스코프를 구성하고, 이렇게 구성되는 스코프가 렉시컬스코프이다.\n클로저 생성하기 내부 함수가 익명 함수로 되어 외부 함수의 반환값으로 사용된다. 내부 함수는 외부 함수의 실행 환경에서 실행된다. 내부 함수에서 사용되는 변수는 외부 함수의 변수 스코프에 있다. 1 2 3 4 5 6 7 8 9 10 11 12 function outer() { var name = `closure`; function inner() { console.log(name); } inner(); } outer(); // console\u0026gt; closure outer함수를 실행시키는 context에는 name이라는 변수가 존재하지 않지만, inner함수가 outer 함수 내부에 선언된 name을 참조하기 때문에, name 변수에 대한 정보를 알 수 없는 outer 변수 외부환경에서도 정상 출력된다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 var name = `Warning`; function outer() { var name = `closure`; return function inner() { console.log(name); }; } var callFunc = outer(); callFunc(); // console\u0026gt; closure 위 코드에서 callFunc 를 클로저라고 한다. callFunc 호출에 의해 name 이라는 값이 console에 출력되는데, \u0026ldquo;Warning\u0026ldquo;이 아니라 \u0026ldquo;closure\u0026ldquo;이다. 즉, outer 함수의 context 에 속해있는 변수를 참조하는 것이다. 여기서 outer 함수의 지역변수로 존재하는 name 변수를 free variable(자유변수) 라고 한다.\n이처럼 외부 함수 호출이 종료 되더라도 외부 함수의 지역 변수 및 변수 스코프 객체의 체인 관계를 유지할 수 있는 구조를 클로저라고 한다.\n","date":"2023-04-17T18:11:36+09:00","image":"https://codemario318.github.io/post/js_closure/js_cover_huc1c9a52f33db3f5dad8bb16243cf7e4e_11875_120x120_fill_box_smart1_3.png","permalink":"https://codemario318.github.io/post/js_closure/","title":"Javascript - Closure"},{"content":"Javascript에서 함수의 this 키워드는 다른 언어와 조금 다르게 동작한다. 또한 엄격 모드와 비엄격 모드에서도 일부 차이가 있다.\n대부분의 경우 this의 값은 함수를 호출한 방법에 의해 결정되는데, 실행중에는 할당으로 설정할 수 없고 함수를 호출할 때 마다 다를 수 있다.\nES5는 함수를 어떻게 호출했는지 상관하지 않고 this 값을 설정할 수 있는 bind 메서드를 도입했고, ES2015는 스스로의 this 바인딩을 제공하지 않는 화살표 함수를 추가했다.(렉시컬 컨텍스트안의 this값을 유지함)\n전역 문맥 전역 실행 문맥(global execution context)에서 this는 엄격 모드 여부에 관계 없이 전역 객체를 참조한다.\n1 2 3 4 5 6 7 8 9 // 웹 브라우저에서는 window 객체가 전역 객체 console.log(this === window); // true a = 37; console.log(window.a); // 37 this.b = \u0026#34;MDN\u0026#34;; console.log(window.b) // \u0026#34;MDN\u0026#34; console.log(b) // \u0026#34;MDN\u0026#34; 함수 문맥 함수 내부에서 this의 값은 함수를 호출한 방법에 의해 결정된다.\n단순 호출 엄격 모드가 아닐경우 this의 값이 호출에 의해 설정되지 않으므로, 기본값으로 브라우저에서는 window인 전역 객체를 참조하게 된다.\n1 2 3 4 5 6 7 8 9 function f1() { return this; } // 브라우저 f1() === window; // true // Node.js f1() === global; // true 반면에 엄격 모드에서 this 값은 실행 문맥에 진입하며 설정되는 값을 유지하므로 다음 예시에서 보여지는 것 처럼 this는 undefined로 남아있게 된다.\n1 2 3 4 5 6 function f2(){ \u0026#34;use strict\u0026#34;; // 엄격 모드 참고 return this; } f2() === undefined; // true f2를 객체의 메서드나 속성(예: window.f2())이 아닌 직접 호출했기 때문에 this는 undefined여야 하지만 브라우저에서 엄격 모드를 지원하지 않는다면 window 객체를 반환한다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 var prop = 1; var test = { prop: 42, func: function() { var func2 = function() { console.log(this); } console.log(this); func2(); }, }; test.func(); /* \u0026gt; Object { prop: 42, func: function() { var func2 = function() { console.log(this); } console.log(this); func2(); } } \u0026gt; [object Window] // browser \u0026gt; [object global] // node.js */ function 키워드로 선언된 함수가 전역 실행 문맥(global execution context)에서 호출되었기 때문에 this는 엄격 모드 여부에 관계 없이 전역 객체를 참조한다.\nbind 메서드 ECMAScript5는 Function.prototype.bind를 도입했다. f.bind(someObject)를 호출하면 f와 같은 본문(코드)과 범위를 가졌지만 this는 원본 함수를 가진 새로운 함수를 생성한다. 새 함수의 this는 호출 방식과 상관없이 영구적으로bind()의 첫 번째 매개변수로 고정된다.\n1 2 3 4 5 6 7 8 9 10 11 12 function f() { return this.a; } var g = f.bind({a: \u0026#39;azerty\u0026#39;}); console.log(g()); // azerty var h = g.bind({a: \u0026#39;yoo\u0026#39;}); // bind는 한 번만 동작함! console.log(h()); // azerty var o = {a: 37, f: f, g: g, h: h}; console.log(o.a, o.f(), o.g(), o.h()); // 37, 37, azerty, azerty 화살표 함수 화살표 함수에서 this는 자신을 감싼 정적 범위(lexical context)이다. 전역 코드에서는 전역 객체를 가르킨다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 var globalObject = this; var foo = (() =\u0026gt; this); console.log(foo() === globalObject); // true // 객체로서 메서드 호출 var obj = {func: foo}; console.log(obj.func() === globalObject); // true // call을 사용한 this 설정 시도 console.log(foo.call(obj) === globalObject); // true // bind를 사용한 this 설정 시도 foo = foo.bind(obj); console.log(foo() === globalObject); // true 화살표 함수를 call(), bind(), apply()를 사용해 호출할 때 this의 값을 정해주더라도 무시한다. 사용할 매개변수를 정해주는 건 문제 없지만, 첫 번째 매개변수(thisArg)는 null을 지정해야 한다.\n어떤 방법을 사용하든 foo의 this는 생성 시점의 것으로 설정된다.(위 예시에서는 global 객체). 다른 함수 내에서 생성된 화살표 함수에도 동일하게 적용된다. this는 싸여진 렉시컬 컨텍스트로 유지된다.\n1 2 3 4 5 6 7 8 9 10 11 12 var obj = { bar: function() { var x = (() =\u0026gt; this); return x; } }; var fn = obj.bar(); console.log(fn() === obj); // true var fn2 = obj.bar; console.log(fn2()() === window); // true 화살표 함수의 범위는 선언될때 결정되는데, fn은 obj.bar()로 호출된 x를 활용하게 되어 this가 obj 를 의미하게 되고, fn2는 전역 실행 문맥에서 obj.bar 자체를 fn2에 할당 하였기 때문에 window로 설정되었다.\n객체의 메서드를 호출할 때 함수를 어떤 객체의 메서드로 호출하면 this의 값은 그 객체를 사용한다.\n다음 예제에서 o.f()를 실행할 때 o 객체가 함수 내부의 this와 연결된다.\n1 2 3 4 5 6 7 8 9 10 11 12 var o = {prop: 37}; function independent() { return this.prop; } o.f = independent; console.log(o.f()); // logs 37 o.b = {g: independent, prop: 42}; console.log(o.b.g()); // logs 42 this 바인딩은 멤버 대상에 영향을 받는다. 함수를 실행할 때, 객체 o.b의 메소드 g 로서 호출하면 함수 내부의 this는 o.b를 나타낸다.\n객체의 프로토타입 체인에서의 this 메서드가 어떤 객체의 프로토타입 체인 위에 존재한다면, this의 값은 그 객체가 메서드를 가진 것 처럼 설정된다.\n1 2 3 4 5 6 7 8 var o = { f:function() { return this.a + this.b; } }; var p = Object.create(o); p.a = 1; p.b = 4; console.log(p.f()); // 5 이 예제에서, f 속성을 가지고 있지 않은 변수 p가 할당된 객체는, 프로토타입으로 부터 상속받는다. 그러나 그것은 결국 o에서 f 이름을 가진 멤버를 찾는 되는 문제가 되지 않는다 ; p.f를 찾아 참조하기 시작하므로, 함수 내부의 this는 p 처럼 나타나는 객체 값을 취한다. 즉, f는 p의 메소드로서 호출된 이후로, this는 p를 나타낸다. 이것은 JavaScript의 프로토타입 상속의 흥미로운 기능이다.\n접근자와 설정자의 this 함수를 접근자와 설정자에서 호출하더라도 동일하다. 접근자나 설정자로 사용하는 함수의 this는 접근하거나 설정하는 속겅을 가진 객체로 묶인다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 function sum() { return this.a + this.b + this.c; } var o = { a: 1, b: 2, c: 3, get average() { return (this.a + this.b + this.c) / 3; } }; Object.defineProperty(o, \u0026#39;sum\u0026#39;, { get: sum, enumerable: true, configurable: true}); console.log(o.average, o.sum); // 2, 6 생성자로서 함수를 new 키워드와 함께 생성자로 사용하면 this는 새로 생긱 객체에 묶인다.\n","date":"2023-04-17T18:11:36+09:00","image":"https://codemario318.github.io/post/js_this/js_cover_huc1c9a52f33db3f5dad8bb16243cf7e4e_11875_120x120_fill_box_smart1_3.png","permalink":"https://codemario318.github.io/post/js_this/","title":"Javascript - this"},{"content":"hoist라는 단어의 사전적 정의는 \u0026ldquo;끌어올리기\u0026rdquo; 라는 뜻이다. 자바스크립트가 실행될때 선언된 모든 변수 선언부가 코드의 가장 위로 끌어올려진 것 처럼 처리된다.\n호이스트를 통해 변수의 정의가 그 범위에 따라 선언과 할당으로 분리된다. 즉, 변수가 함수 내에서 정의되었을 경우, 선언이 함수 최상위로, 함수 바깥에서 정의되었을 경우, 전역 컨텍스트의 최상위로 변경이 된다.\n1 2 3 4 5 6 7 8 9 function getX() { console.log(x); // undefined var x = 100; console.log(x); // 100 } getX(); 위와 같이 정의 되었을때, 아래와 같이 해석된다.\n1 2 3 4 5 6 7 8 9 10 11 function getX() { var x; console.log(x); x = 100; console.log(x); } getX(); 선언문은 항상 자바스크립트 엔진 구동시 가장 최우선으로 해석하므로 호이스팅 되고, 할당 구문은 런타임 과정에서 이루어지기 때문에 호이스팅 되지 않는다.\n함수의 호이스팅 함수가 자신이 위치한 코드에 상관없이 함수 선언문 형태로 정의한 함수의 유효범위는 전체 코드의 맨 처음부터 시작한다. 함수 선언이 함수 실행 부분보다 뒤에 있더라도 자바스크립트 엔진이 함수 선언을 끌어올리는 것을 의미한다.\n1 2 3 4 5 6 7 foo(); function foo(){ console.log(‘hello’); }; // console\u0026gt; hello foo 함수에 대한 선언을 호이스팅하여 global 객체에 등록시키기 때문에 hello가 제대로 출력된다.\n오류 사례 1 2 3 4 5 6 7 foo(); var foo = function() { console.log(‘hello’); }; // console\u0026gt; Uncaught TypeError: foo is not a function 예제의 함수 표현은 함수 리터럴을 할당하는 구조이기 때문에 호이스팅 되지 않으며 그렇기 때문에 아래와 같이 해석되어 런타임 환경에서 Type Error를 발생시킨다.\n1 2 3 4 5 6 7 8 var foo; foo(); // foo = undefined // console\u0026gt; Uncaught TypeError: foo is not a function foo = function( ) { console.log(‘hello’); }; ","date":"2023-04-17T18:04:35+09:00","image":"https://codemario318.github.io/post/js_hoisting/js_cover_huc1c9a52f33db3f5dad8bb16243cf7e4e_11875_120x120_fill_box_smart1_3.png","permalink":"https://codemario318.github.io/post/js_hoisting/","title":"Javascript - Hoisting"},{"content":"MySQL 서버는 서버의 상태를 진단할 수 있는 많은 도구들을 지원하지만 이러한 기능은 많은 지식을 필요로 하는 경우가 많다. 로그 파일을 활용하면 MySQL 서버에 대해 깊은 지식이 없어도 서버의 상태나 부하를 일으키는 원인을 쉽게 찾아 해결할 수 있다.\n에러 로그 파일 MySQL이 실행되는 도중 발생하는 에러나 경고 메시지가 출력되는 로그 파일이다. MySQL 설정 파일(my.cnf)에서 log_error라는 이름의 파라미터로 정의된 경로에 생성되는데 설정 파일에 별도로 정의도지 않은 경우 데이터 디렉터리(datadir 파라미터에 설정된 디렉터리)에 .err라는 확장자가 붙은 파일로 생성된다.\nMySQL이 시작하는 과정과 곤련된 정보성 및 에러 메시지 MySQL 설정 파일을 변경하거나 데이터베이스가 비정상적으로 종료된 후 다시 시작하는 경우에는 반드시 MySQL 에러 로그 파일을 통해 설정된 변수의 이름이나 값이 명확하게 설정되고 의도한 대로 적용됐는지 확인해야 한다.\nMySQL 서버가 정상적으로 기동했고(mysqld: ready for commections 메시지 확인), 새로 변경하거나 추가된 파라미터에 대한 에러나 경고성 메시지가 없다면 정상적으로 적용된 것으로 판단하면 된다.\n무시 ignore: 서버는 정상적으로 기동하지만 해당 파라미터가 적용안됨. 실패: 에러 메시지를 출력하고 시작하지 못했다는 메시지가 노출됨 마지막으로 종료할 때 비정상적으로 종료된 경우 나타나는 트랜잭션 복구 메시지 InnoDB의 경우 MySQL 서버가 비정상적으로 종료됐다면 다시 시작되면서 완료하지 못한 트랜잭션을 정리하고 디스크에 기록되지 못한 데이터가 있다면 다시 기록하는데, 이 과정에서 간단한 메시지가 출력된다.\n복구가 불가능한 경우 해당 에러메시지를 출력하고 MySQL은 다시 종료되며, 이 단계에서 발생하는 문제는 해결하기 어려운 문제점 일 때가 많고, innodb_force_recovery 파라미터를 설정하여 재시작 해야 할 수 있다.\n쿼리 처리 도중에 발생하는 문제에 대한 에러 메시지 쿼리 도중 발생하는 문제점은 사전 예방이 어려우며, 에러 로그 파일을 검토하는 과정에서 알게 된다.\n쿼리 실행 도중 발생한 에러나 복제에서 문제가 될 만한 쿼리에 대한 경고 메시지가 에러 로그에 기록되므로 자주 검토하는 것이 숨겨진 문제점을 해결하는데 많은 도움이 될 수 있다.\n비정상적으로 종료된 커넥션 메시지(Aborted connection) 클라이언트 애플리케이션에서 정상적으로 접속 종료를 하지 못하고 프로그램이 종료된 경우 MySQL 서버의 에러 로그 파일에 이런 내용이 기록된다. (네트워크 문제로 인한 겨우 포함)\n이런 메시지가 아주 많이 기록된다면 애플리케이션의 커넥션 종료 로직을 한번 검토해볼 필요가 있다.\nmax_connect_errors 시스템 변숫값이 너무 낮게 설정된 경우 클라이언트 프로그램이 MySQL 서버에 접속하지 못하고 Host 'host_name' is blocked라는 에러가 발생 가능하며, 이러한 경우는 에러가 어떻게 발생하게 됐는지 원인을 확인하고, 문제가 없다면 해당 시스템 변수의 값을 증가시키면 해결된다.\nInnoDB의 모니터링 또는 상태 조회 명령의 결과 메시지 InnoDB 테이블 모니터링이나 락 모니터링, 또는 엔진 상태를 조회하는 명령은 상대적으로 큰 메시지를 로그 파일에 기록한다.\nInnoDB의 모니터링을 활성화 상태로 유지하는 경우에는 에러 로그 파일이 매우 커져서 파일 시스템의 공간을 많이 사용할 수 있으므로, 다시 비활성화하여 에러 로그 파일이 커지지 않게 만들어야 한다.\nMySQL의 종료 메시지 가끔 MySQL이 아무도 모르게 종료돼 있거나 재시작 되는 경우가 있는데, 이러한 경우 에러 로그 파일에서 MySQL이 마지막으로 종료되면서 출력한 메시지를 확는 것이 서버가 종료된 이유를 확인하는 유일한 방법이다.\nReceived SHOUTDOWN from user ... 메시지: 특정 유저가 종료한 경우 없거나 스택 트레이스(16진수 주소값이 잔뜩 출력되는) 메시지: 세그멘테이션 폴트로 비정상 종료된 경우 세그멘테이션 폴트로 종료된 경우 스택 트레이스 내용을 최대한 참조하여 MySQL의 버그와 연관이 있는지 조사 후 버전을 업그레이드 하거나 회피책(WorkAround)를 찾는다. MySQL \u0026ldquo;The Error Log\u0026quot;절을 확인한다. 제너럴 쿼리 로그 파일 MySQL 서버에서 실행되는 쿼리 목륵을 검토하고 싶다면, 쿼리 로그를 활성화하여 실행 쿼리를 쿼리 로그 파일로 기록하게 한 다음, 해당 파일을 검토한다.\n슬로우 쿼리 로그와는 다르게 제너럴 로그는 실행되기 전에 MySQL이 요청을 받으면 바로 기록하기 때문에 쿼리 실행 중에 에러가 발생해도 일단 로그 파일에 기록된다.\n쿼리 로그 파일의 경로는 general_log_file 파라미터에 설정되있으며, 쿼리 로그를 파일이 아닌 테이블에 저장하도록 설정할 수 있으므로 이 경우에는 테이블을 SQL로 조회해 검토해야 한다.\n1 SHOW GLOBAL VARIABLES LIKE \u0026#39;general_log_file\u0026#39;; 슬로우 쿼리 로그 서비스 운영 중에 MySQL 서버의 전체적인 성능 저하를 검사하거나 정기적인 점검을 위한 튜닝이 필요할 때 어떤 쿼리가 문제인지를 판단하는데 많은 도움을 준다.\nlong_query_time: 해당 시스템 변수에 설정한 시간 이상의 시간이 소요된 쿼리가 모두 기록된다. log_output: 슬로우 커리 로그를 파일 또는 테이블에 기록할지 설정할 수 있다. TABLE: mysql DB의 테이블에 제너럴로그나 슬로우 쿼리 로그를 테이블(slow_log, general_log)에 저장한다. FILE: 로그 내용을 디스크의 파일로 저장한다. 로그 파일의 분석이 완료되면 그 결과는 3개의 그룹으로 나뉘어 저장된다.\n슬로우 쿼리 통계 분석 결과의 최상단에 표시되며, 모든 쿼리를 대상으로 슬로우 쿼리 로그의 실행 시간(Exec time), 잠금 대기 시간(Lock time) 등에 대해 평균 및 최소/최대 값을 표시한다.\n실행 빈도 및 누적 실행 시간순 랭킹 각 쿼리별로 응답 시간과 실행 횟수를 보여주는데, pt-query-digest 명령 실행 시 --oorder-by옵션으로 정렬 순서를 변경할 수 있다.\nQuery ID는 실행된 쿼리 문장을 정규화(쿼리에 사용된 리터럴을 제거)해서 만들어진 해시 값을 의미하는데, 같은 모양의 쿼리라면 동일한 Query ID를 가지게 된다.\n쿼리별 실행 횟수 및 누적 실행 시간 상세 정보 Query ID별 쿼리를 쿼리 랭킹에 표시된 순서대로 자세한 내용을 보여준다. 랭킹별 쿼리에서는 대상 테이블에 대해 어떤 쿼리인지만을 표시하는데, 실제 상세한 쿼리 내용은 개별 쿼리의 정보를 확인해보면 된다.\n","date":"2023-04-14T16:31:23+09:00","image":"https://codemario318.github.io/post/real_mysql_4_4/real_mysql_hu03b8ff0acb6f52b3ec9ae95e616f82c2_25714_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/real_mysql_4_4/","title":"4.4 MySQL 로그 파일"},{"content":"\n키 캐시 키 버퍼라고도 불리는 MyISAM의 키 캐시는 InnoDB의 버퍼풀과 비슷한 역할을 수행한다. 키 캐시는 인덱스만을 대상으로 작동하며, 인덱스의 디스크 쓰기 작업에 대해서만 부분적으로 버퍼링 역할을 한다.\n키 캐시 효율성 수식\n키 캐시 히트율 = 100 - (Key_reads / Key_read_requests * 100)\nKey_reads: 인덱스를 디스크에서 읽어들인 횟수를 저장하는 상태 변수 Key_read_requests: 키 캐시로부터 인덱스를 읽은 횟수를 저장하는 상태변수 1 SHOW GLOBAL STATUS LIKE \u0026#39;Key%\u0026#39;; 메뉴얼에서는 키 캐시를 이용한 쿼리의 비율(Hit rate)을 99% 로 유지할 것을 권장하며, 99% 미만이라면 키 캐시를 조금 더 크게 설정하는 것이 좋다.\n32비트 운영체제에서는 하나의 키 캐시에 4GB 이상 메모리 공간을 설정할 수 없고, 64비트 운영체제에서는 OS_PER_PROCESS_LIMIT 값에 설정된 크기만큼의 메모리를 할당할 수 있다.\n제한 값 이상의 키 캐시를 할당하고 싶다면 기본 키 캐시 이외에 별도 명명된 키 캐시 공간을 설정해야 하며, 기본 키 캐시 공간을 설정하는 파라미터는 key_buffer_size다.\n1 2 3 key_buffer_size = 4GB kbuf_board.key_buffer_size = 2GB kbuf_comment.key_buffer_size = 2GB 위 같이 설정하면 기본 키 캐시 4GB와 kbuf_board, kbuf_comment라는 이름의 키 캐시가 각각 2GB씩 생성된다.\n기본 키 캐시 영역외 키 캐시 영역은 아무런 설정이 없다면 할당만 해두고 사용하지 않아 추가된 키 캐시는 어떤 인덱스를 캐시할지 MySQL에 알려야 한다.\n1 2 CACHE INDEX db1.board, db2.board IN kbuf_board; CACHE INDEX db1.comment, db2.comment IN kbuf_comment; 운영체제의 캐시 및 버퍼 MyISAM 테이블의 인덱스는 키 캐시를 이용해 디스크를 검색하지 않고도 빠르게 검색될 수 있으나, 디스크 데이터 I/O를 성능을 위한 캐시나 버퍼링 기능은 없다. 따라서 MyISAM 테이블의 데이터 읽기나 쓰기 작업은 항상 운영체제의 디스크 읽기 또는 쓰기 작업으로 요청된다.\n운영체제의 캐시 공간은 남는 메모리를 사용하는 것이 기본 원칙이어서 남는 공간이 없다면 MyISAM 스토리지 엔진 데이터 I/O에 사용될 메모리를 확보할 수 없어 느려진다.\nMyISAM이 주로 사용되는 MySQL에서 일반적으로 키 캐시는 최대 물리 메모리의 40% 이상을 넘지 않게 설정하고, 나머지 메모리 공간은 운영체제가 자체적은 파일 시스템을 위한 캐시 공간을 마련할 수 있게 해주는 것이 좋다.\n데이터 파일과 프라이머리 키(인덱스) 구조 InnoDB 스토리지 엔진을 사용하는 테이블은 프라이머리 키에 의해서 클러스터링되어 저장되지만, MyISAM 테이블은 프라이머리 키에 의한 클러스터링 없이 데이터 파일이 Heap 공간처럼 활용된다. (프라이머리 키 값과 무관하게 INSERT되는 순서대로 데이터 파일에 저장된다.)\nMyISAM 테이블에 저장되는 레크드는 모두 ROWID라는 물리적인 주소값을 가지는데, 프라이머리 키와 세컨더리 인덱스는 모두 데이터 파일에 저장된 레코드의 ROWID 값을 포인터로 가진다.\nROWID는 두가지 방법으로 저장된다.\n고정 길이 ROWID\n자주 사용되지는 않지만 MyISAM 테이블을 생성할 때 MAX_ROWS 옵션을 사용해 명시하면 MySQL 서버는 쵀대로 가질 수 있는 레코드가 한정된 테이블을 생성한다. 레코드 개수가 한정되면 MyISAM 테이블은 ROWID값으로 4바이트 정수를 사용하여 INSERT된 순번으로 ROWID를 사용한다.\n가변 길이 ROWID\nMAX_ROWS 옵션을 사용하지 않으면 MyISAM 테이블의 ROWID는 최대 myisam_data_pointer_size 시스템 변수에 설정된 바이트 수 만큼에 공간을 사용할 수 있다. 기본값은 7이며 최소 2byte 부터 7byte 까지 가변적인 ROWID를 갖게 된다. 첫 바이트는 ROWID의 길이를 저장하는 용도로 사용되고 나머지 공간은 실제 ROWID를 저장하는데 사용한다. 가변적인 ROWID를 가지면 데이터 파일에서 레코드의 위치가 ROWID로 사용되어, 가변 길이 ROWID인 테이블일때 최대 크기 256TB(2**(8(7-1)))가질 수 있다.\n","date":"2023-04-14T15:52:19+09:00","image":"https://codemario318.github.io/post/real_mysql_4_3/real_mysql_hu03b8ff0acb6f52b3ec9ae95e616f82c2_25714_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/real_mysql_4_3/","title":"4.3 MyISAM 스토리지 엔진 아키텍처"},{"content":"Double Write Buffer InnoDB 스토리지 엔진의 리두 로그는 공간 낭비를 막기 위해 페이지의 변경된 내용만 기록한다. 이로인해 더티 페이지를 디스크 파일로 플러시할 때 일부만 기록되는 문제가 발생하면 그 페이지의 내용은 복구할 수 없을 가능성이 있다.\n이런 현상을 파셜 페이지 또는 톤 페이지라고 하는데, 하드웨어의 오작동이나 시스템의 비정상 종료 등으로 발생할 수 있다.\n파셜 페이지(Partial-Page)\n데이터 베이스 페이지 중에서 데이터가 일부만 채워진 페이지. 레코드가 페이지의 크기보다 작을 때 발생하며, 레코드가 페이지를 벗어나지 않은 상태에서 페이지의 일부만 사용하게 된다. 톤 페이지(Tone-Page)\n디스크에 기록 중인 페이지의 기록 작업이 중간에 중단되어 발생하는 문제. 페이지 일부가 디스크에 기록되지 않아 데이터 무결성이 손상되는 문제를 일으킬 수 있다. InnoDB 스토리지 엔진은 이러한 문제를 막기 위해 Double-Write 기법을 활용한다.\nInnoDB 스토리지 엔진은 실제 데이터 파일에 변경 내용을 기록하기 전에 기록될 더티 페이지들을 묶어 시스템 테이블 스페이스의 DoubleWrite 버퍼에 기록한다.\n더티 페이지 플러싱 중 오류등으로 서버가 종료되었다면 InnoDB 스토리지 엔진은 재시작 될 때 항상 Double Write 버퍼의 내용을 데이터 파일의 페이지로 복사하게 된다.\nDoubleWrite 기능을 사용할지 여부는 Innodb_doublewrite 시스템 변수로 제어할 수 있다.\n이처럼 DoubleWrite 버퍼는 데이터의 안정성을 위해 사용되는데, HDD처럼 자기 원판이 회전하는 저장 시스템에서는 한 번의 순차 디스크 쓰기를 하는 것으로 부담스럽지 않지만 SSD처럼 랜덤 IO와 순차 IO의 비용이 비슷한 저장 시스템에서는 부담스럽다.\nSSD는 HDD와 다르게 내부적으로 물리적인 섹터 단위로 데이터를 읽고 쓰지 않는다. 따라서 메모리에 복사된 내용이 SSD의 섹터 크기보다 작은 경우에도(순차 디스크 쓰기) 여러번 기록되어야 한다.\n하지만 데이터의 무결성이 매우 중요한 서비스에서는 DoubleWrite의 활성화를 고려하는 것도 좋다. 만약 데이터베이스 서버의 성능을 위해 InnoDB 리두 로그 동기화 설정(innodb_flush_log_at_trx_commit 시스템 변수)을 1이 아닌 값으로 설정했다면, DoubleWrite도 비활성화 하는 것이 좋다.\ninnodb_flush_log_at_trx_commit\n0: 커밋 후 로그 버퍼를 디스크에 즉시 플러시 하지 않고, 로그 버퍼가 일정 수준 채워지거나 데이터베이스 서버가 종료될 때 플러시한다. 데이터 일관성이 보장되지 않을 수 있다. 1(default): 컷밋 후 로그 버퍼를 디스크에 즉시 플러시한다. 데이터 일관성은 보장하지만 디스크 IO가 부하를 발생시킬 수 있다. 2: 커밋 후 로그 버퍼를 디스크에 즉시 플러시 하지 않고, 로그를 별도 파일에 쓴 후 파일을 주기적으로 플러시 한다. 0과 1의 중간 정도로 데이터 일관성과 디스크 IO 부하 감소를 균형있게 유지할 수 있다. 언두 로그 InnoDB 스토리지 엔진은 트랜잭션과 격리 수준을 보장하기 위해 DML로 변경되기 이전 버전의 데이터를 별도로 백업한다. 이렇게 백업된 데이터를 언두 로그(Undo Log)라고 한다.\n트랜잭션 보장\n트랜잭션이 롤백되면 트랜잭션 도중 변경된 데이터를 변경 전 데이터로 복구해야 하는데, 이때 언두 로그에 백업해둔 이전 버전의 데이터를 이용해 복구한다. 격리 수준 보장\n특정 커넥션에서 데이터를 변경하는 도중 다른 커넥션에서 데이터를 조회하면 트랜잭션 격리 수준에 맞게 변경중인 레코드를 읽지 않고 언두 로그에 백업해둔 데이터를 읽어서 반환하기도 한다. 언두 로그 모니터링 언두 로그로 인해 여러가지 성능 이슈가 발생할 수 있어 모니터링이 필요하다.\n대용량 처리 트랜잭션\n1억 건의 레코드가 저장된 100GB 크기의 테이블을 DELETE로 삭제한다고 가정했을때, 언두 로그에 삭제전 값을 저장해야 하므로 언두 로그 공간은 100GB가 된다.\n장시간 활성화된 트랜잭션\n트랜잭션이 완료됐다고 해서 해당 트랜잭션이 생성한 언두 로그를 즉시 삭제할수 없을 수 있다. 먼저 시작된 트랜잭션보다 이후 발생한 트랜잭션이 완료된 경우, 먼저 시작된 완료된 트랜적션이 완료되기 전 까지 언두 로그는 삭제되지 않는다. 이러한 경우 언두 로그의 이력을 필요한 만큼 스캔해야만 필요한 레코드를 찾을 수 있기 때문에 쿼리의 성능이 전반적으로 떨어질 수 있다.\n1 2 3 4 5 6 7 8 9 /* MySQL 모든 버전 */ SHOW ENGING INNODB STATUS \\G /* MySQL 8.0 */ SELECT count FROM information_schema.innodb_metrics WHERE SUBSYSTEM=\u0026#39;transaction\u0026#39; AND NAME=\u0026#39;trx_rseg_history_len\u0026#39; ; MySQL 서버에서 실행되는 INSERT, UPDATE, DELETE 문장이 얼마나 많은 데이터를 변경하느냐에 따라 평상시 언두 로그 건수는 상이할 수 있어, 안정적인 시점의 언두 로그 건수를 확인하고 이를 기중으로 언두 로그의 급증 여부를 모니터링하는 것이 좋다.\nMySQL 서버에서 INSERT 문장으로 인한 언두 로그와 UPDATE, DELETE 문장으로 인한 언두 로그는 별도로 관리된다. UPDATE, DELETE 문장으로 인한 언두 로그는 MVCC와 데이터 복구(롤백 등)에 모두 사용되지만, INSERT 문장으로 인한 언두 로그는 롤백, 데이터 복구만을 위해 사용된다.\n언두 테이블스페이스 관리 언두 로그가 저장되는 공간을 언두 테이블스페이스(Undo Tablespace)라고 한다.\nMySQL 5.6 이전 버전에서는 언두 로그가 모두 시스템 테이블스페이스(ibdata.idb)에 저장되었었지만, 시스템 테이블스페이스의 언두 로그는 MySQL서버가 초기화될 때 생성되기 때문에 확장의 한계가 있었다. 이에 따라 5.6 버전에서는 innodb_undo_tablespaces 시스템 변수가 도입되어 별도 로그 파일을 사용할 수 있게 되었고, 8.0으로 업그레이드되면서 언두 로그는 항상 시스템 테이블스페이스 외부의 별도 로그 파일에만 기록되도록 개선되었다.\n하나의 언두 테이블스페이스는 1~128개의 롤백 세그먼트를 가지며, 롤백 세크먼트는 1개 이상의 언두 슬롯(Undo Slot)을 가진다.\n최대 동시 처리 가능한 트랜잭션의 개수는 다음 수식으로 예측할 수 있다.\n(InnDB 페이지 크기) / 16 * (롤백 세그먼트 개수) * (언두 테이블 스페이스 수)\nInnoDB 기본 설정(innodb_undo_tablespace=2, innodb_rollback_segments=128)을 사용한다면 131,072개 정도의 트랜잭션이 동시에 처리 가능해진다. 일반적인 서비스에서 이 정도까지 동시 트랜잭션이 필요하진 않겠지만 기본값으로 해서 크게 문제될 건 없다.\n언두 로그 슬롯이 부족한 경우에는 트래잭션을 시작할 수 없는 심각한 문제가 발생하기 때문에 적절히 정해야 한다.\nMySQL 8.0 부터 CREATE UNDO TABLESPACE나 DROP TABLESPACE같은 명령으로 새로운 언두 테이블 스페이스를 동적으로 추가하고 삭제할 수 있게 개선되었다.\n언두 테이블스페이스 공간을 필요한 만큼만 남기고 불필요하거나 과도하게 할당된 공간을 운영체제로 반납하는 것을 \u0026lsquo;Undo tablespace truncate\u0026rsquo;라고 하며 자동, 수동 두가지 방법이 있다.\n체인지 버퍼 RDBMS에서 레코드가 추가, 변경될 때 데이터 파일을 변경하는 작업뿐 아니라 해당 테이블에 포함된 인덱스를 업데이트하는 작업도 필요하다. 인덱스를 업데이트하는 작업은 랜덤하게 디스크를 읽는 작업이 필요하므로 테이블에 인덱스가 많다면 상당히 많은 자원을 소모하게 된다. 따라서 InnoDB는 변경해야 할 인덱스 페이지가 버퍼풀에 있으면 바로 업데이트를 수행하지만, 그렇지 않고 디스크로부터 읽어와서 업데이트해야 한다면 이를 즉시 실행하지 않고 임시 공간에 저장해 두고 바로 사용자에게 결과를 반환하는 형태로 성능을 향상시키게 되는데, 이때 사용하는 임시 메모리 공간을 체인지 버퍼(Change Buffer)라고 한다.\n사용자에게 결과를 반환하기 전에 반드시 중복 여부를 체크해야 하는 유니크 인덱스는 체인지 버퍼를 사용할 수 없다.\n체인지 버퍼에 임시로 저장된 인덱스 레코드 조각은 이후 백그라운드 스레드에 의해 병합되는데, 이 스레드를 체인지 버퍼 머지 스레드라고 한다.\nMySQL 5.5 이전 버전까지는 INSERT 작업에 대해서만 이러한 버퍼링이 가능했는데, 이후 조금씩 개선되며 INSERT, UPDATE, DELETE로 인해 키를 추가하거나 삭제하는 작업에 대해서도 버퍼링이 될 수 있게 개선되었다.\n또한 innodb_change_buffering이라는 시스템 변수가 새로 도입되어 작업의 종류별로 체인지 버퍼를 활성화할 수 있으며, 체인지 버퍼가 비효일적일 때는 체인지 버퍼를 사용하지 않게 설정할 수 있게 개선되었다.\nall: 모든 인덱스 관련 작업을 버퍼링(inserts + deletes + purges) none: 버퍼링 안함 inserts: 인덱스에 새로운 아이템을 추가하는 작업만 버퍼링 deletes: 인덱스에서 기존 아이템을 삭제하는 작업(삭제됐다는 마킹 작업)만 버퍼링 changes: 인덱스에 추가하고 삭제하는 작업만(inserts + deletes) 버퍼링 purges: 인덱스 아이템을 영구적으로 삭제하는 작업만 버퍼링(백그라운드 작업) 체인지 버퍼는 기본적으로 InnoDB 버퍼풀로 설정된 메모리 공간의 25%까지 활용할 수 있게 설정돼있으며, 필요하다면 50%까지 설정할 수 있다. innodb_change_buffer_max_size 시스템 변수에 비율을 조정하여 바꿀 수 있다.\n리두 로그 및 로그 버퍼 리두 로그는 트랜잭션의 4가지 요소인 ACID 중에서 D(Durable)에 해당하는 영속성과 가장 밀점하게 연관돼 있다. 리두 로그는 하드웨어나 소프트웨어 등 문제로 인해 MySQL 서버가 비정상적으로 종료됐을 때 데이터 파일에 기록되지 못한 데이터를 잃지 않게 해주는 안전장치이다.\n대부분 데이터베이스 서버는 데이터 변경 내용을 로그로 먼저 기록한다. 대부분 DBMS에서 데이터 파일은 쓰기보다 읽기 성능을 고려한 자료 구조를 가지고 있기 때문에 데이터 파일 쓰기는 디스크의 랜덤 액세스가 필요하여 상대적으로 큰 비용이 필요하다.\n이로 인한 성능 저하를 막기 위해 쓰기 비용이 낮은 자료구조인 리두 로그를 가지고 있으며, 비정상 종료가 발생하면 리두 로그의 내용을 이용해 데이터 파일을 다시 서버가 종료되기 직전 상태로 복구한다.\n또한 성능을 위해 리두 로그를 버퍼링 할 수 있는 InnoDB 버퍼풀이나, 리두 로그를 버퍼링할 수 있는 로그 버퍼와 같은 자료 구조도 가지고 있다.\nMySQL 서버가 비정상으로 종료되는 경우 InnoDB 스토리지 엔진의 데이터 파일은 두 가지 일관되지 않은 데이터를 가질 수 있다.\n커밋됐지만 데이터 파일에 기록되지 않은 데이터 롤백됐지만 데이터 파일에 이미 기록된 데이터 리두로그를 활용하여 변경이 커밋, 롤백, 트랜잭션의 실행 중간 상태였는지 확인하고, 적절히 처리한다.\n데이터베이스 서버에서 리두 로그는 트랜잭션이 커밋되면 즉시 디스크로 기록되도록 시스템 변수를 설정하는 것을 권장한다. 그래야만 서버가 비정상적으로 종료되었을때 직전까지의 트랜잭션 커밋 내용이 리두 로그에 기록될 수 있고, 그 리두 로그를 이용해 장애 직전 시점까지 복구가 가능해진다.\n하지만 트랜잭션이 커밋될 때마다 리두 로그를 디스크에 기록하면 부하가 생길 수 있어, InnoDB 스토리지 엔진에서 리두 로그를 어느 주기로 디스크에 동기화할지를 결정하는 innodb_flush_log_trx_commit 시스템 변수를 제공한다.\n0: 1초에 한 번씩 리두 로그를 디스크로 기록하고 동기화를 실행한다. 서버가 비정상 종료되면 최대 1초 동안의 트랜잭션은 커밋됐더라도 데이터는 사라질 수 있다. 1: 매번 트랜잭션이 커밋될 때마다 디스크로 기록되고 동기화까지 수행한다. 2: 트랜잭션이 커밋될 때마다 디스크로 기록은 되지만 실질적인 동기화는 1초에 한번씩 실행된다. 커밋이 되면 변경 내용이 운영체제의 메모리 버퍼로 기롤되는 것이 보장되기 때문에 MySQL 서버가 비정상 종료되더라도 트랜잭션 데이터는 사라지지 않는다. 리두 로그 파일들의 전체 크기는 버버풀의 효율성을 결정하기 때문에 신중히 결정해야한다. 리두 로그 파일의 크기는 innodb_log_file_size 시스템 변수로 결정하며, innodb_log_files_in_group 시스템 뼌수는 리두 로그 파일 개수를 결정한다.\n리두 로그 파일의 전체 크기를 버퍼풀의 크기에 맞게 설정해야 적절히 변경된 내용을 버퍼풀에 모아 한번에 디스크에 기록할 수 있다.\nACID는 데이터베이스에서 트랜잭션의 무결성을 보장하기 위해 꼭 필요한 4가지 요소(기능)을 의미한다.\nA(Atomic): 트랜잭션은 원자성 작업이어야 함. C(Consistent): 일관성 I(Isolated): 격리성 D(Durable): 영속성. 한 번 저장된 데이터는 지속적으로 유지되어야 함. 리두 로그 아카이빙 MySQL 8.0부터 InnoDB 스토리지 엔진의 리두 로그를 아카이빙 할 수 있는 기능이 추가됐다.\n백업 툴이 리두 로그 아카이빙을 사용하려면 먼저 MySQL 서버에서 아카이빙된 리두 로그가 저장될 디렉터리를 innodb_redo_log_archive_dirs 시스템 변수에 설정해야 하며, 디렉터리는 운영체제의 MySQL 서버를 실행하는 유저만 접근이 가능해야 한다.\n1 2 3 4 mkdir /var/log/mysql_redo_archive cd /var/log/mysql_redo_archive mkdir 20230413 chmod 700 20230413 1 SET GLOBAL innodb_redo_log_archive_dirs=\u0026#39;backup:/var/log/mysql_redo_archive\u0026#39;; 디렉터리가 준비되면 리두 로그 아카이빙을 시작하도록 innodb_redo_log_archive_start UDF(사용자 정의 함수)를 실행한다. 해당 UDF는 리두 로그를 아카이빙할 디렉터리에 대한 레이블과 선택적으로 서브 디렉터리 이름 총 두가지의 매개 변수를 받는다.\n1 DO innodb_redo_log_archive_start(\u0026#39;backup\u0026#39;, \u0026#39;20230413\u0026#39;); 리두 아카이빙을 종료할 때는 innodb_redo_log_archive_stop UDF를 실행한다.\n1 DO innodb_redo_log_archive_stop(); innodb_redo_log_archive_start UDF를 실행한 세션의 연결이 끊어지면 InnoDB 스토리지 엔진은 리두 로그 아카이빙을 멈추고 아카이빙 파일도 자동으로 삭제하므로 커넥션을 유지해야 하고, innodb_redo_log_archive_stop UDF를 호출하여 정상적으로 종료돼야 한다.\n리두 로그 활성화 및 비활성화 InnoDB 스토리지 엔진의 리두 로그는 MySQL 서버가 비정상 종료됐을때 데이터 파일에 기록되지 못한 트랜잭션을 복구하기 위해 항상 활성화되어있다. MySQL 서버에서 트랜잭션이 커밋돼도 데이터 파일은 즉시 디스크로 동기화되지 않는 반면, 리두 로그는 항상 디스크로 기록된다.\nMySQL 8.0 버전부터 수동으로 리두 로그를 비활성화 할 수 있어, 대용량 데이터를 한번에 적재하는 경우 사용하여 적재 시간을 단축할 수 있다.\n어댑티브 해시 인덱스 어댑티브 해시 인덱스는 InnoDB 스토리지 엔진에서 사용자가 자주 요청하는 데이터에 대해 자동으로 생성하는 인덱스로, innodb_adaptive_hash_index 시스템 변수를 이용하여 활성화, 비활성화 할 수 있다.\nInnoDB 스토리지 엔진의 대표적인 인덱스는 B-Tree로 데이터는 PK 순으로 정렬되어 관리되고, Secondary Key는 인덱스키 + PK 조합으로 정렬되어 있다. 특정 데이터를 찾기 위해 Secondary Key에서 PK를 찾고, 찾은 PK를 통해 원하는 데이터를 찾는 형태로 처리된다.\nPK 사용시 데이터에 접근되는 비용은 O(logN)이고, Secondary Key를 사용해 데이터에 접근은 PK에 대한 접근도 필요하므로 2 * O(logN)이다.\n따라서 B-Tree 자료구조 특성으로 데이터가 많아진다 하더라도 탐색 비용이 크게 증가하지 않지만, 동시에 많은 스레드에서 탐색 작업이 발생할 경우 Lock 등으로 인해 성능 저하가 발생할 수 있다.\n어댑티브 해시 인덱스는 B-Tree의 검색 시간을 줄여주기 위해 도입된 기능으로, 자주 읽히는 데이터 페이지의 키 값을 이용해 해시 인덱스를 만들고, 필요할 때마다 어댑티브 해시 인덱스를 검색해서 레코드가 저장된 데이터 페이지를 즉시 찾아갈 수 있다.\n구조 해시 인덱스는 인덱스 키 값과 해당 인덱스 키 값이 저장된 데이터 페이지 주소의 쌍으로 관리된다.\n인덱스 키 값:\nB-Tree 인덱스의 고유번호 + B-Tree 인덱스의 실제 키 값 인덱스의 고유번호가 포함되는 이유는 InnoDB 스토리지 엔진에서 어댑티브 해시 인덱스는 하나만 존재하기 때문이다. 데이터 페이지 주소:\n실제 키 값이 저장된 데이터 페이지의 메모리 주소, 버퍼풀에 로딩된 페이지의 주소를 의미 어댑티브 해시 인덱스는 버퍼풀에 올려진 데이터 페이지에 대해서만 괸리되고, 버퍼풀에서 해당 데이터 페이지가 없어지면 어댑티브 해시 인덱스에서도 해당 페이지의 정보는 사라진다.\n성능 어댑티브 해시 인덱스를 활성화 후 처리량은 2배 가까이 늘었음에도 불구하고 CPU 사용량은 오히려 떨어진다.\nInnoDB 내부잠금(세마포어)의 횟수도 획기적으로 줄어든다.\n추가로 MySQL 8.0 부터는 내부 잠금을 줄이기 위해 어댑티브 해시 인덱스의 파티션 기능을 제공하며 innodb_adaptive_hash_index_parts 시스템 변수를 통해 파티션 개수를 변경할 수 있다(기본값 8개).\n어댑티브 해시 인덱스가 성능에 많은 도음이 된다면 파티션 개수를 더 많이 설정하는 것도 도움이 될 수 있다.\n한계 상황에 따라 어댑티브 해시 인덱스가 성능 향상에 크게 도움이 되지 않는 경우도 있다.\n성능 향상에 도움이 되는 경우 디스크의 데이터가 InnoDB 버퍼풀 크기와 비슷한 경우(디스크 읽기가 많지 않은 경우) 동등 조건 검색(동등 비교 및 IN 연산)이 많은 경우 쿼리가 일부 데이터에만 집중 되는 경우 성능 향상에 크게 도움이 되지 않는 경우 디스크 읽기가 많은 경우 특정 패턴의 쿼리가 많은 경우(JOIN, LIKE 패턴 검색) 매우 큰 데이터를 가진 테이블의 레코드를 폭넓게 읽는 경우 어댑티브 해시 인덱스는 데이터 페이지를 메모리(버퍼풀) 내에서 접근하는 것을 더 빠르게 만드는 기능으로 데이터 페이지를 디스크에서 읽어오는 경우가 많은 경우 데이터베이스 서버에서는 큰 도움이 되지 않는다.\n어댑티브 해시 인덱스 또한 메모리를 사용하며, 때로는 상당히 큰 메모리 공간을 사용할 수 있다. 데이터 페이지의 인덱스 키가 해시 인덱스로 만들어져야 하기 때문에 불필요한 경우 제거되어야 한다. 활성화되면 InnoDB 스토리지 엔진이 필수적으로 검색에 활용해야 하기 때문에 불필요한 접근이 발생할 수 있다. 주의할 점 테이블 삭제(DROP), 변경(ALTER)시 해당 테이블이 가진 모든 데이터 페이지의 내용을 어댑티브 해시 인덱스에서 제거해야한다. 이로 인해 테이블이 삭제되거나 스키마가 변경되는 동안 상당히 많은 CPU 자원을 사용하게되어 데이터베이스 서버의 처리 성능이 떨어진다.\n모니터링 MySQL 서버의 상태 값들을 통해 어댑티브 해시 인덱스가 불필요한 오버헤드만 만들고 있는지 확인할 수 있다.\n1 2 3 4 5 6 7 8 SHOW ENGINE INNODB STATUS\\G /* Hash table size 8747, node heap has 1 buffers(s) Hash table size 8747, node heap has 0 buffers(s) ... 1.03 hash searches/s, 2.64 non-hash searches/s /* searches: 쿼리가 처리되기 위해 내부적으로 키 값의 검색이 몇 번 실행되었는지를 의미함\n어댑티브 해시 인덱스의 효율은 검색 횟수가 아니라 해시 인덱스 히트율과 인덱스가 사용 중인 메모리 공간, 서버의 CPU 사용량을 종합해서 판단해야 한다.\n위 실행 쿼리 결과에서는 28% 정도가 어댑티브 해시 인덱스를 이용했다는 것을 알 수 있는데, 서버의 CPU 사용량이 100%에 근접한다면 효율적이라고 볼 수 있다. 하지만 CPU 사용량이 낮고 어댑티브 해시 인덱스의 메모리 사용량이 높다면 비활성화하여 버퍼풀이 더 많은 메모리를 사용할 수 있게 유도하는 것도 좋은 방법이다.\n어댑티브 해시 인덱스의 메모리 사용량은 performance_schema를 이용해서 확인 가능하다.\n1 2 3 4 5 SELECT EVENT_NAME ,CURRENT_NUMBER_OF_BYTES_USED FROM performance_schema.memory_summary_global_by_event_name WHERE EVENT_NAME=\u0026#39;memory/innodb/adaptive hash index\u0026#39; ; MyISAM, MEMORY 스토리지 엔진 비교 MyISAM MySQL 5.5부터는 InnoDB 스토리지 엔진이 기본 스토리지 엔진으로 채택 되었지만, 이전까지는 MyISAM이 기본 스토리지 엔진으로 사용되는 경우가 많았다.\nMySQL 서버의 시스템 테이블의 기본 스토리지 엔진 MySQL 8.0 부터는 MyISAM이 기본 설정되었던 서버의 시스템 테이블(사용자 인증 관련 정보, 복제 관련 정보가 저장된 mysql DB의 테이블) 등 서버의 모든 기능을 InnoDB 스토리지 엔진으로 교체되었다. 전문 검색 및 공간 좌표 검색 기능 제공. InnoDB 스토리지 엔진에서도 전문 검색과 공간 좌표 검색 기능을 모두 지원하도록 개선되었다. 이러한 이유로 MyISAM 스토리지 엔진은 InnoDB 스토리지 엔진으로 대체될 것으로 예상된다.\nMEMORY MEMORY 스토리지 엔진이 메모리라는 이름 때문에 과대 평가를 받는 경우가 있다.\n단일 스레드 처리 성능 단일 스레드 처리 성능은 MEMORY 스토리지 엔진이 빠를 수 있으나, MySQL 서버는 일반적으로 온라인 트랜잭션 처리를 위한 목적으로 사용되어 동시 처리 성능이 매우 중요하다. MEMORY 스토리지 엔진에서 동시에 많은 클라이언트 쿼리 요청이 실행되는 상황이라면 테이블 수준의 잠금으로 인해 InnoDB 스토리지 엔진을 따라갈 수 없다.\n임시 테이블 용도로 활용 MySQL 5.7 버전까지 내부 임시 테이블 용도로 활용되었으나, 가변 길이 타입의 컬럼을 지원하지 않는다는 문제점으로 MySQL 8.0 부터는 TempTable 스토리지 엔진이 대체되어 사용된다.\n이러한 이유로 MEMORY 스토리지 엔진을 선택해서 얻을 수 있는 장점이 없어져, 향후 버전에서는 제거될 것으로 예상된다.\n","date":"2023-04-13T12:39:01+09:00","image":"https://codemario318.github.io/post/real_mysql_4_2_3/real_mysql_hu03b8ff0acb6f52b3ec9ae95e616f82c2_25714_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/real_mysql_4_2_3/","title":"4.2 InnoDB 스토리지 엔진 아키텍처(3)"},{"content":"버퍼풀은 InnoDB 스토리지 엔진의 핵심으로 디스크에서 데이터를 읽어 메모리에 보관하고, 필요할 때 메모리에서 데이터를 읽어와 처리하는 역할을 수행한다. 또한 디스크와 메모리 사이에서 데이터 읽기 및 쓰기를 관리하여 데이터 베이스의 성능을 향상시킨다.\n디스크의 데이터 파일이나 인덱스 정보를 메모리에 캐시해 두는 공간이다. 쓰기 작업을 지연시켜 일괄 작업으로 처리할 수 있게 해주는 버퍼 역할도 수행한다. 일반적인 애플리케이션에서는 INSERT, UPDATE, DELETE처럼 데이터를 변경하는 쿼리는 데이터 파일의 흩어져있는 레코드를 변경하기 때문에 랜덤한 디스크 작업을 발생시킨다. 변경을 모아 처리하여 랜덤 디스크 접근 작업 수를 줄일 수 있다.\n버퍼풀의 크기 설정 운영체제와 각 클라이언트 스레드가 사용할 메모리도 충분히 고려하여 설정한다. MySQL 서버 내에서 메모리를 필요로 하는 부분은 크게 없지만 아주 독특한 경우 레코드 버퍼가 상당한 메모리를 사용하기도 한다.\n레코드버퍼\n각 클라이언트 세션에서 테이블의 레코드를 읽고 쓸 때 버퍼로 사용하는 공간으로 커넥션이 많고 사용하는 테이블도 많다면 레코드 버퍼 용도로 사용되는 메모리 공간이 많이 필요할 수 있다.\nMySQL 서버가 사용하는 레코드 버퍼 공간은 별도로 설정할 수 없어, 전체 커넥션 개수와 각 커넥션에서 읽고 쓰는 테이블의 개수에 따라 결정되고, 동적으로 해제되기도 하므로 정확히 필요한 메모리의 크기를 계산할 수 없다.\n버퍼풀 동적 크기 조절 MySQL 5.7 버전부터 InnoDB 버퍼풀의 크기를 동적으로 조절할 수 있게 개선되어 가능하면 InnoDB 버퍼풀의 크기를 적절히 작은 값으로 설정하고 상황을 봐가며 증가시키는 방법이 최적이다.\ninnodb_buffer_pool_size 시스템 변수로 크기를 설정할 수 있으며, 동적으로 버퍼풀의 크기를 확장할 수 있다.\n크리티컬한 변경이므로 가능하며 MySQL 서버가 한가한 시점을 골라 실행한다. 버퍼풀의 크기를 줄이는 작업은 서비스 영향도가 매우 크므로 주의해야한다. 버퍼풀은 내부적으로 128MB 청크 단위로 쪼개어 관리되어 조절된다. 버퍼풀 나누기 InnoDB 버퍼풀은 정통적으로 버퍼풀 전체를 관리하는 잠금(세마포어)으로 인해 내부 잠금 경합을 많이 유발해왔는데, 이런 경함을 줄이기 위해 버퍼풀을 여러개로 쪼개어 관리할 수 있게 개선되었다.\n버퍼풀이 여러 개의 작은 버퍼풀로 쪼개지면서 개별 버퍼풀을 관리하는 잠금 자체도 경합이 분산되는 효과를 얻을 수 있게 된다.\ninnodb_buffer_pool_instances 시스템 변수를 이용해 버퍼풀을 여러개로 분리하여 관리할 수 있다.\n버퍼풀 구조 InnoDB 스토리지 엔진은 버퍼풀이라는 거대한 메모리 공간을 페이지 크기(innodb_page_size 시스템 변수에 설정된)의 조각으로 쪼개어 InnoDB 스토리지 엔진이 데이터를 필요로 할 때 해당 데이터 페이지를 읽어서 각 조각에 저장한다.\n버퍼풀의 페이지 조각을 관리하기 위해 LRU(least Recently Used) 리스트와, 플러시(Flush) 리스트, 프리(Free) 리스트라는 3개의 자료 구조를 관리한다.\nLRU 리스트: 디스크로부터 읽어온 페이지 저장하는 자료구조. 읽어온 페이지를 최대한 오랫동안 버퍼풀의 메모리에 유지하여 디스크 읽기를 최소화 한다.\n플러시 리스트: 디스크로 동기화되지 않은 데이터를 가진 데이터 페이지(더티 페이지)의 변경 시점 기준의 페이지 목록을 관리한다.\n프리리스트: 버퍼풀에서 실제 사용자 데이터로 채워지지 않은 비어있는 페이지들의 목록. 사용자의 쿼리가 새로벡 디스크의 데이터 페이지를 읽어와야 하는 경우 사용된다.\nLRU 리스트 구조 LRU 리스트는, Old 서브리스트 영역은 LRU, New 서브리스트 영역은 MRU(Most Recently Used)가 합쳐진 방식으로 동작한다.\nNew 서브리스트의 Tail과 Old 서브리스트의 Head가 만나는 지점을 MidPoint라 하며 버퍼풀에 새로운 페이지가 들어올 경우 Old 서브리스트의 Head 부분에 저장한다.\nNew 서브리스트와 Old 서브리스트로 나눈 이유는?\n하나의 큐를 사용하여 페이지를 관리할 경우에 Head 또는 Tail에 페이지를 저장하는 방식을 생각해 볼 수 있다. Head에 저장될 경우 새로 관리되는 페이지가 사용되지 않더라도 오랜 시간동안 리스트에 남아 있게되고, Tail에 저장될경우 해당 페이지를 즉시 읽지 않는다면 리스트에 남아있지 않게 되어 의미가 없어질 수 있다.\n이를 위해 두개의 서브리스트로 나누고, 경험적으로 얻은 5/8 지점을 활용한 중간점 삽입 전략을 사용하는 것 같다.\n데이터를 찾는 과정 필요한 레코드가 저장된 데이터 페이지가 버퍼풀에 있는지 검사\nInnoDB 어댑티브 해시 인덱스를 이용해 페이지를 검색 해당 테이블의 인덱스(B-Tree)를 이용해 버퍼풀에서 페이지를 검색 버퍼풀에 이미 데이터 페이지가 있다면 해당 페이지의 포인터를 MRU 방향으로 승급 디스크에서 필요한 데이터 페이지를 버퍼풀에 적재하고, 적재된 페이지에 대한 포인터를 LRU 헤더 부분에 추가\n버퍼풀의 LRU 헤더에 적재된 데이터 페이지가 실제로 읽히면 MRU 헤더 부분으로 이동(Read Ahead와 같이 대량 읽기의 경우 디스크 페이지가 버퍼풀로 적재는 되지만 실제 쿼리에서 사용되지는 않을수도 있으며, 이련 경우는 MRU로 이동되지 않음)\n버퍼풀에 상주하는 데이터 페이지는 사용자 쿼리가 얼마나 최근에 접근했었는지에 따라 나이가 부여되며, 버퍼풀에 상주하는 동안 쿼리에서 오랫동안 사용되지 않으면 오래된 페이지는 버퍼풀에서 제거됨. 버퍼풀의 페이지가 쿼리에 의해 사용되면 나이가 초기회되고 MRU헤더 부분으로 옮겨진다.\n필요한 데이터가 자주 접근됐다면 해당 페이지의 인덱스 키를 어댑티브 해시 인덱스에 추가\n처음 한번 읽힌 데이터 페이지가 이후 자주 사용된다면 버퍼풀의 MRU 영역에서 살아남게 되고, 그렇지 않은 경우 새롭게 읽히는 데이터 페이지에 밀려 결과적으로 버퍼풀에서 제거된다.\n버퍼풀과 리두 로그 버퍼풀은 데이터 베이스 서버의 성능 향상을 위해 데이터 캐시와 쓰기 버퍼링이라는 두가지 용도가 있다. 따라서 메모리가 허용하는 만큼 크게 설정하면 데이터 캐시 공간을 키워 쿼리의 성능 높힐 수 있지만, 쓰기 버퍼링 성능 향상을 위해서는 버퍼풀과 리두 로그의 관계에 대해 이해하는 것이 중요하다.\n리두 로그(Redo Log)란? 리두 로그는 데이터베이스에 대한 모든 변경 내용을 기록하는 파일셋이다. 시스템 장애나 충돌이 발생했을 때 데이터의 내구성과 일관성을 보장하기 위해 사용된다.\n데이터베이스에 변경 사항이 발생하면, 먼저 선로깅(write-ahead logging)프로세스로 리두 로그에 쓰여지고 변경 내용이 리두 로그에 기록되면 데이터베이스에 적용된다.\n리두 로그 파일은 일반적으로 디스크에 저장되며, MySQL은 변경 사항을 순차적으로 기록한다. 리두 로그 파일이 가득 차면 MySQL은 \u0026ldquo;체크포인트(checkpoint)\u0026ldquo;를 수행하여 데이터베이스의 모든 더티 페이지(버퍼풀에서 수정된 페이지)를 디스크에 기록한 후, 로그 파일을 잘라내어 공간을 확보하게 된다.\nMySQL에서 리두 로그는 원형 버퍼 형식으로 저장되며, 채워지면 다음 변경 사항은 순환 방식으로 다음 사용 가능한 리두 로그 파일에 기록된다. 이를 통해 리두 로그에 변경 사항이 지속적으로 기록되어 시스템 충돌이나 장애가 발생하더라도 변경 사항을 손실하지 않도록 보장한다.\n버퍼풀과 리두 로그의 관계 버퍼풀은 디스크에서 읽은 상태로 전혀 변경되지 않은 클린 페이지(Clean Page)와 함께 INSERT, UPDATE, DELETE를 통해 변경된 데이터를 가진 더티 페이지(Duty Page)를 가지고 있다.\n데이터 변경이 발생하면 먼저 리두 로그에 기록되고 리두 로그는 더티 페이지와 대응하게 된다.\n데이터 변경이 반복되면 결국 리두 로그 파일을 기록할 수 없거나 버퍼풀 용량이 부족해지는데, 이를 대응하기 위해 체크포인트를 수행하여 모든 더티페이지를 디스크에 기록한 후, 리두 로그 파일을 잘라내어 공간을 확보한다.\n이러한 방식이 버퍼풀이 쓰기 버퍼의 역할을 수행하게 만들게 되는데, 이에 따라서 리두 로그 파일의 크기가 작을수록 버퍼풀의 크기가 크더라도 대응되는 더티 페이지가 적으므로 버퍼링으로 얻을 수 있는 효과가 적어지고, 리두 로그 파일이 클수록 체크포인트를 통해 디스크에 기록되는 데이터가 많아져 갑자기 많은 디스크 I/O를 발생 시킬 수 있다.\n따라서, 리두 로그 파일의 크기를 적절히 선택해야하며, 어렵다면 버퍼풀의 크기가 100GB 이하의 MySQL 서버에서는 리두 로그 파일의 전체 크기를 대략 5~10GB 수준으로 선택하고 필요할 때마다 조금씩 늘려가며 최적값을 찾는 것이 좋다.\n버퍼풀 플러시(Buffer Pool Flush) 버퍼풀에서 수정된 데이터 페이지를 디스크로 쓰는 과정으로 MySQL 5.6 버전까지는 InnoDB 스토리지 더티 페이지 플러시 기능이 급작스럽게 디스크 기록이 폭증해서 MySQL 서버의 사용자 쿼리 처리 성능에 영향을 받는 등 그다지 부드럽게 처리되지 않았다.\nMySQL 5.7 버전을 거쳐 8.0 버전으로 업그레이드되면서 대부분의 서비스에서는 더티 페이지 프러시에서 예전과 같이 폭증 현상은 발생하지 않았다. 따라서 InnoDB 스토리지 엔진의 더티 페이지 플러시 성능 문제가 발생하지 않는다면 관련 시스템 변수는 조절하지 않아도 괜찮다.\nInnoDB 스토리지 엔진은 버퍼풀에서 아직 디스크로 기록되지 않은 더티 페이지들을 성능상 악영향 없이 디스크에 동기화하기 위해 다음과 같이 2개의 플러시 기능을 백그라운드로 실행한다.\n플러시 리스트(Flush_list) 플러시 LRU 리스트(LRU_list) 플러시 플러시 리스트 플러시 InnoDB 스토리지 엔진은 리두 로그 공간의 재활용을 위해 주기적으로 오래된 리두 로그 엔트리가 사용하는 공간을 비운다. 이때 오래된 리두 로그 공간이 지워지려면 반드시 InnoDB 버퍼풀의 더티 페이지가 먼저 디스크로 동기화 돼야 한다.\n이를 위해 InnoDB 스토리지 엔진은 주기적으로 플러시 리스트(Flush_list) 플러시 함수를 호출하여 플러시 리스트에서 오래전에 변경된 데이터 페이지 순서대로 디스크에 동기화 하는 작업을 수행한다.\n이때 언제부터 얼마나 많은 더티 페이지를 한번에 디스크로 기록하느냐에 따라 사용자의 쿼리 처리가 악영향을 받지 않으면서 부드럽게 처리된다. 리를 위해 InnoDB 스토리지 엔진은 여러 시스템 변수를 제공한다.\ninnodb_page_cleaners InnoDB 스토리지 엔진에서 더티 페이지를 디스크로 동기화하는 스레드를 클리너 스레드(Cleaner Thread)라고 하고, 클리너 스레드의 개수를 조정할 수 있게 해준다.\n설정값이 버퍼풀 인스턴스 개수보다 많은 경우 innodb_buffer_pool_instances 설정값으로 자동으로 변경하여, 하나의 클리너 스레드가 하나의 버퍼풀 인스턴스를 처리하도록 한다.\n시스템 변수의 설정값이 버퍼풀 인스턴스 개수보다 적은 경우 하나의 클리너 스레드가 여러 개의 버퍼풀 인스턴스를 처리하므로, innodb_page_cleaners 설정값은 innodb_buffer_pool_instances 설정 값과 동일하게 설정하는 것이 좋다.\ninnodb_max_dirty_pages_pct InnoDB 버퍼풀은 클린 페이지와 더티 페이지를 함께 가지고 있어 뭏란정 더티 페이지를 그대로 유지할 수 없다. 기본적으로 InnoDB 스토리지 엔진은 전체 버퍼풀이 가진 페이지의 90%까지 더티페이지를 가질 수 있는데, innodb_max_dirty_pct 시스템 변수를 이용해 더티페이지의 비율을 조절할 수 있다.\n일반적으로 버퍼풀이 더티페이지를 많이 가지고 있을수록 디스크 쓰기 작업을 버퍼링함으로써 I/O 작업을 줄일 수 있으므로 기본값으로 유지하는 것이 좋다.\ninnodb_max_dirty_pages_pct_lwm InnoDB 스토리지 엔진은 innodb_io_capacity 시스템 변수에 설정된 값을 기준으로 더티 페이지 쓰기를 실행하는데, 디스크로 기록되는 더티페이지 개수보다 더 많은 더티페이지가 발생하면 버퍼풀에 더티페이지가 계속 증가하게 되고, 지정한 비율이 넘어가면 더티페이지를 디스크로 기록하여 디스크 쓰기 폭발(Dist IO Bust) 현상이 발생할 가능성이 있다.\n이런 문제를 완화하기 위해 innodb_max_dirty_pages_pct_lwm 시스템 설정 변수를 이용해 일정 수준 이상의 더티페이지가 발생하면 조금씩 더티 페이지를 디스크로 기록한다.\n기본값은 10% 정도로, 디스크 쓰기가 많이 발생하고 더티 페이지 비율이 낮은 상태를 유지한다면 높은 값으로 조정할 수 있다.\ninnodb_io_capacity, innodb_io_capacity_max 데이터베이스 서버에서 어느정도의 디스크 IO가 가능한지 설정하는 값이다. innodb_io_capacity는 일반적인 상황에서 디스크가 적절히 처리할 수 있는 수준의 값을 설정하며, innodb_io_capacity_max는 디스크가 최대 성능을 발휘할 때 어느 정도 IO가 가능한지를 설정한다.\n여기서 언급되는 IO는 InnoDB 스토리지 엔진의 백그라운드 스레드가 수행하는 디스크 작업을 의미하며, 대부분 더티페이지 쓰기이다.\n스토리지 엔진은 사용자의 쿼리를 처리하기 위해 디스크를 읽기도 해야하므로 하드웨어 성능에 무조건 맞추는 것은 좋지 않다.\ninnodb_adaptive_flushing, innodb_adaptive_flushing_lwm 어댑티브 플러시를 활성화 하면 InnoDB 스토리지 엔진은 버퍼불의 더티 페이지 비율이나 innodb_io_capacity, innodb_io_capacity_max 설정 값에 의존하지 않고 알고리즘을 사용한다.\n더티 페이지는 리두 로그와 대응하므로, 리두 로그가 어느정도 증가하는지 분석하여 확인할 수 있다. 어댑티브 플러시 알고리즘은 리두 로그의 증가 속도를 분석하여 적절한 수준의 더티 페이지가 버퍼풀에 유지될 수 있도록 디스크 쓰기를 실행한다.\ninnodb_adaptive_flushing는 기본값이 활성이며, innodb_adaptive_flushing_lwm는 어댑티브 플러시 알고리즘 활성을 위한 활성 리두 공간의 하한 비율을 의미한다.\ninnodb_flush_neighbors 더티페이지를 디스크에 기록할 때 디스크에서 근접한 페이지 중 더티페이지가 있다면 InnoDB 스토리지 엔진이 함께 묶어 디스크로 기록하게 해주는 기능을 활성화 할지 결정한다.\n과거에는 HDD의 경우 IO 비용이 높아 최대한 줄이기 위해 만들어졌다.\n데이터 저장을 하드디스크로 하고있다면 1, 2 정도로 활성화 하고, SSD를 사용한다면 기본값인 비활성으로 유지하는 것이 좋다.\nLRU 리스트 플러시 InnoDB 스토리지 엔진은 LRU 리스트에서 사용 빈도가 낮은 데이터 페이지들을 제거하여 새로운 페이지들을 읽어올 공간을 만들어야 하는데, 이를 위해 LRU 리스트 플러시 함수가 사용된다.\n리스트 끝부분 부터 시작하여 최대 innodb_lru_scan_depth 시스템 변수에 설정된 수만큼의 페이지들을 스캔하는데, 이때 더티체이지는 디스크에 동기화하고, 클린 페이지는 즉시 프리 리스트로 페이지를 옮긴다.\nInnoDB 스토리지 엔진은 버퍼풀 인스턴스 별로 최대 innodb_lru_scan_depth 개수만큼 스캔하기 때문에 실질적으로 LRU 리스트의 스캔은 (innodb_buffer_pool_instances * innodb_lru_scan_depth) 수만큼 수행하게 된다.\n버퍼풀 상태 백업 및 복구 InnoDB 서버의 버퍼풀은 쿼리의 성능에 매우 밀접하게 연결돼 있다. 서버 재실행시 버퍼풀에 쿼리들이 사용할 데이터가 없어 성능이 매우 떨어지게 된다.\n디스크의 데이터가 버퍼풀에 적재돼 있는 상태를 위밍업(Warming Up)이라고 표현하는데, 워밍업 상태에 따라 몇십 배 쿼리 처리속도 차이가 발생하게 된다.\nMySQL 5.5 버전은 재실행시 강제 워밍업을 위해 주요 테이블과 인덱스에 대해 풀스캔을 실행하고 서비스를 오픈했었다. 하지만 5.6 버전부터는 버퍼풀 덤프 및 적재 기능이 도입되어 MySQL 서버 셧다운 전 innodb_buffer_pool_dump_now 시스템 변수를 이용해 현재 InnoDB 버퍼풀 상태를 백업할 수 있다.\n1 2 3 4 5 /* 버퍼풀 상태 백업 */ SET GLOBAL innodb_buffer_pool_dump_now=ON; /* 백업된 버퍼풀 상태 복구 */ SET GLOBAL innodb_buffer_pool_load_now=ON; 버퍼풀 백업을 수행하면 데이터 디렉터리에 ib_buffer_pool이라는 파일로 생성되는데, InnoDB 스토리지 엔진이 버퍼풀의 LRU 리스트에서 적재된 데이터 페이지의 메타 정보만 가져와 저장하여, 버퍼풀이 크다고 하더라도 몇십 MB 이하로 작다.\n하지만 버퍼풀로 복구하는 과정에서 각 테이블의 데이터 페이지를 디스크에서 다시 읽어와야 하기 때문에 버퍼풀의 크기에 따라 매우 오래 걸릴 수 있다.\n1 SHOW STATUS LIKE \u0026#39;Innodb_buffer_pool_dump_status\u0026#39;\\G InnoDB의 버퍼풀을 복구하는 작업은 상당히 많은 디스크 읽기를 필요로 하기 때문에, 복구중 서비스 재개하는 것은 좋지 않을 수 있다. 버퍼풀 적재 작업을 중지하려면 innodb_buffer_pool_load_abort 시스템 변수를 통해 중지하여 재개하는 것을 권장한다.\n1 SET GLOBAL innodb_buffer_pool_load_abort=ON; 백업 및 복구 자동화 InnoDB 스토리지 엔진은 innodb_buffer_pool_dump_at_shutdown, innodb_buffer_pool_load_at_shutdown 설정을 MySQL 설정 파일에 넣으면 서버가 셧다운 되기 직전에 버퍼풀의 백업을 실행하고, MySQL 서버가 시작되면 자동으로 백업된 버퍼풀의 상태를 복구할 수 있는 기능을 제공한다.\n버퍼풀의 적재 내용 확인 MySQL 5.6 버전부터 MySQL 서버의 information_schema 데이터베이스의 innodb_buffer_page 테이블을 이용해 InnoDB 버퍼풀의 메모리에 어떤 테이블의 페이지들이 적재돼 있는지 확인할 수 있었다. 하지만 버퍼풀이 큰 경우에는 테이블 조회가 상당히 큰 부하를 일으키면서 서비스 쿼리가 많이 느려지는 문제가 있어, 실제 서비스용으로 사용되는 MySQL 서버에서는 버퍼풀의 상태를 확인하는 것이 거의 불가능했다.\nMySQL 8.0 버전에서는 information_schema 데이터베이스에 innodb_cached_indexes 테이블이 새로 추가되어, 테이블의 인덱스별로 데이터 페이지가 얼마나 InnoDB 버퍼풀에 적재돼 있는지 확인할 수 있다.\n1 2 3 4 5 6 7 8 9 SELECT it.name table_name ,ii.name index_name ,ici.n_cached_pages n_cached_pages FROM information_schema.innodb_tables it JOIN information_schema.innodb_indexes ii ON ii.table_id = it.table_id JOIN information_schema.innodb_cached_indexes ici ON ici.index_id = ii.index_id WHERE it.name=CONCAT(\u0026#39;employees\u0026#39;, \u0026#39;/\u0026#39;, \u0026#39;employees\u0026#39;) ; 아직 MySQL 서버는 개별 인덱스별로 전체 페이지 개수가 몇 개인지는 사용자에게 알려주지 않기 때문에 information_schema의 테이블을 이용해도 테이블의 인덱스별로 페이지가 InnoDB 버퍼풀에 적재된 비율은 확인할 수가 없다.\n","date":"2023-04-12T14:27:41+09:00","image":"https://codemario318.github.io/post/real_mysql_4_2_2/real_mysql_hu03b8ff0acb6f52b3ec9ae95e616f82c2_25714_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/real_mysql_4_2_2/","title":"4.2 InnoDB 스토리지 엔진 아키텍처(2) - InnoDB 버퍼풀"},{"content":"\nInnoDB는 MySQL에서 사용할 수 있는 스토리지 엔진 중 거의 유일하게 레코드 기반 잠금을 제공하며, 그 때문에 높은 동시성 처리가 가능하고 안정적이며 성능이 뛰어나다.\n프라이머리 키에 의한 클러스터링 InnoDB의 모든 테이블은 기본적으로 프라이머리 키를 기준으로 클러스터링되어 자장된다.\n프라이머리 키 값의 순서대로 디스크에 저장되며, 모든 세컨더리 인덱스는 레코드의 주소 대신 프라이머리 키의 값을 논리적인 주소로 사용한다. 프라이머리 키가 클러스터링 인덱스이기 때문에 프라이머리 키를 이용한 레인지 스캔은 상당히 빨리 처리될 수 있다. 쿼리의 실행계획에서 프라이머리 키는 기본적으로 다른 보조 인덱스에 비해 비중이 높게 설정된다. 외래 키 지원 외래 키에 대한 지원은 InnoDB 스토리지 엔진 레벨에서 지원하는 기능으로 MyISAM이나 MEMORY 테이블에서는 사용할 수 없다.\n외래 키는 데이터베이스 서버 운영의 불편함 때문에 서비스용 데이터베이스에서는 생성하지 않는 경우도 자주 있다. 그렇다 하더라도 개발 환경의 데이터베이스에서는 좋은 가이드 역할을 할 수 있다.\nInnoDB에서 외래 키는 부모 테이블과 자식 테이블 모두 해당 칼럼에 인덱스 생성이 필요함 변경 시에는 반드시 부모 테이블이나 자식 테이블에 데이터가 있는지 체크하는 작업이 필요하므로, 잠금이 여러 테이블로 전파됨 그로인한 데드락이 발생할 때가 많으므로 개발할때도 외래 키의 존재에 주의하는 것이 좋음 수동으로 데이터를 적재하거나 스키마 변경 등의 관리 작업이 실패할 수 있다. 부모 테이블과 자식 테이블의 관계를 명확히 파악해서 순서대로 작업한다면 문제없이 실행될 수 있지만 외래키가 복잡하게 얽힌 경우에는 간단하지 않다.\nforeign_key_checks 시스템 변수를 OFF로 설정하면 외래키 관계에 대한 체크 작업을 일시적으로 멈출 수 있다. 외래키 체크 작업을 일시적으로 멈추면 대략 레코드 적재나 삭제 등의 작업도 부가적인 체크가 필요 없기 때문에 훨씬 빠르게 처리할 수 있다.\n1 2 3 4 5 SET foreign_key_checks=OFF; /* 작업 수행 ... */ SET foreign_key_checks=ON; 외래키 체크를 일시적으로 중지한 상태에서 외래키 관계를 가진 부모 테이블의 레코드를 삭제했다면 반드시 자식 테이블의 레코드도 살제하여 일관성을 맞춰준 후 다시 외래키 체크 기능을 활성화 해야 한다.\nforeign_key_checks가 비활성화되면 외래키 관계의 부모 테이블에 대한 작업도 무시한다.(ON DELETE CASCADE, ON UPDATE CASCADE)\nMVCC - Multi Version Concurrency Control 일반적으로 레코드 레벨의 트랜잭션을 지원하는 DBMS가 제공하는 기능이며, MVCC의 가장 큰 목적은 잠금을 사용하지 않는 일관된 읽기를 제공하는 데 있다.\nInnoDB는 언두 로그(Undo log)를 이용해 이 기능을 구현한다.\n멀티 버전: 하나의 레코드에 대해 여러 개의 버전이 동시에 관리 1 2 3 4 5 6 7 CREATE TABLE member ( m_id INT NOT NULL, m_name VARCHAR(20) NOT NULL, m_area VARCHAR(100) NOT NULL, PRIMARY KEY (m_id), INDEX ix_area (m_area) ); 1 2 INSERT INTO member (m_id, m_name, m_area) VALUES (12, \u0026#39;홍길동\u0026#39;, \u0026#39;서울\u0026#39;); COMMIT; 1 UPDATE member SET m_area=\u0026#39;경기\u0026#39; WHERE m_id=12; UPDATE 문장이 실행되면 커밋 실행 여부와 관계 없이 InnoDB의 버퍼풀은 새로운 값인 ‘경기’로 업데이트 된다. 그리고 디스크의 데이터 파일에는 체크포인트나 InnoDB의 Write 스레드에 의해 새로운 값으로 업데이트돼 있을 수도 있고 아닐 수도 있다.(InnoDB가 ACID를 보장하기 때문에 일반적으로는 InnoDB의 버퍼풀과 데이터 파일은 동일한 상태라고 가정해도 무방함)\n아직 COMMIT이나 ROLLBACK이 되지 않은 상태에서 다른 사용자가 다음 같은 쿼리로 작업 중인 레코드를 조회한다면, MySQL 서버의 시스템 변수(transaction_isolation)에 설정된 격리 수준(Isolation level)에 따라 다르다.\nREAD_UNCOMMITED: InnoDB 버퍼풀이 현재 가지고 있는 변경된 데이터를 읽어서 반환한다. READ_COMMITTED, REPEATABLE_READ, SERIALIZABLE: 아직 커밋되지 않았기 때문에 InnoDB 버퍼풀이나 데이터 파일에 있는 내용 대신 변경되기 이전의 내용을 보관하고 있는 언두 영역의 데이터를 반환한다. 이러한 과정을 DBMS에서는 MVCC라고 표현한다. 즉 하나의 레코드(회원번호가 12인 레코드)에 대해 2개의 버전이 유지되고, 필요에 따라 어느 데이터가 보여지는지 여러 가지 상황에 따라 다르다.\n트랜잭션이 길어지면 언두에서 관리하는 예전 데이터가 삭제되지 못하고 오랫동안 관리되어야 하며, 자연히 언두 영역이 저장되는 시스템 테이블 스페이스의 공간이 많이 늘어나는 상황이 발생할 수 있다.\nUPDATE 쿼리가 실행되면 InnoDB 버퍼 풀은 즉시 새로운 데이터로 변경되고 기존 데이터는 언두영역으로 복사된다.\nCOMMIT: InnoDB는 더 이상의 변경 작업 없이 지금의 상태를 영구적인 데이터로 만들어 버린다. ROLLBACK: 언두 영역에 있는 백업된 데이터를 InnoDB 버퍼 풀로 다시 복구하고, 언두 영역의 내용을 삭제한다. 커밋이 된다고 언두 영역의 백업 데이터가 항상 바로 삭제되지는 않고, 언두 영역을 필요로 하는 트랜잭션이 없을때 삭제된다.\n잠금 없는 일관된 읽기 - Non-Locking Consistent Read InnoDB 스토리지 엔진은 MVCC 기술을 이용해 감금을 걸지 않고 읽기 작업을 수행한다. 잠금을 걸지 않기 때문에 InnoDB에서 읽기 작업은 다른 트랜잭션이 가지고 있는 잠금을 기다리지 않고, 읽기 작업이 가능하다.\n격리수준이 SERIALIZABLE이 아닌 READ_UNCOMMITED나 READ_COMMITED, REPEATEABLE_READ 수준인 경우 INSERT와 연결되지 않은 순수한 읽기(SELECT) 작업은 다른 트랜잭션의 변경 작업과 관계 없이 항상 잠금을 대기하지 않고 바로 실행된다.\n특정 사용자가 레코드를 변경하고 아직 커밋을 수행하지 않았다 하더라도 변경 트랜잭션이 다른 사용자의 SELECT 작업을 방해하지 않는다. 이를 ‘잠금 없는 일관된 읽기’ 라고 표현하며, InnoDB에서는 변경되기 전의 데이터를 읽기 위해 언두 로그를 사용한다.\n오랜 시간 동안 활성 상태인 트랜잭션으로 인해 MySQL 서버가 느려지거나 문제가 발생할 때가 가끔 있는데, 일관된 읽기를 위해 언두 로그를 삭제하지 못하고 계속 유지해야 하기 때문에 발생하는 문제이다.\n따라서 트랜잭션이 시작됐다면 가능한 빨리 롤백이나 커밋을 통해 트랜잭션을 완료하는 것이 좋다.\n자동 데드락 감지 InnoDB 스토리지 엔진은 내부적으로 잠금이 교착 상태에 빠지지 않았는지 체크하기 위해 잠금 대기 목록(Wait-for List)을 그래프 형태로 관리한다. InnoDB 스토리지 엔진은 데드락 감지 스레드를 통해 주기적으로 잠금 대기를 그래프를 검사해 교착 상태에 빠진 트랜잭션들을 찾아서 그중 하나를 강제 종료한다.\n트랜잭션의 언두 로그양이 적은 트랜잭션이 롤백 해도 처리한 내용이 적기 때문에 선택된다.\nInnoDB 스토리지 엔진은 상위 레이어인 MySQL 엔진에서 관리되는 테이블 잠금(LOCK TABLES 명령으로 잠긴 테이블)은 볼 수가 없어 데드락 감지가 불확실 할 수 있는데, innodb_table_locks 시스템 변수를 활성화 하면 InnoDB 스토리지 엔진 내부의 레코드 잠금뿐만 아니라 테이블 레벨의 잠금 까지 감지할 수 있게 된다.\n일반적인 서비스에서는 데드락 감지 스레드가 데드락을 찾아내는 작업은 부담되지 않지만, 동시 처리 스레드가 매우 많아지거나 트랜잭션이 가진 잠금 개수가 많아지면 데드락 감지 스레드가 느려진다.\n데드락 감지 스레드는 잠금 목록을 검사해야 하기 때문에 잠금 상태가 변경되지 않도록 잠금 목록이 저장된 리스트(잠금 테이블)에 새로운 잠금을 걸고 데드락 스레드를 찾게 되는데, 데드락 감시 스레드가 느려지면 서비스 쿼리를 처리중인 스레드는 더는 작업을 진행하지 못하고 대기하며 서비스에 악영항을 미치게 된다. 이렇게 동시 처리 스레드가 매우 많은 경우 데드락 감지 스레드는 더 많은 CPU 자원을 소모할 수도 있다.\ninnodb_deadlock_detect 시스템 변수를 활용하여 데드락 감지 스레드를 비활성화 할 수 있다. 이럴 경우 데드락 상황 발생시 무한정 대기할 수도 있지만, innodb_lock_wait_timeout 시스템 변수를 활성화하면 일정 시간이 지났을 경우 요청 실패하고 에러 메시지를 반환하게 만들 수 있다.\n데드락 감시 스레드가 부담되어 innodb_deadlock_detect를 OFF로 설장해서 비활성화 하는 경우에는 innodb_lock_time_wait_timeout을 기본값인 50초보다 훨씬 낮은 시간으로 변경하여 사용할 것을 권장한다.\n자동화된 장애 복구 InnoDB에는 손실이나 장애로 부터 데이터를 보호하기 위한 여러가지 메커니즘이 탑재돼있다. 그러한 메커니즘을 이용해 MySQL 서버가 시작될 때 완료되지 못한 트랜잭션이나 디스크에 일부만 기록된(Partial write)데이터 페이지 등에 대한 인련의 복구 작업이 자동으로 진행된다.\nInnoDB 스토리지 엔진은 매우 견고해서 데이터 파일이 손상되거나 MySQL 서버가 시작되지 못하는 경우는 거의 발생하지 않지만, 디스크나 하드웨어 이슈로 InnoDB 스토리지 엔진이 자동으로 복구를 못 하는 경우도 발생할 수 있는데, 한번 문제가 생기면 복구하기 쉽지 않다.\nInnoDB 데이터 파일은 기본적으로 서버가 시작될 때 자동 복구를 수행하며, 자동으로 복구될 수 없는 손상이 있다면 서버가 종료된다.\n장애 복구 대응 MySQL 서버의 설정 파일에 innodb_force_recovery 시스템 변수를 설정하여 시작해야 한다.\n6: 로그 파일 손상 1: 테이블의 데이터 파일이 손상 어떤 부분이 문제인지 알 수 없다면 1~6까지 변경하며 재실행 이후 서버가 가동되고 InnoDB 테이블이 인식된다면 mysqldump를 이용해 데이터를 가능한 만큼 백업하고 그 데이터로 MySQL 서버의 DB와 테이블을 다시 생성하는 것이 좋다.\nInnoDB_force_recovery 옵션 1(SRV_FORCE_IGNORE_CORRUPT):\n테이블스페이스의 데이터나 인덱스 페이지에서 손상된 부분이 발견되도 무시하고 서버를 시작한다. \u0026lsquo;Database page corruption on disk or a failed\u0026rsquo; 출력되는 경우가 많다. mysqldump나 SELECT INTO OUTFILE ...를 이용해 덤프하여 데이터베이스를 다시 구축하는 것이 좋다. 2(SRV_FORCE_NO_BACKGROUND):\n백그라운드 스레드 가운데 메인 스레드를 시작하지 않고 MySQL 서버를 시작한다. 메인 스레드가 언두 데이터를 삭제하는 과정에서 장애가 발생했을때 사용 3(SRV_FORCE_NO_TRX_UNDO):\n일반적으로 MySQL 서버는 재실행시 언두 영역의 데이터를 먼저 파일에 적용하고 리두 로그의 내용을 다시 덮어써서 장애 시점의 데이터 상태를 만들어 낸 후, 최종적으로 커밋되지 않은 트랜잭션의 작업을 롤백하지만 3으로 설정시 롤백하지 않고 그대로 나둔다. 커밋되지 않고 종료된 트랜잭션은 계속 그 상태로 남아있게 된다. 백업 후 데이터베이스를 다시 구축하는 것이 좋다. 4(SRV_FORCE_NO_IBUF_MERGE):\nInnoDB는 INSERT, UPDATE, DELETE 등의 데이터 변경으로 인한 인덱스 변경 작업을 상황에 따라 즉시처리 혹은 버퍼에 두고 나중에 처리할 수 있다. 인서트 버퍼를 통해 처리가 될 경우, 비정상 종료시 병합 될지 알 수 없기 때문에, 인서트 버퍼의 손상을 감지하면 에러를 발생시켜 MySQL 서버의 실행을 막는다. 인서트 버퍼의 내용을 무시하고 강제로 MySQL을 실행시킨다. 인서트 버퍼는 실제 데이터와 관련된 부분이 아니라, 인덱스에 관련된 부분이므로 테이블을 텀프한 후 다시 데이터베이스를 구축하면 데이터의 손실 없이 복구할 수 있다. 5(SRV_FORCE_NO_UNDO_LOG_SCAN):\nMySQL 서버가 종료되는 시점에 처리중인 트랜잭션이 있을 경우 별도의 처리 없이 커넥션을 강제로 끊어버리고 종료된다. MySQL 서버가 재실행되면 InnoDB 엔진은 언두 레코드를 이용해 데이터 페이지를 복구하고 리두 로그를 적용해 종료 시점의 상태로 만들고, 커밋되지 않은 트랜잭션에서 변경한 작업은 모두 롤백 처리한다. 이때 InnoDB 스토리지 엔진이 언두 로그를 사용할 수 없다면 에러가 발생하여 MySQL 서버가 실행될 수 없다. 언두 로그를 모두 무시하고 실행한다. MySQL 서버가 종료되던 시점에 커밋되지 않았던 작업도 모두 커밋된 것처럼 처리되어 잘못된 데이터가 남을 수 있다. 데이터를 백업하고, 데이터베이스를 새로 구축해야한다. 6(SRV_FORCE_NO_LOG_REDO):\nInnoDB 스토리지 엔진의 리두 로그가 손상되면 MySQL 서버가 실행되지 못한다. 해당 복구 모드로 실행하면 리두 로그를 무시하고 서버가 실행된다.\n트랜잭션이 커밋됐다 하더라도 리두 로그에만 기록되고 데이터 파일에 기록되지 않은 데이터는 모두 무시되므로 마지막 체크 포인트시점의 데이터만 남게 된다. 기존 InnoDB의 리두 로그는 모두 삭제 또는 백업하고 MySQL 서버를 시작하는 것이 좋다. 데이터를 백업하고 MySQL 서버를 새로 구축하는 것이 좋다. 위 방법을 수행해도 MySQL서버가 시작되지 않으면 백업을 이용해 다시 구축하는 방법밖에 없다. 백업이 있다면 마지막 백업으로 데이터베이스를 다시 구축하고, 바이너리 로그를 사용해 최대한 장애 시점까지의 데이터를 복구할 수도 있다.\n마지막 풀 백업 시점부터 장애 시점까지의 바이너리 로그가 있다면 이용하는 것이 데이터 손실이 더 적을 수 있다.\n백업은 있지만 복제의 바이너리 로그가 없거나 손실되었다면, 마지막 백업 시점가지만 복구할 수 있다.\n","date":"2023-04-11T19:15:11+09:00","image":"https://codemario318.github.io/post/real_mysql_4_2_1/real_mysql_hu03b8ff0acb6f52b3ec9ae95e616f82c2_25714_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/real_mysql_4_2_1/","title":"4.2 InnoDB 스토리지 엔진 아키텍처(1)"},{"content":"MySQL의 전체 구조 MySQL 서버는 크게 MySQL 엔진과 스토리지 엔진으로 구분할 수 있다.\n사람으로 비유하면 MySQL 엔진은 머리 역할을 담담하고, 스토리지 엔진은 손과 발의 역할을 담당한다.\nMySQL 엔진 MySQL 엔진은 요청된 SQL 문장을 분석하거나 최적화하는 등 DBMS의 두뇌에 해당하는 처리를 수행한다.\n커넥션 핸들러: 클라이언트 요청에 따라 새로운 연결을 생성하고 관리 SQL 파서 및 전처리기: SQL 쿼리를 최적화 및 실행하기 전에 구문 분석 및 전처리를 담당 옵티마이저: 쿼리의 최적화 MySQL은 표준 SQL(ANSI SQL) 문법을 지원하기 때문에 표준 문법에 따라 작성된 쿼리는 타 DBMS와 호환되어 실행될 수 있다.\n스토리지 엔진 스토리지 엔진은 실제 데이터를 디스크 스토리지에 저장하거나 디스크 스토리지로부터 데이터를 읽어오는 역할 수행한다.\nMySQL 서버에서 MySQL엔진은 하나지만 스토리지 엔진은 여러 개를 동시에 사용할 수 있다.\n1 CREATE TABLE test_table (fd1 INT, fd2 INT) ENGINE=INNODB; 위처럼 테이블이 사용할 스토리지 엔진을 지정하면 해당 테이블의 모든 읽기 작업과 변경 작업은 정의된 스토리지 엔진이 처리한다.\n각 스토리지 엔진은 성능 향상을 위해 키 캐시(MyISAM), 버퍼풀(InnoDB) 같은 기능을 내장하고 있다.\n핸들러 API MySQL 엔진의 쿼리 실행기에서 데이터를 쓰거나 읽어야 할 때는 스토리지 엔진에 쓰기 또는 읽기를 요청하는데, 이러한 요청을 핸들러 요청이라고 하며, 사용되는 API를 핸들러 API라고 한다.\nInnoDB 스토리지 엔진 또한 이 핸들러 API를 이용해 MySQL 엔진과 데이터를 주고 받는다.\n핸들러 API를 통해 발생한 작업은 아래 쿼리로 확인 가능하다.\n1 SHOW GLOBAL STATUS LIKE \u0026#39;Handler%\u0026#39;; MySQL 스레딩 구조 MySQL 서버는 프로세스 기반이 아니라 스레드 기반으로 동작한다.\nMySQL 서버에서 실행 중인 스레드 목록은 performance_schema 데이터베이스에 threads 테이블을 통해 확인할 수 있다.\n1 2 3 4 5 6 7 8 9 SELECT thread_id ,name ,type ,processlist_user ,processlist_host FROM performance_schema.threads ORDER BY type,thread_id ; 백그라운드 스레드의 개수는 MySQL 서버의 설정 내용에 따라 가변적일 수 있다. 동일한 스레드가 2개 이상씩 보이는 것은 MySQL 서버의 설정 내용에 의해 여러 스레드가 동일 작업을 병렬로 처리하는 경우이다.\n포그라운드 스레드(클라이언트 스레드) 포그라운드 스레드는 클라이언트 연결 요청을 처리하고 데이터베이스 작업을 수행한다. 이러한 스레드는 쿼리 실행 중에 CPU 및 I/O 리소스를 사용하므로, 성능에 중요한 역할을 한다.\n포그라운드 스레드는 최소한 MySQL 서버에 접속된 클라이언트의 수만큼 존재하며, 주로 각 클라이언트 사용자가 요청하는 쿼리 문장을 처리한다.\n클라이언트 사용자가 작업을 마치고 커넥션을 종료하면, 해당 커넥션을 담당하던 스레드는 다시 스레드 캐시로 돌아간다.\n이때 이미 스레드 캐시에 일정 개수 이상의 대기중인 스레드가 있으면 스레드 캐시에 넣지 않고 스레드를 종료시켜 일정 개수의 스레드만 스레드 캐시에 존재하게 한다.\n스레드 캐시에 유지할 수 있는 최대 스레드 개수는 thread_cache_size 시스템 변수로 설정한다.\n포그라운드 스레드는 데이터를 MySQL 데이터 버퍼나 캐시로 부터 가져오며, 버퍼나 캐시에 없는 경우 직접 디스크의 데이터나 인덱스 파일로부터 데이터를 읽어와서 작업을 처리한다.\nMyISAM: 디스크 쓰기 작업까지 포그라운드 스레드가 처리 InnoDB: 데이터 버퍼나 캐시까지만 포그라운드 스레드가 처리 백그라운드 스레드 MyISAM의 경우 해당 사항이 별로 없지만, InnoDB는 다음과 같이 여러가지 작업이 백그라운드로 처리된다.\n인서트 버퍼(Insert Buffer)를 병합하는 스레드 로그를 디스크로 기록하는 스레드 InnoDB 버퍼풀의 데이터를 디스크에 기록하는 스레드 데이터 버퍼로 읽어 오는 스레드 잠금이나 데드락을 모니터링 하는 스레드 모두 중요한 역할을 수행하지만 로그 스레드와 버퍼의 데이터를 디스크로 내려쓰는 작업을 처리하는 쓰기 스레드(Write thread)가 특히 중요하다.\nMySQL 5.5 버전부터 데이터 쓰기 스레드와 데이터 읽기 스레드의 개수를 2개 이상 지정할 수 있게 됐으며, innodb_write_io_thread, innodb_read_io_threads 시스템 변수로 스레드의 개수를 설정한다.\nInnoDB에서도 데이터를 읽는 작업은 주로 클라이언트 스레드에서 처리되기 때문에 읽기 스레드는 많이 설정할 필요는 없지만, 쓰기 스레드는 아주 많은 작업을 백그라운드로 처리하기 때문에 일반적인 내장 디스크를 사용할때는 2~4 정도, DAS, SAN과 같은 스토리지를 사용할 때는 디스크를 최적으로 사용할 수 있을 만큼 충분히 설정하는 것이 좋다.\n사용자의 요청을 처리하는 도중 데이터의 쓰기 작업은 지연(버퍼링)되어 처리될 수 있지만 데이터의 읽기 작업은 절대 지연될 수 없다. 일반적인 상용 DBMS에는 대부분 쓰기 작업을 버퍼링해서 일괄 처리하는 기능이 있다.\nInnoDB: INSERT, UPDATE, DELETE 쿼리로 데이터가 변경되는 경우 데이터가 디스크의 데이터 파일로 완전히 저장될 때까지 기다리지 않아도 된다. MyISAM: 사용자 스레드가 쓰기 작업까지 함께 처리하도록 설계되어, 일반적인 쿼리는 쓰기 버퍼링 기능을 사용할 수 없다. 메모리 할당 및 사용 구조 글로벌 메모리 영역과 로컬 메모리 영역으로 구분되며, 서버 내에 존재하는 많은 스레드가 공유해서 사용하는 공간인지 여부에 따라 구분된다.\n글로벌 메모리 영역 일반적으로 클라이언트 스레드의 수와 무관하게 하나의 메모리 공간만 할당된다. 필요에 따라 2개 이상의 메모리 공간을 할당받을 수도 있지만 클라이언트의 스레드 수와 무관하며, 생성된 글로벌 영역이 N개라 하더라도 모든 스레드에 의해 공유된다.\n테이블 캐시 InnoDB 버퍼풀 InnoDB 어댑티드 해시 인덱스 InnoDB 리두 로그 버퍼 등이 대표적인 글로벌 메모리 영역이다.\n로컬 메모리 영역 세션 메모리 영역이라고도 표현하며, MySQL 서버상에 존재하는 클라이언트 스레드가 쿼리를 처리하는 데 사용하는 메모리 영역이다.\n정렬 버퍼 조인 버퍼 바이너리 로그 캐시 네트워크 버퍼 MySQL 서버에 클라이언트가 접속하면, 클라이언트 커넥션(세션)으로부터의 요청을 처리하기 위해 스레드를 하나씩 할당하게 되는데, 클라이언트 스레드가 사용하는 메모리 공간이라고 해서 클라이언트 메모리 영역이라고도 한다.\n로컬 메모리는 각 클라이언트 스레드별로 독립적으로 할당되며 절대 공유되어 사용되지 않는다.\n일반적으로 글로벌 메모리 영역의 크기는 주의해서 설정하지만 소트 버퍼와 같은 오컬 메모리 영역은 크게 신경 쓰지 않고 설정하는데, 최악의 경우 MySQL 서버가 메모리 부족으로 멈춰 버릴수도 있으므로 적절한 메모리 공간을 설정하는 것이 중요하다.\n커넥션이 열러있는 동안 계속 할당된 상태로 남아있는 경우: 커넥션 버퍼, 결과 버퍼 쿼리를 실행하는 순간에만 할당: 소트 버퍼, 조인 버퍼 플러그인 스토리지 엔진 모델 MySQL의 독특한 구조 중 대표적인 중 하나가 플러그인 모델이다.\n스토리지 엔진 검색 엔진을 위한 검색어 파서 사용자의 인증을 위한 Native Authentication, Caching SHA-2 Authentication 등 MySQL은 이미 기본적으로 많은 스토리지 엔진을 가지고 있지만, 필요에 의해 직접 스토리지 엔진을 만드는 것도 가능하다.\nMySQL에서 쿼리가 실행되는 과정을 보면 대부분 작업이 MySQL엔진에서 처리되고, 마지막 데이터 읽기, 쓰기 작업만 스토리지 엔진에 의해 처리한다.\nGROUP BY, ORDER BY 등 복잡한 처리는 스토리지 엔진 영역이 아니라 MySQL 엔진의 처리 영역인 쿼리 실행기에서 처리된다.\n스토리지 엔진에 따라 데이터 읽기/쓰기 작업 처리 방식이 크게 달라질 수 있다.\n하나의 쿼리 작업은 여러 하위 작업으로 나뉘는데, 각 하위 작업이 MySQL 엔진 영역에서 처리되는지 스토리지 엔진 영역에서 처리되는지 구분할 줄 알아야 한다.\n1 2 /* 스토리지 엔진 조회 */ SHOW ENGINES; 서버에 포함되지 않은 스토리지 엔진을 사용하려면 MySQL 서버를 다시 빌드해야 한다. 준비만 되어있다면 플러그인 형태로 빌드된 스토리지 엔진 라이브러리를 다운로드해서 끼워넣기만 하면 사용할 수 있다.\n1 2 /* 플러그인 조회 */ SHOW PLUGINS; 컴포넌트 플러그인 아키텍처는 다음과 같은 단점이 있다.\n오직 MySQL 서버와 인테페이스할 수 있고, 플러그인끼리는 통신할 수 없음 MySQL 서버의 변수나 함수를 직접 호출하기 때문에 안전하지 않음(캡슐화 안됨) 플러그인은 상호 의존 관계를 설정할 수 없어 초기화가 어려움 이러한 문제를 개선하기 위해 MySQL 8.0 부터는 기존의 플러그인 아키텍처를 대체하기 위해 컴포넌트 아키텍처가 지원된다.\n예를 들면, MySQL 5.7 버전까지는 비밀번호 검증 기능이 플러그인 형태로 제공됐지만 MySQL8.0의 비밀번호 검증 기능은 컴포넌트로 개선됐다.\n1 2 3 4 5 /* validate_password 설치 */ INSTALL COMPONENT \u0026#39;file://component_validate_password\u0026#39;; /* 설치된 컴포넌트 확인 */ SELECT * FROM mysql.component; 쿼리 실행 구조 쿼리 파서 쿼리 파서는 사용자 요청으로 들어온 쿼리 문장을 토큰(MySQL이 인식할 수 있는 최소 단위의 어휘나 기호)으로 분리해 트리 형태의 구조로 만들어 내는 작업을 의미한다.\n쿼리 문장의 기본 문법 오류는 이 과정에서 발견되고 사용자에게 오류 메시지를 전달하게 된다. 전처리기 파서 과정에서 만들어진 파서 트리를 기반으로 쿼리 문장에 구조적인 문제점이 있는지 확인한다.\n각 토큰을 테이블 이름이나 컬럼 이름, 또는 내장 함수와 같은 개체를 매핑해 해당 객체의 존재 여부와 객체의 접근 권한 등을 확인하는 과정을 수행한다.\n실제 존재하지 않거나 권한상 사용할 수 없는 개체의 토큰(컬럼, 내장 함수)은 이 단계에서 걸러진다. 옵티마이저 사용자의 요청으로 들어온 쿼리 문장을 저렴한 비용으로 가장 빠르게 처리할지를 결정하는 역할을 담당한다.\nDBMS의 두뇌에 비유되며, 옵티마이저가 더 나은 선택을 하도록 유도하는 것이 매우 중요하다.\n실행 엔진 옵티마이저가 두뇌라면 실행 엔진과 핸들러는 손과 발에 비유할 수 있다.\n옵티마이저가 GROUP BY를 처리하기 위해 임시 테이블을 사용하기로 결정했다면 아래 과정을 거칠 수 있다.\n실행 엔진이 핸들러에게 임시 테이블을 만들라고 요청 실행 엔진은 WHERE 절에 일치하는 레코드를 읽어오라고 핸들러에게 요청 읽어온 레코드들을 1번에서 준비한 임시 테이블로 저장하라고 핸들러에게 요청 데이터가 준비된 임시 테이블에서 필요한 방식으로 데이터를 읽어 오라고 핸들러에게 요청 결과를 사용자나 다른 모듈로 넘김 즉, 만들어진 계획대로 각 핸들러에게 요청해서 받은 결과를 또 다른 핸들러 요청의 입력으로 연결하는 역할을 수행한다.\n핸들러(스토리지 엔진) MySQL 서버의 가장 밑단에서 실행 엔진의 요청에 따라 데이터를 디스크로 저장하고 디스크로부터 읽어 오는 역할을 담당한다.\n핸들러는 결국 스토리지 엔진을 의미하며, MyISAM 테이블을 조작하는 경우 핸들러가 MyISAM 스토리지 엔진이 되고, InnoDB 테이블을 조작하는 경우 InnoDB 스토리지 엔진이 된다.\n복제 MySQL 서버에서 복제(Replication)는 매우 중요한 역할을 담당하며, 지금까지 MySQL 서버에서 복제는 많은 발전을 거듭해왔다.(16장)\n쿼리 캐시 쿼리 캐시는 빠른 응답을 필요로 하는 웹 기반의 응용 프로그램에서 매우 중요한 역할을 담당했다. 쿼리 캐시는 SQL의 실행 결과를 메모리에 캐시하고, 동일 SQL 쿼리가 실행되면 테이블을 읽지 않고 즉시 결과를 반환하기 때문에 매우 빠른 성능을 보였다.\n하지만 쿼리 캐시는 테이블의 데이터가 변경되면 캐시에 저장된 결과 중에서 변경된 테이블과 관련된 테이블과 관련된 것들은 모두 삭제(Invalidate)해야 하므로, 심각한 동시 처리 성능 저하를 유발한다. 또한 MySQL 서버가 발전하면서 성능이 개선되는 과정에서 쿼리 캐시는 계속된 동시 처리 성능 저하와 많은 버그의 원인이 되기도 했다.\n다수의 클라이언트가 동시에 같은 쿼리를 실행하는 경우 쿼리 캐시 락(query cache lock)이 발생 가능하다. 이는 쿼리 캐시에 새로운 결과를 저장하거나 기존 결과를 반환하기 위해 필요한 락(lock)으로, 동시 처리가 많은 시스템에서는 쿼리 캐시를 사용하지 않는 것이 더 나은 성능을 보일 수 있다.\nMySQL 5.6 이하 버전에서는 쿼리 캐시가 InnoDB 또는 NDB Cluster 스토리지 엔진을 사용하는 경우에만 동작하는데 MyISAM 스토리지 엔진을 사용하는 경우에도 쿼리 캐시를 켜면 쿼리 결과가 무한정 캐시될 수 있는 버그가 있었다. 이러한 버그는 시스템의 부하를 높일 뿐만 아니라, 캐시 메모리의 공간을 차지해 다른 쿼리의 실행에 영향을 미칠 수 있다.\n이러한 이유로 MySQL 8.0으로 올라오면서 완전히 제거되고, 관련 시스템 변수도 모두 제거되었다.\n스레드 풀 MySQL 서버 엔터프라이즈 에디션은 스레드풀 기능을 제공하지만 커뮤니티 에디션은 지원하지 않는다. 따라서 Percona Server 플러그인에서 제공하는 스레드풀 기능을 살펴본다.\n스레드풀은 내부적으로 사용자의 요청을 처리하는 스레드 개수를 줄여서 동시 처리되는 요청이 많다 하더라도 MySQL 서버의 CPU가 제한된 개수의 스레드 처리에만 집중할 수 있게 하여 서버의 자원 소모를 줄이는것이 목적이다.\n하지만 스레드풀이 실제 서비스에서 눈에띄는 성능 향상을 보여준 경우는 드물다.\n실행 중인 스레드들을 CPU가 최대한 잘 처리해낼 수 있는 수준으로 줄여서 빨리 처리하게 하는 기능으므로 스케줄링 과정에서 CPU 시간을 제대로 확보하지 못하는 경우 쿼리 처리가 더 느려지는 사례도 발생할 수 있다.\n제한된 수의 스레드만으로 CPU가 처리하도록 적절히 유도하면 CPU의 프로세서 친화도(Processor affinity)도 높히고 불필요한 컨텍스트 스위치를 줄여 오버헤드를 낮출 수 있다.\n스레드 그룹 개수 Percona Server의 스레드 풀은 기본적으로 CPU 코어의 개수만큼 스레드 그룹을 생성하며 일반적으로 CPU 코어의 개수와 맞추는것이 CPU 프로세서 친화도를 높이는 데 좋다.\nMySQL 서버가 처리해야할 요청이 생기면 스레드풀로 처리를 이관하는데, 이미 스레드풀이 처리중인 작업이 있는 경우 시스템 변수에 설정된 개수만큼 추가로 더 받아들여서 처리한다. 너무 많으면 스케줄링해야 할 수레드가 많아져 비효율적으로 작동할 수 있다.\n타이머 스레드 스레드 그룹의 모든 스레드가 일을 처리하고 있다면 스레드 풀은 해당 스레드 그룹에 새로운 작업 스레드를 추가할지, 기존 작업 스레드가 처리를 완료할 때가지 기다릴지 여부를 판단해야 한다.\n주기적으로 스레드 그룹의 상태를 체크해서 thread_pool_stall_limit 시스템 변수에 정의된 시간에 작업을 끝내지 못했다면 새로운 스레드를 생성해 스레드 그룹에 추가한다.\n모든 스레드 그룹의 스레드가 작업을 수행중이라면 시스템 변수에 설정된 개수를 넘어설 수 없어 대기해야 한다.\n응답 시간이 아주 민감한 서비스라면 시스템 변수를 적절히 낮춰 설정해야하며, 0에 가까운 값으로 설정하는 것은 좋지 않고 이런 경우는 스레드풀을 사용하지 않는 것이 좋을 수 있다.\n우선순위 큐 선순위 큐와 후순위 큐를 이용해 특정 트랜잭션이나 쿼리를 우선적으로 처리할 수 있는 기능도 제공한다. 먼저 시작된 트랜잭션 내에 속한 SQL을 빨리 처리해주면 해당 트랜잭션이 가지고 있던 잠금이 빨리 해제되고 잠금 경합을 낮춰 전체적인 처리 성능을 향상시킬 수 있다.\n트랜잭션 지원 메타데이터 데이터베이스 서버에서 테이블의 구조 정보와 스토어드 프로그램 등의 정보를 데이터 딕셔너리 또는 메타데이터라고 하는데, MySQL 서버는 5.7 버전까지 테이블의 구조를 FRM 파일에 저장하고 일부 스토어드 프로그램 또한 파일 기반으로 관리 되었다.\n이러한 파일 기반의 메타데이터는 생성 및 변경 작업이 트랜잭션을 지원하지 않기 때문에 테이블의 생성 또는 변경 도중에 MySQL 서버가 비정상적으로 종료되면 일관되지 않은 상태로 남게되는 문제가 있었다.\n이에따라 8버전 부터는 테이블의 구조 정보나 스토어드 프로그램의 코드 관련 정보를 모두 InnoDB의 테이블에 저장하도록 개선되었다.\n","date":"2023-04-10T00:00:00Z","image":"https://codemario318.github.io/post/real_mysql_4_1/real_mysql_hu03b8ff0acb6f52b3ec9ae95e616f82c2_25714_120x120_fill_q75_box_smart1.jpeg","permalink":"https://codemario318.github.io/post/real_mysql_4_1/","title":"4.1 MySQL 엔진 아키텍처"}]